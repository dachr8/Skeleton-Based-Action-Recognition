[ Tue Feb  2 03:29:54 2021 ] Parameters:
{'work_dir': './work_dir/ntu_ShiftGCN_joint_xsub_raw', 'model_saved_name': './save_models/ntu_ShiftGCN_joint_xsub_raw', 'Experiment_name': 'ntu_ShiftGCN_joint_xsub_raw', 'config': 'config/nturgbd-cross-subject/train_joint_raw.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': './data/ntu_raw/xsub/train_data_joint.npy', 'label_path': './data/ntu_raw/xsub/train_label.pkl', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': {'data_path': './data/ntu_raw/xsub/val_data_joint.npy', 'label_path': './data/ntu_raw/xsub/val_label.pkl'}, 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 60, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [60, 80, 100], 'device': [0, 1, 2, 3], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 32, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 140, 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Tue Feb  2 03:29:54 2021 ] Training epoch: 1
[ Tue Feb  2 03:30:24 2021 ] Parameters:
{'work_dir': './work_dir/ntu_ShiftGCN_joint_xsub_raw', 'model_saved_name': './save_models/ntu_ShiftGCN_joint_xsub_raw', 'Experiment_name': 'ntu_ShiftGCN_joint_xsub_raw', 'config': 'config/nturgbd-cross-subject/train_joint_raw.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': './data/ntu_raw/xsub/train_data_joint.npy', 'label_path': './data/ntu_raw/xsub/train_label.pkl', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': {'data_path': './data/ntu_raw/xsub/val_data_joint.npy', 'label_path': './data/ntu_raw/xsub/val_label.pkl'}, 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 60, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [60, 80, 100], 'device': [4, 5, 6, 7], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 32, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 140, 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Tue Feb  2 03:30:24 2021 ] Training epoch: 1
[ Tue Feb  2 03:31:00 2021 ] 	Batch(99/1252) done. Loss: 4.0552  lr:0.100000  network_time: 0.0872
[ Tue Feb  2 03:31:23 2021 ] 	Batch(199/1252) done. Loss: 3.5665  lr:0.100000  network_time: 0.0966
[ Tue Feb  2 03:31:46 2021 ] 	Batch(299/1252) done. Loss: 3.1193  lr:0.100000  network_time: 0.0924
[ Tue Feb  2 03:32:08 2021 ] 	Batch(399/1252) done. Loss: 3.3159  lr:0.100000  network_time: 0.0813
[ Tue Feb  2 03:32:31 2021 ] 	Batch(499/1252) done. Loss: 3.3786  lr:0.100000  network_time: 0.1008
[ Tue Feb  2 03:32:54 2021 ] 	Batch(599/1252) done. Loss: 3.1448  lr:0.100000  network_time: 0.0917
[ Tue Feb  2 03:33:17 2021 ] 	Batch(699/1252) done. Loss: 2.4823  lr:0.100000  network_time: 0.0991
[ Tue Feb  2 03:33:39 2021 ] 	Batch(799/1252) done. Loss: 2.9166  lr:0.100000  network_time: 0.0877
[ Tue Feb  2 03:34:02 2021 ] 	Batch(899/1252) done. Loss: 2.3655  lr:0.100000  network_time: 0.0944
[ Tue Feb  2 03:34:25 2021 ] 	Batch(999/1252) done. Loss: 2.3755  lr:0.100000  network_time: 0.0895
[ Tue Feb  2 03:34:48 2021 ] 	Batch(1099/1252) done. Loss: 2.4697  lr:0.100000  network_time: 0.0859
[ Tue Feb  2 03:35:10 2021 ] 	Batch(1199/1252) done. Loss: 2.6535  lr:0.100000  network_time: 0.0843
[ Tue Feb  2 03:35:22 2021 ] Eval epoch: 1
[ Tue Feb  2 03:35:57 2021 ] 	Mean test loss of 258 batches: 3.2624075412750244.
[ Tue Feb  2 03:35:57 2021 ] 	Top1: 38.98%
[ Tue Feb  2 03:35:57 2021 ] 	Top5: 75.40%
[ Tue Feb  2 03:35:57 2021 ] Training epoch: 2
[ Tue Feb  2 03:36:11 2021 ] 	Batch(47/1252) done. Loss: 1.8718  lr:0.100000  network_time: 0.1035
[ Tue Feb  2 03:36:34 2021 ] 	Batch(147/1252) done. Loss: 2.0408  lr:0.100000  network_time: 0.0859
[ Tue Feb  2 03:36:56 2021 ] 	Batch(247/1252) done. Loss: 1.7790  lr:0.100000  network_time: 0.0720
[ Tue Feb  2 03:37:19 2021 ] 	Batch(347/1252) done. Loss: 1.8695  lr:0.100000  network_time: 0.0795
[ Tue Feb  2 03:37:42 2021 ] 	Batch(447/1252) done. Loss: 1.7783  lr:0.100000  network_time: 0.1026
[ Tue Feb  2 03:38:04 2021 ] 	Batch(547/1252) done. Loss: 1.8506  lr:0.100000  network_time: 0.0868
[ Tue Feb  2 03:38:27 2021 ] 	Batch(647/1252) done. Loss: 1.5590  lr:0.100000  network_time: 0.0820
[ Tue Feb  2 03:38:50 2021 ] 	Batch(747/1252) done. Loss: 1.4141  lr:0.100000  network_time: 0.0907
[ Tue Feb  2 03:39:12 2021 ] 	Batch(847/1252) done. Loss: 1.6664  lr:0.100000  network_time: 0.0770
[ Tue Feb  2 03:39:35 2021 ] 	Batch(947/1252) done. Loss: 1.0906  lr:0.100000  network_time: 0.1088
[ Tue Feb  2 03:39:58 2021 ] 	Batch(1047/1252) done. Loss: 1.5933  lr:0.100000  network_time: 0.1030
[ Tue Feb  2 03:40:20 2021 ] 	Batch(1147/1252) done. Loss: 1.6994  lr:0.100000  network_time: 0.0995
[ Tue Feb  2 03:40:43 2021 ] 	Batch(1247/1252) done. Loss: 1.4893  lr:0.100000  network_time: 0.0903
[ Tue Feb  2 03:40:44 2021 ] Eval epoch: 2
[ Tue Feb  2 03:41:18 2021 ] 	Mean test loss of 258 batches: 1.5435034036636353.
[ Tue Feb  2 03:41:18 2021 ] 	Top1: 56.04%
[ Tue Feb  2 03:41:18 2021 ] 	Top5: 87.01%
[ Tue Feb  2 03:41:18 2021 ] Training epoch: 3
[ Tue Feb  2 03:41:43 2021 ] 	Batch(95/1252) done. Loss: 1.5268  lr:0.100000  network_time: 0.0956
[ Tue Feb  2 03:42:05 2021 ] 	Batch(195/1252) done. Loss: 1.6152  lr:0.100000  network_time: 0.1016
[ Tue Feb  2 03:42:28 2021 ] 	Batch(295/1252) done. Loss: 1.0137  lr:0.100000  network_time: 0.1039
[ Tue Feb  2 03:42:51 2021 ] 	Batch(395/1252) done. Loss: 1.2030  lr:0.100000  network_time: 0.0824
[ Tue Feb  2 03:43:14 2021 ] 	Batch(495/1252) done. Loss: 1.0746  lr:0.100000  network_time: 0.0761
[ Tue Feb  2 03:43:37 2021 ] 	Batch(595/1252) done. Loss: 1.2825  lr:0.100000  network_time: 0.0983
[ Tue Feb  2 03:43:59 2021 ] 	Batch(695/1252) done. Loss: 1.5453  lr:0.100000  network_time: 0.0965
[ Tue Feb  2 03:44:21 2021 ] 	Batch(795/1252) done. Loss: 1.3416  lr:0.100000  network_time: 0.0873
[ Tue Feb  2 03:44:44 2021 ] 	Batch(895/1252) done. Loss: 1.2630  lr:0.100000  network_time: 0.0824
[ Tue Feb  2 03:45:07 2021 ] 	Batch(995/1252) done. Loss: 1.1681  lr:0.100000  network_time: 0.0898
[ Tue Feb  2 03:45:29 2021 ] 	Batch(1095/1252) done. Loss: 1.2478  lr:0.100000  network_time: 0.0811
[ Tue Feb  2 03:45:52 2021 ] 	Batch(1195/1252) done. Loss: 1.2263  lr:0.100000  network_time: 0.0842
[ Tue Feb  2 03:46:04 2021 ] Eval epoch: 3
[ Tue Feb  2 03:46:39 2021 ] 	Mean test loss of 258 batches: 1.270194172859192.
[ Tue Feb  2 03:46:39 2021 ] 	Top1: 61.48%
[ Tue Feb  2 03:46:39 2021 ] 	Top5: 89.90%
[ Tue Feb  2 03:46:40 2021 ] Training epoch: 4
[ Tue Feb  2 03:46:52 2021 ] 	Batch(43/1252) done. Loss: 0.8546  lr:0.100000  network_time: 0.0974
[ Tue Feb  2 03:47:15 2021 ] 	Batch(143/1252) done. Loss: 0.7986  lr:0.100000  network_time: 0.1044
[ Tue Feb  2 03:47:37 2021 ] 	Batch(243/1252) done. Loss: 1.7378  lr:0.100000  network_time: 0.0889
[ Tue Feb  2 03:48:00 2021 ] 	Batch(343/1252) done. Loss: 1.2554  lr:0.100000  network_time: 0.0805
[ Tue Feb  2 03:48:22 2021 ] 	Batch(443/1252) done. Loss: 1.3736  lr:0.100000  network_time: 0.1085
[ Tue Feb  2 03:48:44 2021 ] 	Batch(543/1252) done. Loss: 1.2899  lr:0.100000  network_time: 0.0783
[ Tue Feb  2 03:49:06 2021 ] 	Batch(643/1252) done. Loss: 1.0597  lr:0.100000  network_time: 0.0699
[ Tue Feb  2 03:49:29 2021 ] 	Batch(743/1252) done. Loss: 1.1878  lr:0.100000  network_time: 0.0883
[ Tue Feb  2 03:49:51 2021 ] 	Batch(843/1252) done. Loss: 1.2412  lr:0.100000  network_time: 0.0889
[ Tue Feb  2 03:50:13 2021 ] 	Batch(943/1252) done. Loss: 1.4917  lr:0.100000  network_time: 0.0755
[ Tue Feb  2 03:50:35 2021 ] 	Batch(1043/1252) done. Loss: 1.0632  lr:0.100000  network_time: 0.1000
[ Tue Feb  2 03:50:57 2021 ] 	Batch(1143/1252) done. Loss: 0.8572  lr:0.100000  network_time: 0.0898
[ Tue Feb  2 03:51:19 2021 ] 	Batch(1243/1252) done. Loss: 1.2241  lr:0.100000  network_time: 0.0833
[ Tue Feb  2 03:51:21 2021 ] Eval epoch: 4
[ Tue Feb  2 03:51:56 2021 ] 	Mean test loss of 258 batches: 1.2640117406845093.
[ Tue Feb  2 03:51:56 2021 ] 	Top1: 64.62%
[ Tue Feb  2 03:51:56 2021 ] 	Top5: 89.89%
[ Tue Feb  2 03:51:56 2021 ] Training epoch: 5
[ Tue Feb  2 03:52:19 2021 ] 	Batch(91/1252) done. Loss: 1.0788  lr:0.100000  network_time: 0.0854
[ Tue Feb  2 03:52:42 2021 ] 	Batch(191/1252) done. Loss: 1.1324  lr:0.100000  network_time: 0.0919
[ Tue Feb  2 03:53:04 2021 ] 	Batch(291/1252) done. Loss: 1.1918  lr:0.100000  network_time: 0.0894
[ Tue Feb  2 03:53:26 2021 ] 	Batch(391/1252) done. Loss: 1.1422  lr:0.100000  network_time: 0.0755
[ Tue Feb  2 03:53:48 2021 ] 	Batch(491/1252) done. Loss: 1.3094  lr:0.100000  network_time: 0.0779
[ Tue Feb  2 03:54:10 2021 ] 	Batch(591/1252) done. Loss: 0.7629  lr:0.100000  network_time: 0.0826
[ Tue Feb  2 03:54:32 2021 ] 	Batch(691/1252) done. Loss: 0.7268  lr:0.100000  network_time: 0.0771
[ Tue Feb  2 03:54:54 2021 ] 	Batch(791/1252) done. Loss: 0.8180  lr:0.100000  network_time: 0.0803
[ Tue Feb  2 03:55:16 2021 ] 	Batch(891/1252) done. Loss: 0.5706  lr:0.100000  network_time: 0.0893
[ Tue Feb  2 03:55:39 2021 ] 	Batch(991/1252) done. Loss: 0.9013  lr:0.100000  network_time: 0.0807
[ Tue Feb  2 03:56:01 2021 ] 	Batch(1091/1252) done. Loss: 1.0553  lr:0.100000  network_time: 0.0863
[ Tue Feb  2 03:56:23 2021 ] 	Batch(1191/1252) done. Loss: 0.8444  lr:0.100000  network_time: 0.0804
[ Tue Feb  2 03:56:36 2021 ] Eval epoch: 5
[ Tue Feb  2 03:57:10 2021 ] 	Mean test loss of 258 batches: 1.1213189363479614.
[ Tue Feb  2 03:57:11 2021 ] 	Top1: 68.62%
[ Tue Feb  2 03:57:11 2021 ] 	Top5: 92.33%
[ Tue Feb  2 03:57:11 2021 ] Training epoch: 6
[ Tue Feb  2 03:57:23 2021 ] 	Batch(39/1252) done. Loss: 0.8680  lr:0.100000  network_time: 0.0960
[ Tue Feb  2 03:57:45 2021 ] 	Batch(139/1252) done. Loss: 1.2676  lr:0.100000  network_time: 0.1054
[ Tue Feb  2 03:58:07 2021 ] 	Batch(239/1252) done. Loss: 1.0201  lr:0.100000  network_time: 0.0853
[ Tue Feb  2 03:58:29 2021 ] 	Batch(339/1252) done. Loss: 1.2416  lr:0.100000  network_time: 0.0942
[ Tue Feb  2 03:58:51 2021 ] 	Batch(439/1252) done. Loss: 0.9402  lr:0.100000  network_time: 0.0847
[ Tue Feb  2 03:59:13 2021 ] 	Batch(539/1252) done. Loss: 0.6129  lr:0.100000  network_time: 0.1022
[ Tue Feb  2 03:59:35 2021 ] 	Batch(639/1252) done. Loss: 0.6687  lr:0.100000  network_time: 0.0870
[ Tue Feb  2 03:59:57 2021 ] 	Batch(739/1252) done. Loss: 1.0331  lr:0.100000  network_time: 0.0810
[ Tue Feb  2 04:00:20 2021 ] 	Batch(839/1252) done. Loss: 1.1587  lr:0.100000  network_time: 0.0800
[ Tue Feb  2 04:00:42 2021 ] 	Batch(939/1252) done. Loss: 1.0592  lr:0.100000  network_time: 0.0827
[ Tue Feb  2 04:01:04 2021 ] 	Batch(1039/1252) done. Loss: 0.9428  lr:0.100000  network_time: 0.0856
[ Tue Feb  2 04:01:26 2021 ] 	Batch(1139/1252) done. Loss: 0.7639  lr:0.100000  network_time: 0.0801
[ Tue Feb  2 04:01:48 2021 ] 	Batch(1239/1252) done. Loss: 0.7859  lr:0.100000  network_time: 0.1034
[ Tue Feb  2 04:01:51 2021 ] Eval epoch: 6
[ Tue Feb  2 04:02:25 2021 ] 	Mean test loss of 258 batches: 1.0338404178619385.
[ Tue Feb  2 04:02:25 2021 ] 	Top1: 69.45%
[ Tue Feb  2 04:02:26 2021 ] 	Top5: 92.70%
[ Tue Feb  2 04:02:26 2021 ] Training epoch: 7
[ Tue Feb  2 04:02:48 2021 ] 	Batch(87/1252) done. Loss: 1.2046  lr:0.100000  network_time: 0.0889
[ Tue Feb  2 04:03:10 2021 ] 	Batch(187/1252) done. Loss: 0.9240  lr:0.100000  network_time: 0.0877
[ Tue Feb  2 04:03:32 2021 ] 	Batch(287/1252) done. Loss: 0.3746  lr:0.100000  network_time: 0.0850
[ Tue Feb  2 04:03:54 2021 ] 	Batch(387/1252) done. Loss: 0.7369  lr:0.100000  network_time: 0.0794
[ Tue Feb  2 04:04:16 2021 ] 	Batch(487/1252) done. Loss: 1.0179  lr:0.100000  network_time: 0.0958
[ Tue Feb  2 04:04:38 2021 ] 	Batch(587/1252) done. Loss: 0.7199  lr:0.100000  network_time: 0.0770
[ Tue Feb  2 04:05:00 2021 ] 	Batch(687/1252) done. Loss: 0.7912  lr:0.100000  network_time: 0.0835
[ Tue Feb  2 04:05:22 2021 ] 	Batch(787/1252) done. Loss: 0.9349  lr:0.100000  network_time: 0.0786
[ Tue Feb  2 04:05:44 2021 ] 	Batch(887/1252) done. Loss: 0.9013  lr:0.100000  network_time: 0.0827
[ Tue Feb  2 04:06:07 2021 ] 	Batch(987/1252) done. Loss: 0.5890  lr:0.100000  network_time: 0.0822
[ Tue Feb  2 04:06:29 2021 ] 	Batch(1087/1252) done. Loss: 1.1053  lr:0.100000  network_time: 0.0896
[ Tue Feb  2 04:06:51 2021 ] 	Batch(1187/1252) done. Loss: 0.9407  lr:0.100000  network_time: 0.0756
[ Tue Feb  2 04:07:05 2021 ] Eval epoch: 7
[ Tue Feb  2 04:07:39 2021 ] 	Mean test loss of 258 batches: 0.9667550921440125.
[ Tue Feb  2 04:07:39 2021 ] 	Top1: 70.61%
[ Tue Feb  2 04:07:39 2021 ] 	Top5: 93.86%
[ Tue Feb  2 04:07:39 2021 ] Training epoch: 8
[ Tue Feb  2 04:07:50 2021 ] 	Batch(35/1252) done. Loss: 1.2771  lr:0.100000  network_time: 0.0827
[ Tue Feb  2 04:08:13 2021 ] 	Batch(135/1252) done. Loss: 1.1294  lr:0.100000  network_time: 0.0753
[ Tue Feb  2 04:08:35 2021 ] 	Batch(235/1252) done. Loss: 1.0038  lr:0.100000  network_time: 0.0717
[ Tue Feb  2 04:08:57 2021 ] 	Batch(335/1252) done. Loss: 0.6597  lr:0.100000  network_time: 0.0887
[ Tue Feb  2 04:09:19 2021 ] 	Batch(435/1252) done. Loss: 0.9789  lr:0.100000  network_time: 0.0830
[ Tue Feb  2 04:09:41 2021 ] 	Batch(535/1252) done. Loss: 0.7864  lr:0.100000  network_time: 0.1028
[ Tue Feb  2 04:10:03 2021 ] 	Batch(635/1252) done. Loss: 1.0118  lr:0.100000  network_time: 0.0935
[ Tue Feb  2 04:10:25 2021 ] 	Batch(735/1252) done. Loss: 0.9730  lr:0.100000  network_time: 0.0798
[ Tue Feb  2 04:10:48 2021 ] 	Batch(835/1252) done. Loss: 0.6762  lr:0.100000  network_time: 0.0886
[ Tue Feb  2 04:11:10 2021 ] 	Batch(935/1252) done. Loss: 0.4396  lr:0.100000  network_time: 0.0937
[ Tue Feb  2 04:11:32 2021 ] 	Batch(1035/1252) done. Loss: 0.4871  lr:0.100000  network_time: 0.0828
[ Tue Feb  2 04:11:55 2021 ] 	Batch(1135/1252) done. Loss: 0.2742  lr:0.100000  network_time: 0.0868
[ Tue Feb  2 04:12:17 2021 ] 	Batch(1235/1252) done. Loss: 0.6831  lr:0.100000  network_time: 0.0935
[ Tue Feb  2 04:12:20 2021 ] Eval epoch: 8
[ Tue Feb  2 04:12:55 2021 ] 	Mean test loss of 258 batches: 0.9821254014968872.
[ Tue Feb  2 04:12:55 2021 ] 	Top1: 70.56%
[ Tue Feb  2 04:12:55 2021 ] 	Top5: 94.26%
[ Tue Feb  2 04:12:55 2021 ] Training epoch: 9
[ Tue Feb  2 04:13:17 2021 ] 	Batch(83/1252) done. Loss: 0.6687  lr:0.100000  network_time: 0.0827
[ Tue Feb  2 04:13:39 2021 ] 	Batch(183/1252) done. Loss: 0.7690  lr:0.100000  network_time: 0.0772
[ Tue Feb  2 04:14:01 2021 ] 	Batch(283/1252) done. Loss: 0.7488  lr:0.100000  network_time: 0.0804
[ Tue Feb  2 04:14:23 2021 ] 	Batch(383/1252) done. Loss: 0.5816  lr:0.100000  network_time: 0.0753
[ Tue Feb  2 04:14:45 2021 ] 	Batch(483/1252) done. Loss: 0.6327  lr:0.100000  network_time: 0.0828
[ Tue Feb  2 04:15:07 2021 ] 	Batch(583/1252) done. Loss: 0.5958  lr:0.100000  network_time: 0.0776
[ Tue Feb  2 04:15:29 2021 ] 	Batch(683/1252) done. Loss: 1.0981  lr:0.100000  network_time: 0.0836
[ Tue Feb  2 04:15:52 2021 ] 	Batch(783/1252) done. Loss: 1.0884  lr:0.100000  network_time: 0.1029
[ Tue Feb  2 04:16:14 2021 ] 	Batch(883/1252) done. Loss: 0.8893  lr:0.100000  network_time: 0.0805
[ Tue Feb  2 04:16:36 2021 ] 	Batch(983/1252) done. Loss: 0.5715  lr:0.100000  network_time: 0.0895
[ Tue Feb  2 04:16:58 2021 ] 	Batch(1083/1252) done. Loss: 1.0789  lr:0.100000  network_time: 0.0861
[ Tue Feb  2 04:17:20 2021 ] 	Batch(1183/1252) done. Loss: 0.9036  lr:0.100000  network_time: 0.0998
[ Tue Feb  2 04:17:36 2021 ] Eval epoch: 9
[ Tue Feb  2 04:18:10 2021 ] 	Mean test loss of 258 batches: 0.8985702395439148.
[ Tue Feb  2 04:18:10 2021 ] 	Top1: 73.25%
[ Tue Feb  2 04:18:10 2021 ] 	Top5: 94.29%
[ Tue Feb  2 04:18:11 2021 ] Training epoch: 10
[ Tue Feb  2 04:18:21 2021 ] 	Batch(31/1252) done. Loss: 0.7844  lr:0.100000  network_time: 0.0797
[ Tue Feb  2 04:18:43 2021 ] 	Batch(131/1252) done. Loss: 0.7696  lr:0.100000  network_time: 0.0873
[ Tue Feb  2 04:19:05 2021 ] 	Batch(231/1252) done. Loss: 0.8751  lr:0.100000  network_time: 0.1026
[ Tue Feb  2 04:19:27 2021 ] 	Batch(331/1252) done. Loss: 0.8179  lr:0.100000  network_time: 0.0831
[ Tue Feb  2 04:19:50 2021 ] 	Batch(431/1252) done. Loss: 0.4937  lr:0.100000  network_time: 0.0929
[ Tue Feb  2 04:20:12 2021 ] 	Batch(531/1252) done. Loss: 0.5297  lr:0.100000  network_time: 0.0772
[ Tue Feb  2 04:20:34 2021 ] 	Batch(631/1252) done. Loss: 0.5945  lr:0.100000  network_time: 0.0960
[ Tue Feb  2 04:20:58 2021 ] 	Batch(731/1252) done. Loss: 0.5260  lr:0.100000  network_time: 0.0874
[ Tue Feb  2 04:21:22 2021 ] 	Batch(831/1252) done. Loss: 0.5922  lr:0.100000  network_time: 0.0890
[ Tue Feb  2 04:21:47 2021 ] 	Batch(931/1252) done. Loss: 0.8925  lr:0.100000  network_time: 0.1042
[ Tue Feb  2 04:22:11 2021 ] 	Batch(1031/1252) done. Loss: 0.7146  lr:0.100000  network_time: 0.0916
[ Tue Feb  2 04:22:35 2021 ] 	Batch(1131/1252) done. Loss: 0.8927  lr:0.100000  network_time: 0.0895
[ Tue Feb  2 04:22:59 2021 ] 	Batch(1231/1252) done. Loss: 1.2136  lr:0.100000  network_time: 0.0875
[ Tue Feb  2 04:23:04 2021 ] Eval epoch: 10
[ Tue Feb  2 04:23:40 2021 ] 	Mean test loss of 258 batches: 0.9738063216209412.
[ Tue Feb  2 04:23:40 2021 ] 	Top1: 71.69%
[ Tue Feb  2 04:23:40 2021 ] 	Top5: 93.67%
[ Tue Feb  2 04:23:40 2021 ] Training epoch: 11
[ Tue Feb  2 04:24:02 2021 ] 	Batch(79/1252) done. Loss: 0.9104  lr:0.100000  network_time: 0.0940
[ Tue Feb  2 04:24:26 2021 ] 	Batch(179/1252) done. Loss: 1.2023  lr:0.100000  network_time: 0.0906
[ Tue Feb  2 04:24:50 2021 ] 	Batch(279/1252) done. Loss: 0.9609  lr:0.100000  network_time: 0.0884
[ Tue Feb  2 04:25:15 2021 ] 	Batch(379/1252) done. Loss: 0.9368  lr:0.100000  network_time: 0.0933
[ Tue Feb  2 04:25:39 2021 ] 	Batch(479/1252) done. Loss: 0.7546  lr:0.100000  network_time: 0.0879
[ Tue Feb  2 04:26:03 2021 ] 	Batch(579/1252) done. Loss: 0.7864  lr:0.100000  network_time: 0.0950
[ Tue Feb  2 04:26:27 2021 ] 	Batch(679/1252) done. Loss: 0.4122  lr:0.100000  network_time: 0.1029
[ Tue Feb  2 04:26:51 2021 ] 	Batch(779/1252) done. Loss: 0.6663  lr:0.100000  network_time: 0.0875
[ Tue Feb  2 04:27:16 2021 ] 	Batch(879/1252) done. Loss: 0.7134  lr:0.100000  network_time: 0.0977
[ Tue Feb  2 04:27:40 2021 ] 	Batch(979/1252) done. Loss: 0.8851  lr:0.100000  network_time: 0.0976
[ Tue Feb  2 04:28:04 2021 ] 	Batch(1079/1252) done. Loss: 0.6644  lr:0.100000  network_time: 0.0807
[ Tue Feb  2 04:28:28 2021 ] 	Batch(1179/1252) done. Loss: 0.6036  lr:0.100000  network_time: 0.0840
[ Tue Feb  2 04:28:45 2021 ] Eval epoch: 11
[ Tue Feb  2 04:29:22 2021 ] 	Mean test loss of 258 batches: 0.8683909177780151.
[ Tue Feb  2 04:29:22 2021 ] 	Top1: 74.87%
[ Tue Feb  2 04:29:22 2021 ] 	Top5: 94.80%
[ Tue Feb  2 04:29:22 2021 ] Training epoch: 12
[ Tue Feb  2 04:29:32 2021 ] 	Batch(27/1252) done. Loss: 0.7760  lr:0.100000  network_time: 0.0861
[ Tue Feb  2 04:29:55 2021 ] 	Batch(127/1252) done. Loss: 0.4935  lr:0.100000  network_time: 0.0947
[ Tue Feb  2 04:30:19 2021 ] 	Batch(227/1252) done. Loss: 0.5171  lr:0.100000  network_time: 0.0951
[ Tue Feb  2 04:30:43 2021 ] 	Batch(327/1252) done. Loss: 0.8498  lr:0.100000  network_time: 0.1014
[ Tue Feb  2 04:31:07 2021 ] 	Batch(427/1252) done. Loss: 0.5277  lr:0.100000  network_time: 0.0940
[ Tue Feb  2 04:31:30 2021 ] 	Batch(527/1252) done. Loss: 0.5966  lr:0.100000  network_time: 0.0800
[ Tue Feb  2 04:31:52 2021 ] 	Batch(627/1252) done. Loss: 0.7454  lr:0.100000  network_time: 0.0943
[ Tue Feb  2 04:32:14 2021 ] 	Batch(727/1252) done. Loss: 1.1942  lr:0.100000  network_time: 0.0787
[ Tue Feb  2 04:32:37 2021 ] 	Batch(827/1252) done. Loss: 0.6123  lr:0.100000  network_time: 0.0851
[ Tue Feb  2 04:32:59 2021 ] 	Batch(927/1252) done. Loss: 0.5994  lr:0.100000  network_time: 0.0837
[ Tue Feb  2 04:33:21 2021 ] 	Batch(1027/1252) done. Loss: 0.5560  lr:0.100000  network_time: 0.1007
[ Tue Feb  2 04:33:43 2021 ] 	Batch(1127/1252) done. Loss: 1.5136  lr:0.100000  network_time: 0.0852
[ Tue Feb  2 04:34:06 2021 ] 	Batch(1227/1252) done. Loss: 0.6255  lr:0.100000  network_time: 0.0854
[ Tue Feb  2 04:34:11 2021 ] Eval epoch: 12
[ Tue Feb  2 04:34:46 2021 ] 	Mean test loss of 258 batches: 0.8446759581565857.
[ Tue Feb  2 04:34:46 2021 ] 	Top1: 75.01%
[ Tue Feb  2 04:34:46 2021 ] 	Top5: 95.18%
[ Tue Feb  2 04:34:46 2021 ] Training epoch: 13
[ Tue Feb  2 04:35:06 2021 ] 	Batch(75/1252) done. Loss: 1.0975  lr:0.100000  network_time: 0.0795
[ Tue Feb  2 04:35:28 2021 ] 	Batch(175/1252) done. Loss: 0.7521  lr:0.100000  network_time: 0.0842
[ Tue Feb  2 04:35:50 2021 ] 	Batch(275/1252) done. Loss: 0.4377  lr:0.100000  network_time: 0.0800
[ Tue Feb  2 04:36:12 2021 ] 	Batch(375/1252) done. Loss: 0.6464  lr:0.100000  network_time: 0.0825
[ Tue Feb  2 04:36:34 2021 ] 	Batch(475/1252) done. Loss: 0.9305  lr:0.100000  network_time: 0.0947
[ Tue Feb  2 04:36:57 2021 ] 	Batch(575/1252) done. Loss: 0.4708  lr:0.100000  network_time: 0.1008
[ Tue Feb  2 04:37:19 2021 ] 	Batch(675/1252) done. Loss: 0.5203  lr:0.100000  network_time: 0.0890
[ Tue Feb  2 04:37:41 2021 ] 	Batch(775/1252) done. Loss: 0.7204  lr:0.100000  network_time: 0.0757
[ Tue Feb  2 04:38:03 2021 ] 	Batch(875/1252) done. Loss: 0.6618  lr:0.100000  network_time: 0.0892
[ Tue Feb  2 04:38:25 2021 ] 	Batch(975/1252) done. Loss: 0.5075  lr:0.100000  network_time: 0.1143
[ Tue Feb  2 04:38:48 2021 ] 	Batch(1075/1252) done. Loss: 0.8077  lr:0.100000  network_time: 0.0823
[ Tue Feb  2 04:39:10 2021 ] 	Batch(1175/1252) done. Loss: 0.8128  lr:0.100000  network_time: 0.0832
[ Tue Feb  2 04:39:27 2021 ] Eval epoch: 13
[ Tue Feb  2 04:40:01 2021 ] 	Mean test loss of 258 batches: 0.8514854311943054.
[ Tue Feb  2 04:40:01 2021 ] 	Top1: 74.94%
[ Tue Feb  2 04:40:01 2021 ] 	Top5: 95.07%
[ Tue Feb  2 04:40:01 2021 ] Training epoch: 14
[ Tue Feb  2 04:40:10 2021 ] 	Batch(23/1252) done. Loss: 0.7252  lr:0.100000  network_time: 0.0822
[ Tue Feb  2 04:40:32 2021 ] 	Batch(123/1252) done. Loss: 0.6999  lr:0.100000  network_time: 0.0798
[ Tue Feb  2 04:40:54 2021 ] 	Batch(223/1252) done. Loss: 0.8625  lr:0.100000  network_time: 0.0738
[ Tue Feb  2 04:41:16 2021 ] 	Batch(323/1252) done. Loss: 0.5953  lr:0.100000  network_time: 0.0819
[ Tue Feb  2 04:41:38 2021 ] 	Batch(423/1252) done. Loss: 0.9087  lr:0.100000  network_time: 0.0768
[ Tue Feb  2 04:42:00 2021 ] 	Batch(523/1252) done. Loss: 0.9450  lr:0.100000  network_time: 0.0792
[ Tue Feb  2 04:42:22 2021 ] 	Batch(623/1252) done. Loss: 0.8208  lr:0.100000  network_time: 0.0823
[ Tue Feb  2 04:42:45 2021 ] 	Batch(723/1252) done. Loss: 0.7442  lr:0.100000  network_time: 0.0800
[ Tue Feb  2 04:43:07 2021 ] 	Batch(823/1252) done. Loss: 0.4507  lr:0.100000  network_time: 0.0837
[ Tue Feb  2 04:43:29 2021 ] 	Batch(923/1252) done. Loss: 0.7184  lr:0.100000  network_time: 0.1015
[ Tue Feb  2 04:43:52 2021 ] 	Batch(1023/1252) done. Loss: 0.7740  lr:0.100000  network_time: 0.0961
[ Tue Feb  2 04:44:14 2021 ] 	Batch(1123/1252) done. Loss: 0.6136  lr:0.100000  network_time: 0.0973
[ Tue Feb  2 04:44:36 2021 ] 	Batch(1223/1252) done. Loss: 0.4073  lr:0.100000  network_time: 0.0807
[ Tue Feb  2 04:44:42 2021 ] Eval epoch: 14
[ Tue Feb  2 04:45:17 2021 ] 	Mean test loss of 258 batches: 0.8723755478858948.
[ Tue Feb  2 04:45:17 2021 ] 	Top1: 74.62%
[ Tue Feb  2 04:45:17 2021 ] 	Top5: 94.63%
[ Tue Feb  2 04:45:17 2021 ] Training epoch: 15
[ Tue Feb  2 04:45:36 2021 ] 	Batch(71/1252) done. Loss: 1.0352  lr:0.100000  network_time: 0.0832
[ Tue Feb  2 04:45:58 2021 ] 	Batch(171/1252) done. Loss: 0.8136  lr:0.100000  network_time: 0.0846
[ Tue Feb  2 04:46:21 2021 ] 	Batch(271/1252) done. Loss: 0.8315  lr:0.100000  network_time: 0.0712
[ Tue Feb  2 04:46:43 2021 ] 	Batch(371/1252) done. Loss: 0.6022  lr:0.100000  network_time: 0.0835
[ Tue Feb  2 04:47:05 2021 ] 	Batch(471/1252) done. Loss: 1.0836  lr:0.100000  network_time: 0.0823
[ Tue Feb  2 04:47:27 2021 ] 	Batch(571/1252) done. Loss: 0.8731  lr:0.100000  network_time: 0.0842
[ Tue Feb  2 04:47:49 2021 ] 	Batch(671/1252) done. Loss: 0.8534  lr:0.100000  network_time: 0.0926
[ Tue Feb  2 04:48:11 2021 ] 	Batch(771/1252) done. Loss: 1.2437  lr:0.100000  network_time: 0.0767
[ Tue Feb  2 04:48:33 2021 ] 	Batch(871/1252) done. Loss: 0.6140  lr:0.100000  network_time: 0.0826
[ Tue Feb  2 04:48:56 2021 ] 	Batch(971/1252) done. Loss: 0.6838  lr:0.100000  network_time: 0.0977
[ Tue Feb  2 04:49:18 2021 ] 	Batch(1071/1252) done. Loss: 0.6125  lr:0.100000  network_time: 0.0972
[ Tue Feb  2 04:49:40 2021 ] 	Batch(1171/1252) done. Loss: 0.7939  lr:0.100000  network_time: 0.0828
[ Tue Feb  2 04:49:58 2021 ] Eval epoch: 15
[ Tue Feb  2 04:50:32 2021 ] 	Mean test loss of 258 batches: 0.8343862295150757.
[ Tue Feb  2 04:50:32 2021 ] 	Top1: 74.87%
[ Tue Feb  2 04:50:32 2021 ] 	Top5: 95.11%
[ Tue Feb  2 04:50:32 2021 ] Training epoch: 16
[ Tue Feb  2 04:50:40 2021 ] 	Batch(19/1252) done. Loss: 0.5276  lr:0.100000  network_time: 0.0816
[ Tue Feb  2 04:51:02 2021 ] 	Batch(119/1252) done. Loss: 0.6616  lr:0.100000  network_time: 0.0794
[ Tue Feb  2 04:51:24 2021 ] 	Batch(219/1252) done. Loss: 0.9193  lr:0.100000  network_time: 0.0805
[ Tue Feb  2 04:51:46 2021 ] 	Batch(319/1252) done. Loss: 0.7380  lr:0.100000  network_time: 0.0842
[ Tue Feb  2 04:52:08 2021 ] 	Batch(419/1252) done. Loss: 0.9013  lr:0.100000  network_time: 0.0900
[ Tue Feb  2 04:52:30 2021 ] 	Batch(519/1252) done. Loss: 0.5403  lr:0.100000  network_time: 0.1009
[ Tue Feb  2 04:52:52 2021 ] 	Batch(619/1252) done. Loss: 0.5484  lr:0.100000  network_time: 0.0988
[ Tue Feb  2 04:53:14 2021 ] 	Batch(719/1252) done. Loss: 0.6672  lr:0.100000  network_time: 0.0864
[ Tue Feb  2 04:53:36 2021 ] 	Batch(819/1252) done. Loss: 0.6808  lr:0.100000  network_time: 0.0788
[ Tue Feb  2 04:53:58 2021 ] 	Batch(919/1252) done. Loss: 0.3206  lr:0.100000  network_time: 0.0911
[ Tue Feb  2 04:54:21 2021 ] 	Batch(1019/1252) done. Loss: 0.9369  lr:0.100000  network_time: 0.0880
[ Tue Feb  2 04:54:43 2021 ] 	Batch(1119/1252) done. Loss: 0.4725  lr:0.100000  network_time: 0.0799
[ Tue Feb  2 04:55:05 2021 ] 	Batch(1219/1252) done. Loss: 0.6015  lr:0.100000  network_time: 0.0761
[ Tue Feb  2 04:55:12 2021 ] Eval epoch: 16
[ Tue Feb  2 04:55:46 2021 ] 	Mean test loss of 258 batches: 0.8185447454452515.
[ Tue Feb  2 04:55:46 2021 ] 	Top1: 76.50%
[ Tue Feb  2 04:55:47 2021 ] 	Top5: 95.56%
[ Tue Feb  2 04:55:47 2021 ] Training epoch: 17
[ Tue Feb  2 04:56:05 2021 ] 	Batch(67/1252) done. Loss: 0.8319  lr:0.100000  network_time: 0.0814
[ Tue Feb  2 04:56:27 2021 ] 	Batch(167/1252) done. Loss: 0.4021  lr:0.100000  network_time: 0.0922
[ Tue Feb  2 04:56:49 2021 ] 	Batch(267/1252) done. Loss: 0.9078  lr:0.100000  network_time: 0.0752
[ Tue Feb  2 04:57:11 2021 ] 	Batch(367/1252) done. Loss: 0.7709  lr:0.100000  network_time: 0.0793
[ Tue Feb  2 04:57:33 2021 ] 	Batch(467/1252) done. Loss: 0.6939  lr:0.100000  network_time: 0.0799
[ Tue Feb  2 04:57:55 2021 ] 	Batch(567/1252) done. Loss: 0.9769  lr:0.100000  network_time: 0.0871
[ Tue Feb  2 04:58:17 2021 ] 	Batch(667/1252) done. Loss: 0.8283  lr:0.100000  network_time: 0.0895
[ Tue Feb  2 04:58:39 2021 ] 	Batch(767/1252) done. Loss: 0.9043  lr:0.100000  network_time: 0.0940
[ Tue Feb  2 04:59:01 2021 ] 	Batch(867/1252) done. Loss: 1.2002  lr:0.100000  network_time: 0.0851
[ Tue Feb  2 04:59:23 2021 ] 	Batch(967/1252) done. Loss: 0.5326  lr:0.100000  network_time: 0.0855
[ Tue Feb  2 04:59:45 2021 ] 	Batch(1067/1252) done. Loss: 0.8741  lr:0.100000  network_time: 0.0784
[ Tue Feb  2 05:00:07 2021 ] 	Batch(1167/1252) done. Loss: 0.5852  lr:0.100000  network_time: 0.0982
[ Tue Feb  2 05:00:26 2021 ] Eval epoch: 17
[ Tue Feb  2 05:01:00 2021 ] 	Mean test loss of 258 batches: 0.8161194324493408.
[ Tue Feb  2 05:01:00 2021 ] 	Top1: 75.33%
[ Tue Feb  2 05:01:00 2021 ] 	Top5: 94.89%
[ Tue Feb  2 05:01:00 2021 ] Training epoch: 18
[ Tue Feb  2 05:01:07 2021 ] 	Batch(15/1252) done. Loss: 0.8485  lr:0.100000  network_time: 0.0807
[ Tue Feb  2 05:01:29 2021 ] 	Batch(115/1252) done. Loss: 0.7878  lr:0.100000  network_time: 0.0859
[ Tue Feb  2 05:01:51 2021 ] 	Batch(215/1252) done. Loss: 0.7243  lr:0.100000  network_time: 0.0723
[ Tue Feb  2 05:02:13 2021 ] 	Batch(315/1252) done. Loss: 0.7652  lr:0.100000  network_time: 0.1031
[ Tue Feb  2 05:02:35 2021 ] 	Batch(415/1252) done. Loss: 1.0692  lr:0.100000  network_time: 0.1001
[ Tue Feb  2 05:02:57 2021 ] 	Batch(515/1252) done. Loss: 0.4695  lr:0.100000  network_time: 0.1000
[ Tue Feb  2 05:03:19 2021 ] 	Batch(615/1252) done. Loss: 0.7895  lr:0.100000  network_time: 0.0841
[ Tue Feb  2 05:03:41 2021 ] 	Batch(715/1252) done. Loss: 0.6229  lr:0.100000  network_time: 0.0744
[ Tue Feb  2 05:04:03 2021 ] 	Batch(815/1252) done. Loss: 0.5559  lr:0.100000  network_time: 0.1016
[ Tue Feb  2 05:04:26 2021 ] 	Batch(915/1252) done. Loss: 0.3888  lr:0.100000  network_time: 0.0828
[ Tue Feb  2 05:04:48 2021 ] 	Batch(1015/1252) done. Loss: 0.7910  lr:0.100000  network_time: 0.0795
[ Tue Feb  2 05:05:10 2021 ] 	Batch(1115/1252) done. Loss: 0.4318  lr:0.100000  network_time: 0.1042
[ Tue Feb  2 05:05:33 2021 ] 	Batch(1215/1252) done. Loss: 1.0380  lr:0.100000  network_time: 0.0851
[ Tue Feb  2 05:05:41 2021 ] Eval epoch: 18
[ Tue Feb  2 05:06:15 2021 ] 	Mean test loss of 258 batches: 0.7666910886764526.
[ Tue Feb  2 05:06:15 2021 ] 	Top1: 76.99%
[ Tue Feb  2 05:06:15 2021 ] 	Top5: 95.83%
[ Tue Feb  2 05:06:15 2021 ] Training epoch: 19
[ Tue Feb  2 05:06:33 2021 ] 	Batch(63/1252) done. Loss: 0.4763  lr:0.100000  network_time: 0.0824
[ Tue Feb  2 05:06:55 2021 ] 	Batch(163/1252) done. Loss: 0.2368  lr:0.100000  network_time: 0.0858
[ Tue Feb  2 05:07:17 2021 ] 	Batch(263/1252) done. Loss: 0.5620  lr:0.100000  network_time: 0.1021
[ Tue Feb  2 05:07:39 2021 ] 	Batch(363/1252) done. Loss: 0.8413  lr:0.100000  network_time: 0.0805
[ Tue Feb  2 05:08:01 2021 ] 	Batch(463/1252) done. Loss: 0.6264  lr:0.100000  network_time: 0.0710
[ Tue Feb  2 05:08:24 2021 ] 	Batch(563/1252) done. Loss: 0.6165  lr:0.100000  network_time: 0.0775
[ Tue Feb  2 05:08:46 2021 ] 	Batch(663/1252) done. Loss: 0.9906  lr:0.100000  network_time: 0.0939
[ Tue Feb  2 05:09:08 2021 ] 	Batch(763/1252) done. Loss: 0.3915  lr:0.100000  network_time: 0.0770
[ Tue Feb  2 05:09:31 2021 ] 	Batch(863/1252) done. Loss: 0.7615  lr:0.100000  network_time: 0.0883
[ Tue Feb  2 05:09:53 2021 ] 	Batch(963/1252) done. Loss: 0.6312  lr:0.100000  network_time: 0.0823
[ Tue Feb  2 05:10:15 2021 ] 	Batch(1063/1252) done. Loss: 0.7554  lr:0.100000  network_time: 0.0906
[ Tue Feb  2 05:10:37 2021 ] 	Batch(1163/1252) done. Loss: 0.8927  lr:0.100000  network_time: 0.0850
[ Tue Feb  2 05:10:57 2021 ] Eval epoch: 19
[ Tue Feb  2 05:11:32 2021 ] 	Mean test loss of 258 batches: 0.9004268050193787.
[ Tue Feb  2 05:11:32 2021 ] 	Top1: 74.38%
[ Tue Feb  2 05:11:32 2021 ] 	Top5: 94.66%
[ Tue Feb  2 05:11:32 2021 ] Training epoch: 20
[ Tue Feb  2 05:11:38 2021 ] 	Batch(11/1252) done. Loss: 0.9293  lr:0.100000  network_time: 0.0860
[ Tue Feb  2 05:12:00 2021 ] 	Batch(111/1252) done. Loss: 0.6458  lr:0.100000  network_time: 0.0759
[ Tue Feb  2 05:12:23 2021 ] 	Batch(211/1252) done. Loss: 0.6643  lr:0.100000  network_time: 0.0757
[ Tue Feb  2 05:12:45 2021 ] 	Batch(311/1252) done. Loss: 0.6558  lr:0.100000  network_time: 0.0836
[ Tue Feb  2 05:13:07 2021 ] 	Batch(411/1252) done. Loss: 0.9052  lr:0.100000  network_time: 0.0848
[ Tue Feb  2 05:13:29 2021 ] 	Batch(511/1252) done. Loss: 0.8900  lr:0.100000  network_time: 0.0997
[ Tue Feb  2 05:13:51 2021 ] 	Batch(611/1252) done. Loss: 0.9540  lr:0.100000  network_time: 0.0876
[ Tue Feb  2 05:14:13 2021 ] 	Batch(711/1252) done. Loss: 0.5381  lr:0.100000  network_time: 0.0824
[ Tue Feb  2 05:14:35 2021 ] 	Batch(811/1252) done. Loss: 0.3986  lr:0.100000  network_time: 0.0838
[ Tue Feb  2 05:14:56 2021 ] 	Batch(911/1252) done. Loss: 0.4550  lr:0.100000  network_time: 0.0882
[ Tue Feb  2 05:15:18 2021 ] 	Batch(1011/1252) done. Loss: 1.1357  lr:0.100000  network_time: 0.0781
[ Tue Feb  2 05:15:40 2021 ] 	Batch(1111/1252) done. Loss: 1.2918  lr:0.100000  network_time: 0.0873
[ Tue Feb  2 05:16:02 2021 ] 	Batch(1211/1252) done. Loss: 0.7328  lr:0.100000  network_time: 0.0863
[ Tue Feb  2 05:16:11 2021 ] Eval epoch: 20
[ Tue Feb  2 05:16:44 2021 ] 	Mean test loss of 258 batches: 0.9113460779190063.
[ Tue Feb  2 05:16:44 2021 ] 	Top1: 74.75%
[ Tue Feb  2 05:16:44 2021 ] 	Top5: 94.63%
[ Tue Feb  2 05:16:44 2021 ] Training epoch: 21
[ Tue Feb  2 05:17:01 2021 ] 	Batch(59/1252) done. Loss: 0.9113  lr:0.100000  network_time: 0.0817
[ Tue Feb  2 05:17:23 2021 ] 	Batch(159/1252) done. Loss: 0.8377  lr:0.100000  network_time: 0.0699
[ Tue Feb  2 05:17:44 2021 ] 	Batch(259/1252) done. Loss: 0.4152  lr:0.100000  network_time: 0.0816
[ Tue Feb  2 05:18:06 2021 ] 	Batch(359/1252) done. Loss: 0.8204  lr:0.100000  network_time: 0.0985
[ Tue Feb  2 05:18:28 2021 ] 	Batch(459/1252) done. Loss: 0.4353  lr:0.100000  network_time: 0.1054
[ Tue Feb  2 05:18:50 2021 ] 	Batch(559/1252) done. Loss: 0.5617  lr:0.100000  network_time: 0.0769
[ Tue Feb  2 05:19:11 2021 ] 	Batch(659/1252) done. Loss: 0.8923  lr:0.100000  network_time: 0.0987
[ Tue Feb  2 05:19:33 2021 ] 	Batch(759/1252) done. Loss: 0.7259  lr:0.100000  network_time: 0.0899
[ Tue Feb  2 05:19:55 2021 ] 	Batch(859/1252) done. Loss: 0.5800  lr:0.100000  network_time: 0.0771
[ Tue Feb  2 05:20:17 2021 ] 	Batch(959/1252) done. Loss: 0.5311  lr:0.100000  network_time: 0.0862
[ Tue Feb  2 05:20:39 2021 ] 	Batch(1059/1252) done. Loss: 0.6275  lr:0.100000  network_time: 0.0824
[ Tue Feb  2 05:21:01 2021 ] 	Batch(1159/1252) done. Loss: 0.8749  lr:0.100000  network_time: 0.0800
[ Tue Feb  2 05:21:21 2021 ] Eval epoch: 21
[ Tue Feb  2 05:21:55 2021 ] 	Mean test loss of 258 batches: 0.8532718420028687.
[ Tue Feb  2 05:21:55 2021 ] 	Top1: 74.33%
[ Tue Feb  2 05:21:55 2021 ] 	Top5: 95.08%
[ Tue Feb  2 05:21:55 2021 ] Training epoch: 22
[ Tue Feb  2 05:22:00 2021 ] 	Batch(7/1252) done. Loss: 0.7139  lr:0.100000  network_time: 0.0853
[ Tue Feb  2 05:22:22 2021 ] 	Batch(107/1252) done. Loss: 0.9508  lr:0.100000  network_time: 0.0818
[ Tue Feb  2 05:22:44 2021 ] 	Batch(207/1252) done. Loss: 0.5217  lr:0.100000  network_time: 0.0947
[ Tue Feb  2 05:23:06 2021 ] 	Batch(307/1252) done. Loss: 1.1012  lr:0.100000  network_time: 0.0792
[ Tue Feb  2 05:23:28 2021 ] 	Batch(407/1252) done. Loss: 0.4365  lr:0.100000  network_time: 0.0917
[ Tue Feb  2 05:23:50 2021 ] 	Batch(507/1252) done. Loss: 0.6686  lr:0.100000  network_time: 0.0964
[ Tue Feb  2 05:24:12 2021 ] 	Batch(607/1252) done. Loss: 0.7833  lr:0.100000  network_time: 0.0833
[ Tue Feb  2 05:24:34 2021 ] 	Batch(707/1252) done. Loss: 0.2324  lr:0.100000  network_time: 0.0774
[ Tue Feb  2 05:24:56 2021 ] 	Batch(807/1252) done. Loss: 0.4423  lr:0.100000  network_time: 0.0749
[ Tue Feb  2 05:25:18 2021 ] 	Batch(907/1252) done. Loss: 0.6017  lr:0.100000  network_time: 0.0850
[ Tue Feb  2 05:25:39 2021 ] 	Batch(1007/1252) done. Loss: 0.5623  lr:0.100000  network_time: 0.0841
[ Tue Feb  2 05:26:01 2021 ] 	Batch(1107/1252) done. Loss: 0.6859  lr:0.100000  network_time: 0.0799
[ Tue Feb  2 05:26:23 2021 ] 	Batch(1207/1252) done. Loss: 0.4821  lr:0.100000  network_time: 0.0866
[ Tue Feb  2 05:26:33 2021 ] Eval epoch: 22
[ Tue Feb  2 05:27:06 2021 ] 	Mean test loss of 258 batches: 0.8524452447891235.
[ Tue Feb  2 05:27:07 2021 ] 	Top1: 75.22%
[ Tue Feb  2 05:27:07 2021 ] 	Top5: 95.09%
[ Tue Feb  2 05:27:07 2021 ] Training epoch: 23
[ Tue Feb  2 05:27:22 2021 ] 	Batch(55/1252) done. Loss: 0.3405  lr:0.100000  network_time: 0.0800
[ Tue Feb  2 05:27:43 2021 ] 	Batch(155/1252) done. Loss: 0.6146  lr:0.100000  network_time: 0.0905
[ Tue Feb  2 05:28:05 2021 ] 	Batch(255/1252) done. Loss: 0.8540  lr:0.100000  network_time: 0.0871
[ Tue Feb  2 05:28:27 2021 ] 	Batch(355/1252) done. Loss: 0.4654  lr:0.100000  network_time: 0.0856
[ Tue Feb  2 05:28:49 2021 ] 	Batch(455/1252) done. Loss: 0.6156  lr:0.100000  network_time: 0.0791
[ Tue Feb  2 05:29:10 2021 ] 	Batch(555/1252) done. Loss: 0.3979  lr:0.100000  network_time: 0.0936
[ Tue Feb  2 05:29:32 2021 ] 	Batch(655/1252) done. Loss: 0.7479  lr:0.100000  network_time: 0.0837
[ Tue Feb  2 05:29:54 2021 ] 	Batch(755/1252) done. Loss: 0.6028  lr:0.100000  network_time: 0.0870
[ Tue Feb  2 05:30:16 2021 ] 	Batch(855/1252) done. Loss: 0.7728  lr:0.100000  network_time: 0.0829
[ Tue Feb  2 05:30:37 2021 ] 	Batch(955/1252) done. Loss: 0.4994  lr:0.100000  network_time: 0.0820
[ Tue Feb  2 05:30:59 2021 ] 	Batch(1055/1252) done. Loss: 0.6440  lr:0.100000  network_time: 0.0746
[ Tue Feb  2 05:31:21 2021 ] 	Batch(1155/1252) done. Loss: 0.5764  lr:0.100000  network_time: 0.0713
[ Tue Feb  2 05:31:42 2021 ] Eval epoch: 23
[ Tue Feb  2 05:32:16 2021 ] 	Mean test loss of 258 batches: 0.7870496511459351.
[ Tue Feb  2 05:32:16 2021 ] 	Top1: 76.77%
[ Tue Feb  2 05:32:16 2021 ] 	Top5: 95.65%
[ Tue Feb  2 05:32:16 2021 ] Training epoch: 24
[ Tue Feb  2 05:32:20 2021 ] 	Batch(3/1252) done. Loss: 0.7278  lr:0.100000  network_time: 0.0812
[ Tue Feb  2 05:32:42 2021 ] 	Batch(103/1252) done. Loss: 0.5805  lr:0.100000  network_time: 0.0856
[ Tue Feb  2 05:33:04 2021 ] 	Batch(203/1252) done. Loss: 0.6687  lr:0.100000  network_time: 0.0842
[ Tue Feb  2 05:33:26 2021 ] 	Batch(303/1252) done. Loss: 0.6058  lr:0.100000  network_time: 0.0778
[ Tue Feb  2 05:33:48 2021 ] 	Batch(403/1252) done. Loss: 0.5773  lr:0.100000  network_time: 0.0683
[ Tue Feb  2 05:34:10 2021 ] 	Batch(503/1252) done. Loss: 0.6715  lr:0.100000  network_time: 0.0888
[ Tue Feb  2 05:34:32 2021 ] 	Batch(603/1252) done. Loss: 0.6206  lr:0.100000  network_time: 0.0854
[ Tue Feb  2 05:34:54 2021 ] 	Batch(703/1252) done. Loss: 0.6731  lr:0.100000  network_time: 0.0840
[ Tue Feb  2 05:35:17 2021 ] 	Batch(803/1252) done. Loss: 0.5712  lr:0.100000  network_time: 0.0893
[ Tue Feb  2 05:35:38 2021 ] 	Batch(903/1252) done. Loss: 0.5176  lr:0.100000  network_time: 0.0858
[ Tue Feb  2 05:36:01 2021 ] 	Batch(1003/1252) done. Loss: 0.3089  lr:0.100000  network_time: 0.0814
[ Tue Feb  2 05:36:23 2021 ] 	Batch(1103/1252) done. Loss: 0.3628  lr:0.100000  network_time: 0.0762
[ Tue Feb  2 05:36:45 2021 ] 	Batch(1203/1252) done. Loss: 0.5054  lr:0.100000  network_time: 0.0875
[ Tue Feb  2 05:36:56 2021 ] Eval epoch: 24
[ Tue Feb  2 05:37:30 2021 ] 	Mean test loss of 258 batches: 0.8020290732383728.
[ Tue Feb  2 05:37:30 2021 ] 	Top1: 76.58%
[ Tue Feb  2 05:37:30 2021 ] 	Top5: 95.49%
[ Tue Feb  2 05:37:30 2021 ] Training epoch: 25
[ Tue Feb  2 05:37:44 2021 ] 	Batch(51/1252) done. Loss: 0.8028  lr:0.100000  network_time: 0.0855
[ Tue Feb  2 05:38:06 2021 ] 	Batch(151/1252) done. Loss: 0.2159  lr:0.100000  network_time: 0.0798
[ Tue Feb  2 05:38:28 2021 ] 	Batch(251/1252) done. Loss: 0.6370  lr:0.100000  network_time: 0.1016
[ Tue Feb  2 05:38:50 2021 ] 	Batch(351/1252) done. Loss: 0.2616  lr:0.100000  network_time: 0.0809
[ Tue Feb  2 05:39:12 2021 ] 	Batch(451/1252) done. Loss: 0.5482  lr:0.100000  network_time: 0.0812
[ Tue Feb  2 05:39:34 2021 ] 	Batch(551/1252) done. Loss: 0.3426  lr:0.100000  network_time: 0.0833
[ Tue Feb  2 05:39:56 2021 ] 	Batch(651/1252) done. Loss: 0.3648  lr:0.100000  network_time: 0.0827
[ Tue Feb  2 05:40:18 2021 ] 	Batch(751/1252) done. Loss: 0.3608  lr:0.100000  network_time: 0.0734
[ Tue Feb  2 05:40:40 2021 ] 	Batch(851/1252) done. Loss: 0.4580  lr:0.100000  network_time: 0.0900
[ Tue Feb  2 05:41:02 2021 ] 	Batch(951/1252) done. Loss: 0.5253  lr:0.100000  network_time: 0.0736
[ Tue Feb  2 05:41:24 2021 ] 	Batch(1051/1252) done. Loss: 0.3072  lr:0.100000  network_time: 0.0790
[ Tue Feb  2 05:41:46 2021 ] 	Batch(1151/1252) done. Loss: 0.6359  lr:0.100000  network_time: 0.0804
[ Tue Feb  2 05:42:08 2021 ] 	Batch(1251/1252) done. Loss: 0.5157  lr:0.100000  network_time: 0.0897
[ Tue Feb  2 05:42:09 2021 ] Eval epoch: 25
[ Tue Feb  2 05:42:43 2021 ] 	Mean test loss of 258 batches: 0.7530568242073059.
[ Tue Feb  2 05:42:43 2021 ] 	Top1: 77.87%
[ Tue Feb  2 05:42:43 2021 ] 	Top5: 95.71%
[ Tue Feb  2 05:42:43 2021 ] Training epoch: 26
[ Tue Feb  2 05:43:08 2021 ] 	Batch(99/1252) done. Loss: 0.4472  lr:0.100000  network_time: 0.0901
[ Tue Feb  2 05:43:30 2021 ] 	Batch(199/1252) done. Loss: 0.4209  lr:0.100000  network_time: 0.0836
[ Tue Feb  2 05:43:52 2021 ] 	Batch(299/1252) done. Loss: 0.5963  lr:0.100000  network_time: 0.0808
[ Tue Feb  2 05:44:14 2021 ] 	Batch(399/1252) done. Loss: 0.4352  lr:0.100000  network_time: 0.0942
[ Tue Feb  2 05:44:36 2021 ] 	Batch(499/1252) done. Loss: 0.9768  lr:0.100000  network_time: 0.0869
[ Tue Feb  2 05:44:58 2021 ] 	Batch(599/1252) done. Loss: 0.6779  lr:0.100000  network_time: 0.0767
[ Tue Feb  2 05:45:20 2021 ] 	Batch(699/1252) done. Loss: 0.3822  lr:0.100000  network_time: 0.0889
[ Tue Feb  2 05:45:42 2021 ] 	Batch(799/1252) done. Loss: 0.4592  lr:0.100000  network_time: 0.0900
[ Tue Feb  2 05:46:04 2021 ] 	Batch(899/1252) done. Loss: 0.4522  lr:0.100000  network_time: 0.0864
[ Tue Feb  2 05:46:26 2021 ] 	Batch(999/1252) done. Loss: 0.7631  lr:0.100000  network_time: 0.0838
[ Tue Feb  2 05:46:48 2021 ] 	Batch(1099/1252) done. Loss: 0.6268  lr:0.100000  network_time: 0.0935
[ Tue Feb  2 05:47:09 2021 ] 	Batch(1199/1252) done. Loss: 0.4703  lr:0.100000  network_time: 0.0766
[ Tue Feb  2 05:47:21 2021 ] Eval epoch: 26
[ Tue Feb  2 05:47:55 2021 ] 	Mean test loss of 258 batches: 0.7661088109016418.
[ Tue Feb  2 05:47:55 2021 ] 	Top1: 77.16%
[ Tue Feb  2 05:47:55 2021 ] 	Top5: 95.52%
[ Tue Feb  2 05:47:55 2021 ] Training epoch: 27
[ Tue Feb  2 05:48:09 2021 ] 	Batch(47/1252) done. Loss: 0.6838  lr:0.100000  network_time: 0.0722
[ Tue Feb  2 05:48:31 2021 ] 	Batch(147/1252) done. Loss: 0.4894  lr:0.100000  network_time: 0.0850
[ Tue Feb  2 05:48:52 2021 ] 	Batch(247/1252) done. Loss: 0.8821  lr:0.100000  network_time: 0.0685
[ Tue Feb  2 05:49:14 2021 ] 	Batch(347/1252) done. Loss: 0.3960  lr:0.100000  network_time: 0.0859
[ Tue Feb  2 05:49:36 2021 ] 	Batch(447/1252) done. Loss: 0.5068  lr:0.100000  network_time: 0.0827
[ Tue Feb  2 05:49:58 2021 ] 	Batch(547/1252) done. Loss: 0.5321  lr:0.100000  network_time: 0.0923
[ Tue Feb  2 05:50:20 2021 ] 	Batch(647/1252) done. Loss: 0.7706  lr:0.100000  network_time: 0.0845
[ Tue Feb  2 05:50:42 2021 ] 	Batch(747/1252) done. Loss: 0.6324  lr:0.100000  network_time: 0.0808
[ Tue Feb  2 05:51:04 2021 ] 	Batch(847/1252) done. Loss: 0.3603  lr:0.100000  network_time: 0.0820
[ Tue Feb  2 05:51:26 2021 ] 	Batch(947/1252) done. Loss: 0.7101  lr:0.100000  network_time: 0.0875
[ Tue Feb  2 05:51:48 2021 ] 	Batch(1047/1252) done. Loss: 0.4570  lr:0.100000  network_time: 0.0851
[ Tue Feb  2 05:52:10 2021 ] 	Batch(1147/1252) done. Loss: 0.9074  lr:0.100000  network_time: 0.0980
[ Tue Feb  2 05:52:32 2021 ] 	Batch(1247/1252) done. Loss: 0.7420  lr:0.100000  network_time: 0.0798
[ Tue Feb  2 05:52:33 2021 ] Eval epoch: 27
[ Tue Feb  2 05:53:07 2021 ] 	Mean test loss of 258 batches: 0.8899829387664795.
[ Tue Feb  2 05:53:07 2021 ] 	Top1: 74.49%
[ Tue Feb  2 05:53:07 2021 ] 	Top5: 94.64%
[ Tue Feb  2 05:53:07 2021 ] Training epoch: 28
[ Tue Feb  2 05:53:31 2021 ] 	Batch(95/1252) done. Loss: 0.6591  lr:0.100000  network_time: 0.0847
[ Tue Feb  2 05:53:53 2021 ] 	Batch(195/1252) done. Loss: 0.3659  lr:0.100000  network_time: 0.0893
[ Tue Feb  2 05:54:15 2021 ] 	Batch(295/1252) done. Loss: 0.6754  lr:0.100000  network_time: 0.0822
[ Tue Feb  2 05:54:37 2021 ] 	Batch(395/1252) done. Loss: 0.7499  lr:0.100000  network_time: 0.1011
[ Tue Feb  2 05:54:59 2021 ] 	Batch(495/1252) done. Loss: 0.5738  lr:0.100000  network_time: 0.0843
[ Tue Feb  2 05:55:21 2021 ] 	Batch(595/1252) done. Loss: 0.5768  lr:0.100000  network_time: 0.0834
[ Tue Feb  2 05:55:43 2021 ] 	Batch(695/1252) done. Loss: 0.6689  lr:0.100000  network_time: 0.0761
[ Tue Feb  2 05:56:04 2021 ] 	Batch(795/1252) done. Loss: 0.4408  lr:0.100000  network_time: 0.0890
[ Tue Feb  2 05:56:26 2021 ] 	Batch(895/1252) done. Loss: 0.6061  lr:0.100000  network_time: 0.0799
[ Tue Feb  2 05:56:48 2021 ] 	Batch(995/1252) done. Loss: 0.7515  lr:0.100000  network_time: 0.0926
[ Tue Feb  2 05:57:10 2021 ] 	Batch(1095/1252) done. Loss: 0.3545  lr:0.100000  network_time: 0.0781
[ Tue Feb  2 05:57:32 2021 ] 	Batch(1195/1252) done. Loss: 0.4648  lr:0.100000  network_time: 0.0874
[ Tue Feb  2 05:57:45 2021 ] Eval epoch: 28
[ Tue Feb  2 05:58:19 2021 ] 	Mean test loss of 258 batches: 0.7718104720115662.
[ Tue Feb  2 05:58:19 2021 ] 	Top1: 77.04%
[ Tue Feb  2 05:58:19 2021 ] 	Top5: 96.02%
[ Tue Feb  2 05:58:19 2021 ] Training epoch: 29
[ Tue Feb  2 05:58:31 2021 ] 	Batch(43/1252) done. Loss: 0.8308  lr:0.100000  network_time: 0.0832
[ Tue Feb  2 05:58:53 2021 ] 	Batch(143/1252) done. Loss: 0.9753  lr:0.100000  network_time: 0.0848
[ Tue Feb  2 05:59:16 2021 ] 	Batch(243/1252) done. Loss: 0.5583  lr:0.100000  network_time: 0.0864
[ Tue Feb  2 05:59:38 2021 ] 	Batch(343/1252) done. Loss: 0.4214  lr:0.100000  network_time: 0.0855
[ Tue Feb  2 06:00:00 2021 ] 	Batch(443/1252) done. Loss: 0.4987  lr:0.100000  network_time: 0.0879
[ Tue Feb  2 06:00:22 2021 ] 	Batch(543/1252) done. Loss: 0.6969  lr:0.100000  network_time: 0.0853
[ Tue Feb  2 06:00:43 2021 ] 	Batch(643/1252) done. Loss: 0.6690  lr:0.100000  network_time: 0.0857
[ Tue Feb  2 06:01:05 2021 ] 	Batch(743/1252) done. Loss: 0.3292  lr:0.100000  network_time: 0.0836
[ Tue Feb  2 06:01:27 2021 ] 	Batch(843/1252) done. Loss: 0.5167  lr:0.100000  network_time: 0.0832
[ Tue Feb  2 06:01:49 2021 ] 	Batch(943/1252) done. Loss: 0.6608  lr:0.100000  network_time: 0.0837
[ Tue Feb  2 06:02:11 2021 ] 	Batch(1043/1252) done. Loss: 0.5110  lr:0.100000  network_time: 0.0811
[ Tue Feb  2 06:02:33 2021 ] 	Batch(1143/1252) done. Loss: 1.0390  lr:0.100000  network_time: 0.0882
[ Tue Feb  2 06:02:55 2021 ] 	Batch(1243/1252) done. Loss: 0.5317  lr:0.100000  network_time: 0.0913
[ Tue Feb  2 06:02:57 2021 ] Eval epoch: 29
[ Tue Feb  2 06:03:31 2021 ] 	Mean test loss of 258 batches: 0.757035493850708.
[ Tue Feb  2 06:03:31 2021 ] 	Top1: 77.39%
[ Tue Feb  2 06:03:31 2021 ] 	Top5: 95.81%
[ Tue Feb  2 06:03:31 2021 ] Training epoch: 30
[ Tue Feb  2 06:03:54 2021 ] 	Batch(91/1252) done. Loss: 0.4374  lr:0.100000  network_time: 0.0885
[ Tue Feb  2 06:04:16 2021 ] 	Batch(191/1252) done. Loss: 0.4436  lr:0.100000  network_time: 0.0909
[ Tue Feb  2 06:04:38 2021 ] 	Batch(291/1252) done. Loss: 0.4914  lr:0.100000  network_time: 0.0911
[ Tue Feb  2 06:05:01 2021 ] 	Batch(391/1252) done. Loss: 0.4129  lr:0.100000  network_time: 0.0867
[ Tue Feb  2 06:05:23 2021 ] 	Batch(491/1252) done. Loss: 0.7119  lr:0.100000  network_time: 0.0916
[ Tue Feb  2 06:05:45 2021 ] 	Batch(591/1252) done. Loss: 0.5376  lr:0.100000  network_time: 0.0757
[ Tue Feb  2 06:06:07 2021 ] 	Batch(691/1252) done. Loss: 0.6053  lr:0.100000  network_time: 0.0977
[ Tue Feb  2 06:06:29 2021 ] 	Batch(791/1252) done. Loss: 0.2872  lr:0.100000  network_time: 0.0838
[ Tue Feb  2 06:06:52 2021 ] 	Batch(891/1252) done. Loss: 0.7410  lr:0.100000  network_time: 0.0847
[ Tue Feb  2 06:07:15 2021 ] 	Batch(991/1252) done. Loss: 0.5398  lr:0.100000  network_time: 0.0917
[ Tue Feb  2 06:07:39 2021 ] 	Batch(1091/1252) done. Loss: 0.6195  lr:0.100000  network_time: 0.0790
[ Tue Feb  2 06:08:02 2021 ] 	Batch(1191/1252) done. Loss: 0.4485  lr:0.100000  network_time: 0.0816
[ Tue Feb  2 06:08:15 2021 ] Eval epoch: 30
[ Tue Feb  2 06:08:51 2021 ] 	Mean test loss of 258 batches: 0.8029689192771912.
[ Tue Feb  2 06:08:51 2021 ] 	Top1: 76.79%
[ Tue Feb  2 06:08:51 2021 ] 	Top5: 95.50%
[ Tue Feb  2 06:08:51 2021 ] Training epoch: 31
[ Tue Feb  2 06:09:04 2021 ] 	Batch(39/1252) done. Loss: 0.6077  lr:0.100000  network_time: 0.0762
[ Tue Feb  2 06:09:26 2021 ] 	Batch(139/1252) done. Loss: 0.5551  lr:0.100000  network_time: 0.1054
[ Tue Feb  2 06:09:50 2021 ] 	Batch(239/1252) done. Loss: 0.4016  lr:0.100000  network_time: 0.0896
[ Tue Feb  2 06:10:13 2021 ] 	Batch(339/1252) done. Loss: 0.4711  lr:0.100000  network_time: 0.0807
[ Tue Feb  2 06:10:35 2021 ] 	Batch(439/1252) done. Loss: 1.0114  lr:0.100000  network_time: 0.0838
[ Tue Feb  2 06:10:58 2021 ] 	Batch(539/1252) done. Loss: 0.4620  lr:0.100000  network_time: 0.0900
[ Tue Feb  2 06:11:21 2021 ] 	Batch(639/1252) done. Loss: 0.4847  lr:0.100000  network_time: 0.0871
[ Tue Feb  2 06:11:44 2021 ] 	Batch(739/1252) done. Loss: 0.8126  lr:0.100000  network_time: 0.0803
[ Tue Feb  2 06:12:07 2021 ] 	Batch(839/1252) done. Loss: 0.9519  lr:0.100000  network_time: 0.0878
[ Tue Feb  2 06:12:31 2021 ] 	Batch(939/1252) done. Loss: 0.5325  lr:0.100000  network_time: 0.0868
[ Tue Feb  2 06:12:54 2021 ] 	Batch(1039/1252) done. Loss: 0.5445  lr:0.100000  network_time: 0.0835
[ Tue Feb  2 06:13:17 2021 ] 	Batch(1139/1252) done. Loss: 0.4884  lr:0.100000  network_time: 0.1012
[ Tue Feb  2 06:13:40 2021 ] 	Batch(1239/1252) done. Loss: 0.6194  lr:0.100000  network_time: 0.0814
[ Tue Feb  2 06:13:43 2021 ] Eval epoch: 31
[ Tue Feb  2 06:14:18 2021 ] 	Mean test loss of 258 batches: 0.7843804359436035.
[ Tue Feb  2 06:14:18 2021 ] 	Top1: 76.50%
[ Tue Feb  2 06:14:18 2021 ] 	Top5: 96.10%
[ Tue Feb  2 06:14:18 2021 ] Training epoch: 32
[ Tue Feb  2 06:14:41 2021 ] 	Batch(87/1252) done. Loss: 0.6062  lr:0.100000  network_time: 0.0849
[ Tue Feb  2 06:15:04 2021 ] 	Batch(187/1252) done. Loss: 0.3924  lr:0.100000  network_time: 0.0754
[ Tue Feb  2 06:15:27 2021 ] 	Batch(287/1252) done. Loss: 0.6622  lr:0.100000  network_time: 0.0870
[ Tue Feb  2 06:15:50 2021 ] 	Batch(387/1252) done. Loss: 0.6811  lr:0.100000  network_time: 0.0821
[ Tue Feb  2 06:16:13 2021 ] 	Batch(487/1252) done. Loss: 0.5803  lr:0.100000  network_time: 0.0877
[ Tue Feb  2 06:16:36 2021 ] 	Batch(587/1252) done. Loss: 0.5695  lr:0.100000  network_time: 0.0802
[ Tue Feb  2 06:16:59 2021 ] 	Batch(687/1252) done. Loss: 0.3707  lr:0.100000  network_time: 0.0819
[ Tue Feb  2 06:17:21 2021 ] 	Batch(787/1252) done. Loss: 0.8708  lr:0.100000  network_time: 0.0811
[ Tue Feb  2 06:17:43 2021 ] 	Batch(887/1252) done. Loss: 0.4733  lr:0.100000  network_time: 0.0822
[ Tue Feb  2 06:18:05 2021 ] 	Batch(987/1252) done. Loss: 0.4222  lr:0.100000  network_time: 0.0712
[ Tue Feb  2 06:18:26 2021 ] 	Batch(1087/1252) done. Loss: 0.3154  lr:0.100000  network_time: 0.1071
[ Tue Feb  2 06:18:48 2021 ] 	Batch(1187/1252) done. Loss: 0.4502  lr:0.100000  network_time: 0.0844
[ Tue Feb  2 06:19:03 2021 ] Eval epoch: 32
[ Tue Feb  2 06:19:36 2021 ] 	Mean test loss of 258 batches: 0.7833595275878906.
[ Tue Feb  2 06:19:36 2021 ] 	Top1: 77.21%
[ Tue Feb  2 06:19:36 2021 ] 	Top5: 95.95%
[ Tue Feb  2 06:19:37 2021 ] Training epoch: 33
[ Tue Feb  2 06:19:47 2021 ] 	Batch(35/1252) done. Loss: 0.5483  lr:0.100000  network_time: 0.1126
[ Tue Feb  2 06:20:09 2021 ] 	Batch(135/1252) done. Loss: 0.5784  lr:0.100000  network_time: 0.0911
[ Tue Feb  2 06:20:31 2021 ] 	Batch(235/1252) done. Loss: 0.3575  lr:0.100000  network_time: 0.0817
[ Tue Feb  2 06:20:53 2021 ] 	Batch(335/1252) done. Loss: 0.4513  lr:0.100000  network_time: 0.0835
[ Tue Feb  2 06:21:15 2021 ] 	Batch(435/1252) done. Loss: 0.7129  lr:0.100000  network_time: 0.0984
[ Tue Feb  2 06:21:37 2021 ] 	Batch(535/1252) done. Loss: 0.6470  lr:0.100000  network_time: 0.0906
[ Tue Feb  2 06:21:59 2021 ] 	Batch(635/1252) done. Loss: 0.4176  lr:0.100000  network_time: 0.0999
[ Tue Feb  2 06:22:21 2021 ] 	Batch(735/1252) done. Loss: 0.8777  lr:0.100000  network_time: 0.0758
[ Tue Feb  2 06:22:43 2021 ] 	Batch(835/1252) done. Loss: 0.7132  lr:0.100000  network_time: 0.0704
[ Tue Feb  2 06:23:05 2021 ] 	Batch(935/1252) done. Loss: 0.5156  lr:0.100000  network_time: 0.0847
[ Tue Feb  2 06:23:27 2021 ] 	Batch(1035/1252) done. Loss: 0.3524  lr:0.100000  network_time: 0.0773
[ Tue Feb  2 06:23:48 2021 ] 	Batch(1135/1252) done. Loss: 0.8024  lr:0.100000  network_time: 0.0725
[ Tue Feb  2 06:24:10 2021 ] 	Batch(1235/1252) done. Loss: 0.8434  lr:0.100000  network_time: 0.0737
[ Tue Feb  2 06:24:14 2021 ] Eval epoch: 33
[ Tue Feb  2 06:24:47 2021 ] 	Mean test loss of 258 batches: 0.7405951619148254.
[ Tue Feb  2 06:24:47 2021 ] 	Top1: 77.51%
[ Tue Feb  2 06:24:47 2021 ] 	Top5: 95.93%
[ Tue Feb  2 06:24:47 2021 ] Training epoch: 34
[ Tue Feb  2 06:25:09 2021 ] 	Batch(83/1252) done. Loss: 0.3131  lr:0.100000  network_time: 0.0776
[ Tue Feb  2 06:25:31 2021 ] 	Batch(183/1252) done. Loss: 0.4100  lr:0.100000  network_time: 0.0842
[ Tue Feb  2 06:25:53 2021 ] 	Batch(283/1252) done. Loss: 0.5749  lr:0.100000  network_time: 0.0858
[ Tue Feb  2 06:26:14 2021 ] 	Batch(383/1252) done. Loss: 0.2692  lr:0.100000  network_time: 0.0790
[ Tue Feb  2 06:26:36 2021 ] 	Batch(483/1252) done. Loss: 1.0328  lr:0.100000  network_time: 0.0822
[ Tue Feb  2 06:26:58 2021 ] 	Batch(583/1252) done. Loss: 0.4541  lr:0.100000  network_time: 0.1013
[ Tue Feb  2 06:27:20 2021 ] 	Batch(683/1252) done. Loss: 0.5470  lr:0.100000  network_time: 0.1023
[ Tue Feb  2 06:27:42 2021 ] 	Batch(783/1252) done. Loss: 0.5048  lr:0.100000  network_time: 0.0835
[ Tue Feb  2 06:28:04 2021 ] 	Batch(883/1252) done. Loss: 0.4500  lr:0.100000  network_time: 0.0889
[ Tue Feb  2 06:28:25 2021 ] 	Batch(983/1252) done. Loss: 0.5444  lr:0.100000  network_time: 0.0837
[ Tue Feb  2 06:28:48 2021 ] 	Batch(1083/1252) done. Loss: 0.8135  lr:0.100000  network_time: 0.0774
[ Tue Feb  2 06:29:10 2021 ] 	Batch(1183/1252) done. Loss: 0.3617  lr:0.100000  network_time: 0.0970
[ Tue Feb  2 06:29:25 2021 ] Eval epoch: 34
[ Tue Feb  2 06:29:59 2021 ] 	Mean test loss of 258 batches: 0.746625542640686.
[ Tue Feb  2 06:29:59 2021 ] 	Top1: 77.69%
[ Tue Feb  2 06:29:59 2021 ] 	Top5: 96.03%
[ Tue Feb  2 06:29:59 2021 ] Training epoch: 35
[ Tue Feb  2 06:30:09 2021 ] 	Batch(31/1252) done. Loss: 0.6019  lr:0.100000  network_time: 0.0868
[ Tue Feb  2 06:30:31 2021 ] 	Batch(131/1252) done. Loss: 0.4786  lr:0.100000  network_time: 0.0946
[ Tue Feb  2 06:30:53 2021 ] 	Batch(231/1252) done. Loss: 0.6483  lr:0.100000  network_time: 0.0834
[ Tue Feb  2 06:31:15 2021 ] 	Batch(331/1252) done. Loss: 0.5043  lr:0.100000  network_time: 0.0981
[ Tue Feb  2 06:31:37 2021 ] 	Batch(431/1252) done. Loss: 0.2412  lr:0.100000  network_time: 0.1002
[ Tue Feb  2 06:31:59 2021 ] 	Batch(531/1252) done. Loss: 0.5019  lr:0.100000  network_time: 0.0631
[ Tue Feb  2 06:32:21 2021 ] 	Batch(631/1252) done. Loss: 0.5522  lr:0.100000  network_time: 0.0790
[ Tue Feb  2 06:32:43 2021 ] 	Batch(731/1252) done. Loss: 0.4326  lr:0.100000  network_time: 0.0735
[ Tue Feb  2 06:33:05 2021 ] 	Batch(831/1252) done. Loss: 0.7865  lr:0.100000  network_time: 0.0998
[ Tue Feb  2 06:33:27 2021 ] 	Batch(931/1252) done. Loss: 0.5269  lr:0.100000  network_time: 0.0942
[ Tue Feb  2 06:33:49 2021 ] 	Batch(1031/1252) done. Loss: 0.7671  lr:0.100000  network_time: 0.0789
[ Tue Feb  2 06:34:11 2021 ] 	Batch(1131/1252) done. Loss: 0.6738  lr:0.100000  network_time: 0.0849
[ Tue Feb  2 06:34:33 2021 ] 	Batch(1231/1252) done. Loss: 0.5959  lr:0.100000  network_time: 0.0870
[ Tue Feb  2 06:34:38 2021 ] Eval epoch: 35
[ Tue Feb  2 06:35:11 2021 ] 	Mean test loss of 258 batches: 0.8336043357849121.
[ Tue Feb  2 06:35:12 2021 ] 	Top1: 75.16%
[ Tue Feb  2 06:35:12 2021 ] 	Top5: 95.26%
[ Tue Feb  2 06:35:12 2021 ] Training epoch: 36
[ Tue Feb  2 06:35:32 2021 ] 	Batch(79/1252) done. Loss: 0.6681  lr:0.100000  network_time: 0.0784
[ Tue Feb  2 06:35:54 2021 ] 	Batch(179/1252) done. Loss: 0.6071  lr:0.100000  network_time: 0.0859
[ Tue Feb  2 06:36:16 2021 ] 	Batch(279/1252) done. Loss: 0.8041  lr:0.100000  network_time: 0.1348
[ Tue Feb  2 06:36:38 2021 ] 	Batch(379/1252) done. Loss: 0.7464  lr:0.100000  network_time: 0.0856
[ Tue Feb  2 06:37:00 2021 ] 	Batch(479/1252) done. Loss: 0.6423  lr:0.100000  network_time: 0.0734
[ Tue Feb  2 06:37:22 2021 ] 	Batch(579/1252) done. Loss: 0.4657  lr:0.100000  network_time: 0.0950
[ Tue Feb  2 06:37:44 2021 ] 	Batch(679/1252) done. Loss: 0.6061  lr:0.100000  network_time: 0.0857
[ Tue Feb  2 06:38:06 2021 ] 	Batch(779/1252) done. Loss: 0.7460  lr:0.100000  network_time: 0.0855
[ Tue Feb  2 06:38:28 2021 ] 	Batch(879/1252) done. Loss: 0.4524  lr:0.100000  network_time: 0.0730
[ Tue Feb  2 06:38:50 2021 ] 	Batch(979/1252) done. Loss: 0.8878  lr:0.100000  network_time: 0.0819
[ Tue Feb  2 06:39:12 2021 ] 	Batch(1079/1252) done. Loss: 0.5778  lr:0.100000  network_time: 0.0900
[ Tue Feb  2 06:39:34 2021 ] 	Batch(1179/1252) done. Loss: 0.4477  lr:0.100000  network_time: 0.0880
[ Tue Feb  2 06:39:50 2021 ] Eval epoch: 36
[ Tue Feb  2 06:40:24 2021 ] 	Mean test loss of 258 batches: 0.8669962286949158.
[ Tue Feb  2 06:40:24 2021 ] 	Top1: 75.64%
[ Tue Feb  2 06:40:24 2021 ] 	Top5: 95.44%
[ Tue Feb  2 06:40:24 2021 ] Training epoch: 37
[ Tue Feb  2 06:40:34 2021 ] 	Batch(27/1252) done. Loss: 0.5089  lr:0.100000  network_time: 0.0873
[ Tue Feb  2 06:40:55 2021 ] 	Batch(127/1252) done. Loss: 0.6145  lr:0.100000  network_time: 0.0829
[ Tue Feb  2 06:41:17 2021 ] 	Batch(227/1252) done. Loss: 0.4304  lr:0.100000  network_time: 0.1211
[ Tue Feb  2 06:41:39 2021 ] 	Batch(327/1252) done. Loss: 0.7511  lr:0.100000  network_time: 0.0696
[ Tue Feb  2 06:42:01 2021 ] 	Batch(427/1252) done. Loss: 0.8044  lr:0.100000  network_time: 0.0867
[ Tue Feb  2 06:42:23 2021 ] 	Batch(527/1252) done. Loss: 0.3738  lr:0.100000  network_time: 0.0772
[ Tue Feb  2 06:42:46 2021 ] 	Batch(627/1252) done. Loss: 0.5413  lr:0.100000  network_time: 0.0903
[ Tue Feb  2 06:43:08 2021 ] 	Batch(727/1252) done. Loss: 0.6492  lr:0.100000  network_time: 0.0770
[ Tue Feb  2 06:43:29 2021 ] 	Batch(827/1252) done. Loss: 0.4673  lr:0.100000  network_time: 0.0854
[ Tue Feb  2 06:43:52 2021 ] 	Batch(927/1252) done. Loss: 0.5885  lr:0.100000  network_time: 0.1091
[ Tue Feb  2 06:44:14 2021 ] 	Batch(1027/1252) done. Loss: 0.3794  lr:0.100000  network_time: 0.0890
[ Tue Feb  2 06:44:36 2021 ] 	Batch(1127/1252) done. Loss: 0.5946  lr:0.100000  network_time: 0.1005
[ Tue Feb  2 06:44:58 2021 ] 	Batch(1227/1252) done. Loss: 0.2126  lr:0.100000  network_time: 0.0992
[ Tue Feb  2 06:45:03 2021 ] Eval epoch: 37
[ Tue Feb  2 06:45:37 2021 ] 	Mean test loss of 258 batches: 0.7891678214073181.
[ Tue Feb  2 06:45:37 2021 ] 	Top1: 77.03%
[ Tue Feb  2 06:45:37 2021 ] 	Top5: 95.66%
[ Tue Feb  2 06:45:37 2021 ] Training epoch: 38
[ Tue Feb  2 06:45:57 2021 ] 	Batch(75/1252) done. Loss: 0.5662  lr:0.100000  network_time: 0.0898
[ Tue Feb  2 06:46:19 2021 ] 	Batch(175/1252) done. Loss: 0.5206  lr:0.100000  network_time: 0.0812
[ Tue Feb  2 06:46:41 2021 ] 	Batch(275/1252) done. Loss: 0.8083  lr:0.100000  network_time: 0.0830
[ Tue Feb  2 06:47:03 2021 ] 	Batch(375/1252) done. Loss: 0.5706  lr:0.100000  network_time: 0.0701
[ Tue Feb  2 06:47:25 2021 ] 	Batch(475/1252) done. Loss: 0.7834  lr:0.100000  network_time: 0.0801
[ Tue Feb  2 06:47:47 2021 ] 	Batch(575/1252) done. Loss: 0.5224  lr:0.100000  network_time: 0.0799
[ Tue Feb  2 06:48:09 2021 ] 	Batch(675/1252) done. Loss: 0.5269  lr:0.100000  network_time: 0.0783
[ Tue Feb  2 06:48:31 2021 ] 	Batch(775/1252) done. Loss: 0.5112  lr:0.100000  network_time: 0.0937
[ Tue Feb  2 06:48:54 2021 ] 	Batch(875/1252) done. Loss: 0.5390  lr:0.100000  network_time: 0.1122
[ Tue Feb  2 06:49:16 2021 ] 	Batch(975/1252) done. Loss: 0.4747  lr:0.100000  network_time: 0.0836
[ Tue Feb  2 06:49:38 2021 ] 	Batch(1075/1252) done. Loss: 0.7110  lr:0.100000  network_time: 0.0793
[ Tue Feb  2 06:50:00 2021 ] 	Batch(1175/1252) done. Loss: 0.6993  lr:0.100000  network_time: 0.0834
[ Tue Feb  2 06:50:17 2021 ] Eval epoch: 38
[ Tue Feb  2 06:50:51 2021 ] 	Mean test loss of 258 batches: 0.8288664221763611.
[ Tue Feb  2 06:50:51 2021 ] 	Top1: 76.38%
[ Tue Feb  2 06:50:51 2021 ] 	Top5: 95.97%
[ Tue Feb  2 06:50:51 2021 ] Training epoch: 39
[ Tue Feb  2 06:51:00 2021 ] 	Batch(23/1252) done. Loss: 0.6117  lr:0.100000  network_time: 0.0971
[ Tue Feb  2 06:51:22 2021 ] 	Batch(123/1252) done. Loss: 0.6385  lr:0.100000  network_time: 0.0840
[ Tue Feb  2 06:51:43 2021 ] 	Batch(223/1252) done. Loss: 0.5089  lr:0.100000  network_time: 0.0862
[ Tue Feb  2 06:52:05 2021 ] 	Batch(323/1252) done. Loss: 0.5423  lr:0.100000  network_time: 0.0891
[ Tue Feb  2 06:52:28 2021 ] 	Batch(423/1252) done. Loss: 0.1201  lr:0.100000  network_time: 0.0765
[ Tue Feb  2 06:52:50 2021 ] 	Batch(523/1252) done. Loss: 0.3865  lr:0.100000  network_time: 0.0766
[ Tue Feb  2 06:53:12 2021 ] 	Batch(623/1252) done. Loss: 0.7317  lr:0.100000  network_time: 0.1029
[ Tue Feb  2 06:53:35 2021 ] 	Batch(723/1252) done. Loss: 0.6173  lr:0.100000  network_time: 0.1035
[ Tue Feb  2 06:53:58 2021 ] 	Batch(823/1252) done. Loss: 0.6405  lr:0.100000  network_time: 0.0759
[ Tue Feb  2 06:54:20 2021 ] 	Batch(923/1252) done. Loss: 0.2585  lr:0.100000  network_time: 0.0875
[ Tue Feb  2 06:54:44 2021 ] 	Batch(1023/1252) done. Loss: 0.8976  lr:0.100000  network_time: 0.0888
[ Tue Feb  2 06:55:06 2021 ] 	Batch(1123/1252) done. Loss: 0.5141  lr:0.100000  network_time: 0.0890
[ Tue Feb  2 06:55:29 2021 ] 	Batch(1223/1252) done. Loss: 0.5749  lr:0.100000  network_time: 0.0920
[ Tue Feb  2 06:55:35 2021 ] Eval epoch: 39
[ Tue Feb  2 06:56:10 2021 ] 	Mean test loss of 258 batches: 0.7946814298629761.
[ Tue Feb  2 06:56:11 2021 ] 	Top1: 76.73%
[ Tue Feb  2 06:56:11 2021 ] 	Top5: 95.57%
[ Tue Feb  2 06:56:11 2021 ] Training epoch: 40
[ Tue Feb  2 06:56:30 2021 ] 	Batch(71/1252) done. Loss: 0.4879  lr:0.100000  network_time: 0.0918
[ Tue Feb  2 06:56:53 2021 ] 	Batch(171/1252) done. Loss: 0.2217  lr:0.100000  network_time: 0.0856
[ Tue Feb  2 06:57:16 2021 ] 	Batch(271/1252) done. Loss: 0.3115  lr:0.100000  network_time: 0.1013
[ Tue Feb  2 06:57:39 2021 ] 	Batch(371/1252) done. Loss: 0.2901  lr:0.100000  network_time: 0.0886
[ Tue Feb  2 06:58:02 2021 ] 	Batch(471/1252) done. Loss: 0.4123  lr:0.100000  network_time: 0.0892
[ Tue Feb  2 06:58:25 2021 ] 	Batch(571/1252) done. Loss: 0.6668  lr:0.100000  network_time: 0.0845
[ Tue Feb  2 06:58:47 2021 ] 	Batch(671/1252) done. Loss: 0.5177  lr:0.100000  network_time: 0.1020
[ Tue Feb  2 06:59:10 2021 ] 	Batch(771/1252) done. Loss: 0.2938  lr:0.100000  network_time: 0.0808
[ Tue Feb  2 06:59:33 2021 ] 	Batch(871/1252) done. Loss: 0.6122  lr:0.100000  network_time: 0.1147
[ Tue Feb  2 06:59:56 2021 ] 	Batch(971/1252) done. Loss: 0.5274  lr:0.100000  network_time: 0.1044
[ Tue Feb  2 07:00:19 2021 ] 	Batch(1071/1252) done. Loss: 0.3547  lr:0.100000  network_time: 0.0824
[ Tue Feb  2 07:00:42 2021 ] 	Batch(1171/1252) done. Loss: 0.4628  lr:0.100000  network_time: 0.0873
[ Tue Feb  2 07:01:00 2021 ] Eval epoch: 40
[ Tue Feb  2 07:01:35 2021 ] 	Mean test loss of 258 batches: 0.7837849855422974.
[ Tue Feb  2 07:01:35 2021 ] 	Top1: 76.65%
[ Tue Feb  2 07:01:35 2021 ] 	Top5: 95.88%
[ Tue Feb  2 07:01:35 2021 ] Training epoch: 41
[ Tue Feb  2 07:01:43 2021 ] 	Batch(19/1252) done. Loss: 0.3676  lr:0.100000  network_time: 0.0925
[ Tue Feb  2 07:02:06 2021 ] 	Batch(119/1252) done. Loss: 0.4636  lr:0.100000  network_time: 0.0825
[ Tue Feb  2 07:02:29 2021 ] 	Batch(219/1252) done. Loss: 0.6836  lr:0.100000  network_time: 0.1056
[ Tue Feb  2 07:02:52 2021 ] 	Batch(319/1252) done. Loss: 0.4484  lr:0.100000  network_time: 0.0829
[ Tue Feb  2 07:03:14 2021 ] 	Batch(419/1252) done. Loss: 0.5989  lr:0.100000  network_time: 0.0938
[ Tue Feb  2 07:03:37 2021 ] 	Batch(519/1252) done. Loss: 0.5039  lr:0.100000  network_time: 0.1037
[ Tue Feb  2 07:04:00 2021 ] 	Batch(619/1252) done. Loss: 0.4676  lr:0.100000  network_time: 0.0961
[ Tue Feb  2 07:04:23 2021 ] 	Batch(719/1252) done. Loss: 0.3773  lr:0.100000  network_time: 0.0830
[ Tue Feb  2 07:04:45 2021 ] 	Batch(819/1252) done. Loss: 0.8840  lr:0.100000  network_time: 0.1150
[ Tue Feb  2 07:05:08 2021 ] 	Batch(919/1252) done. Loss: 0.4500  lr:0.100000  network_time: 0.0977
[ Tue Feb  2 07:05:31 2021 ] 	Batch(1019/1252) done. Loss: 0.5206  lr:0.100000  network_time: 0.0859
[ Tue Feb  2 07:05:54 2021 ] 	Batch(1119/1252) done. Loss: 0.6278  lr:0.100000  network_time: 0.0875
[ Tue Feb  2 07:06:17 2021 ] 	Batch(1219/1252) done. Loss: 0.6750  lr:0.100000  network_time: 0.0931
[ Tue Feb  2 07:06:24 2021 ] Eval epoch: 41
[ Tue Feb  2 07:06:59 2021 ] 	Mean test loss of 258 batches: 0.7599753737449646.
[ Tue Feb  2 07:06:59 2021 ] 	Top1: 78.02%
[ Tue Feb  2 07:06:59 2021 ] 	Top5: 95.93%
[ Tue Feb  2 07:06:59 2021 ] Training epoch: 42
[ Tue Feb  2 07:07:18 2021 ] 	Batch(67/1252) done. Loss: 0.2990  lr:0.100000  network_time: 0.1126
[ Tue Feb  2 07:07:41 2021 ] 	Batch(167/1252) done. Loss: 0.4452  lr:0.100000  network_time: 0.0924
[ Tue Feb  2 07:08:03 2021 ] 	Batch(267/1252) done. Loss: 0.8005  lr:0.100000  network_time: 0.0834
[ Tue Feb  2 07:08:26 2021 ] 	Batch(367/1252) done. Loss: 0.6671  lr:0.100000  network_time: 0.0872
[ Tue Feb  2 07:08:49 2021 ] 	Batch(467/1252) done. Loss: 0.6469  lr:0.100000  network_time: 0.0859
[ Tue Feb  2 07:09:12 2021 ] 	Batch(567/1252) done. Loss: 0.3523  lr:0.100000  network_time: 0.0921
[ Tue Feb  2 07:09:35 2021 ] 	Batch(667/1252) done. Loss: 0.7279  lr:0.100000  network_time: 0.0962
[ Tue Feb  2 07:09:57 2021 ] 	Batch(767/1252) done. Loss: 0.5072  lr:0.100000  network_time: 0.1017
[ Tue Feb  2 07:10:20 2021 ] 	Batch(867/1252) done. Loss: 0.6088  lr:0.100000  network_time: 0.0987
[ Tue Feb  2 07:10:43 2021 ] 	Batch(967/1252) done. Loss: 0.3502  lr:0.100000  network_time: 0.0845
[ Tue Feb  2 07:11:06 2021 ] 	Batch(1067/1252) done. Loss: 0.4758  lr:0.100000  network_time: 0.0949
[ Tue Feb  2 07:11:29 2021 ] 	Batch(1167/1252) done. Loss: 0.3490  lr:0.100000  network_time: 0.1092
[ Tue Feb  2 07:11:48 2021 ] Eval epoch: 42
[ Tue Feb  2 07:12:23 2021 ] 	Mean test loss of 258 batches: 0.8058656454086304.
[ Tue Feb  2 07:12:23 2021 ] 	Top1: 76.32%
[ Tue Feb  2 07:12:24 2021 ] 	Top5: 95.68%
[ Tue Feb  2 07:12:24 2021 ] Training epoch: 43
[ Tue Feb  2 07:12:31 2021 ] 	Batch(15/1252) done. Loss: 0.2696  lr:0.100000  network_time: 0.0970
[ Tue Feb  2 07:12:53 2021 ] 	Batch(115/1252) done. Loss: 0.4805  lr:0.100000  network_time: 0.0926
[ Tue Feb  2 07:13:16 2021 ] 	Batch(215/1252) done. Loss: 0.3542  lr:0.100000  network_time: 0.0831
[ Tue Feb  2 07:13:38 2021 ] 	Batch(315/1252) done. Loss: 0.3628  lr:0.100000  network_time: 0.0751
[ Tue Feb  2 07:14:01 2021 ] 	Batch(415/1252) done. Loss: 0.6007  lr:0.100000  network_time: 0.1093
[ Tue Feb  2 07:14:24 2021 ] 	Batch(515/1252) done. Loss: 0.4356  lr:0.100000  network_time: 0.1065
[ Tue Feb  2 07:14:46 2021 ] 	Batch(615/1252) done. Loss: 0.8540  lr:0.100000  network_time: 0.0961
[ Tue Feb  2 07:15:09 2021 ] 	Batch(715/1252) done. Loss: 0.7572  lr:0.100000  network_time: 0.1000
[ Tue Feb  2 07:15:31 2021 ] 	Batch(815/1252) done. Loss: 0.6440  lr:0.100000  network_time: 0.0872
[ Tue Feb  2 07:15:53 2021 ] 	Batch(915/1252) done. Loss: 0.4666  lr:0.100000  network_time: 0.0822
[ Tue Feb  2 07:16:15 2021 ] 	Batch(1015/1252) done. Loss: 0.7622  lr:0.100000  network_time: 0.0795
[ Tue Feb  2 07:16:38 2021 ] 	Batch(1115/1252) done. Loss: 0.5899  lr:0.100000  network_time: 0.0828
[ Tue Feb  2 07:17:00 2021 ] 	Batch(1215/1252) done. Loss: 0.3197  lr:0.100000  network_time: 0.0884
[ Tue Feb  2 07:17:08 2021 ] Eval epoch: 43
[ Tue Feb  2 07:17:42 2021 ] 	Mean test loss of 258 batches: 0.7759643197059631.
[ Tue Feb  2 07:17:42 2021 ] 	Top1: 77.12%
[ Tue Feb  2 07:17:42 2021 ] 	Top5: 96.43%
[ Tue Feb  2 07:17:42 2021 ] Training epoch: 44
[ Tue Feb  2 07:18:00 2021 ] 	Batch(63/1252) done. Loss: 0.4816  lr:0.100000  network_time: 0.0862
[ Tue Feb  2 07:18:22 2021 ] 	Batch(163/1252) done. Loss: 0.8077  lr:0.100000  network_time: 0.0864
[ Tue Feb  2 07:18:45 2021 ] 	Batch(263/1252) done. Loss: 0.4371  lr:0.100000  network_time: 0.0817
[ Tue Feb  2 07:19:07 2021 ] 	Batch(363/1252) done. Loss: 0.5981  lr:0.100000  network_time: 0.0799
[ Tue Feb  2 07:19:29 2021 ] 	Batch(463/1252) done. Loss: 0.5996  lr:0.100000  network_time: 0.0808
[ Tue Feb  2 07:19:52 2021 ] 	Batch(563/1252) done. Loss: 0.3882  lr:0.100000  network_time: 0.1049
[ Tue Feb  2 07:20:14 2021 ] 	Batch(663/1252) done. Loss: 0.6320  lr:0.100000  network_time: 0.0773
[ Tue Feb  2 07:20:36 2021 ] 	Batch(763/1252) done. Loss: 0.5901  lr:0.100000  network_time: 0.0838
[ Tue Feb  2 07:20:59 2021 ] 	Batch(863/1252) done. Loss: 0.5588  lr:0.100000  network_time: 0.0847
[ Tue Feb  2 07:21:21 2021 ] 	Batch(963/1252) done. Loss: 0.3321  lr:0.100000  network_time: 0.1083
[ Tue Feb  2 07:21:44 2021 ] 	Batch(1063/1252) done. Loss: 0.6476  lr:0.100000  network_time: 0.0993
[ Tue Feb  2 07:22:06 2021 ] 	Batch(1163/1252) done. Loss: 0.6551  lr:0.100000  network_time: 0.0867
[ Tue Feb  2 07:22:26 2021 ] Eval epoch: 44
[ Tue Feb  2 07:23:01 2021 ] 	Mean test loss of 258 batches: 0.7356910705566406.
[ Tue Feb  2 07:23:01 2021 ] 	Top1: 78.37%
[ Tue Feb  2 07:23:01 2021 ] 	Top5: 96.06%
[ Tue Feb  2 07:23:01 2021 ] Training epoch: 45
[ Tue Feb  2 07:23:07 2021 ] 	Batch(11/1252) done. Loss: 0.3210  lr:0.100000  network_time: 0.0977
[ Tue Feb  2 07:23:29 2021 ] 	Batch(111/1252) done. Loss: 0.5252  lr:0.100000  network_time: 0.0841
[ Tue Feb  2 07:23:51 2021 ] 	Batch(211/1252) done. Loss: 0.4077  lr:0.100000  network_time: 0.0824
[ Tue Feb  2 07:24:14 2021 ] 	Batch(311/1252) done. Loss: 0.5128  lr:0.100000  network_time: 0.1017
[ Tue Feb  2 07:24:36 2021 ] 	Batch(411/1252) done. Loss: 0.4267  lr:0.100000  network_time: 0.0763
[ Tue Feb  2 07:24:58 2021 ] 	Batch(511/1252) done. Loss: 0.5137  lr:0.100000  network_time: 0.0898
[ Tue Feb  2 07:25:20 2021 ] 	Batch(611/1252) done. Loss: 0.4261  lr:0.100000  network_time: 0.0858
[ Tue Feb  2 07:25:43 2021 ] 	Batch(711/1252) done. Loss: 0.6069  lr:0.100000  network_time: 0.0947
[ Tue Feb  2 07:26:05 2021 ] 	Batch(811/1252) done. Loss: 0.4583  lr:0.100000  network_time: 0.0839
[ Tue Feb  2 07:26:27 2021 ] 	Batch(911/1252) done. Loss: 0.5339  lr:0.100000  network_time: 0.1226
[ Tue Feb  2 07:26:49 2021 ] 	Batch(1011/1252) done. Loss: 0.4540  lr:0.100000  network_time: 0.0839
[ Tue Feb  2 07:27:12 2021 ] 	Batch(1111/1252) done. Loss: 0.3686  lr:0.100000  network_time: 0.0883
[ Tue Feb  2 07:27:34 2021 ] 	Batch(1211/1252) done. Loss: 0.5305  lr:0.100000  network_time: 0.0755
[ Tue Feb  2 07:27:43 2021 ] Eval epoch: 45
[ Tue Feb  2 07:28:17 2021 ] 	Mean test loss of 258 batches: 0.7157630920410156.
[ Tue Feb  2 07:28:17 2021 ] 	Top1: 78.82%
[ Tue Feb  2 07:28:18 2021 ] 	Top5: 96.42%
[ Tue Feb  2 07:28:18 2021 ] Training epoch: 46
[ Tue Feb  2 07:28:34 2021 ] 	Batch(59/1252) done. Loss: 0.5248  lr:0.100000  network_time: 0.0803
[ Tue Feb  2 07:28:57 2021 ] 	Batch(159/1252) done. Loss: 0.3251  lr:0.100000  network_time: 0.0695
[ Tue Feb  2 07:29:19 2021 ] 	Batch(259/1252) done. Loss: 0.8145  lr:0.100000  network_time: 0.0860
[ Tue Feb  2 07:29:42 2021 ] 	Batch(359/1252) done. Loss: 0.4757  lr:0.100000  network_time: 0.0863
[ Tue Feb  2 07:30:04 2021 ] 	Batch(459/1252) done. Loss: 0.4971  lr:0.100000  network_time: 0.0807
[ Tue Feb  2 07:30:26 2021 ] 	Batch(559/1252) done. Loss: 0.3975  lr:0.100000  network_time: 0.0963
[ Tue Feb  2 07:30:49 2021 ] 	Batch(659/1252) done. Loss: 0.6864  lr:0.100000  network_time: 0.0947
[ Tue Feb  2 07:31:11 2021 ] 	Batch(759/1252) done. Loss: 0.6243  lr:0.100000  network_time: 0.0805
[ Tue Feb  2 07:31:33 2021 ] 	Batch(859/1252) done. Loss: 0.4331  lr:0.100000  network_time: 0.0858
[ Tue Feb  2 07:31:56 2021 ] 	Batch(959/1252) done. Loss: 0.5672  lr:0.100000  network_time: 0.0826
[ Tue Feb  2 07:32:18 2021 ] 	Batch(1059/1252) done. Loss: 0.6255  lr:0.100000  network_time: 0.0777
[ Tue Feb  2 07:32:41 2021 ] 	Batch(1159/1252) done. Loss: 0.3299  lr:0.100000  network_time: 0.0859
[ Tue Feb  2 07:33:01 2021 ] Eval epoch: 46
[ Tue Feb  2 07:33:36 2021 ] 	Mean test loss of 258 batches: 0.7950952649116516.
[ Tue Feb  2 07:33:36 2021 ] 	Top1: 77.65%
[ Tue Feb  2 07:33:36 2021 ] 	Top5: 95.65%
[ Tue Feb  2 07:33:36 2021 ] Training epoch: 47
[ Tue Feb  2 07:33:41 2021 ] 	Batch(7/1252) done. Loss: 0.3683  lr:0.100000  network_time: 0.1034
[ Tue Feb  2 07:34:03 2021 ] 	Batch(107/1252) done. Loss: 0.4220  lr:0.100000  network_time: 0.0732
[ Tue Feb  2 07:34:25 2021 ] 	Batch(207/1252) done. Loss: 0.6660  lr:0.100000  network_time: 0.0924
[ Tue Feb  2 07:34:48 2021 ] 	Batch(307/1252) done. Loss: 0.5535  lr:0.100000  network_time: 0.0770
[ Tue Feb  2 07:35:10 2021 ] 	Batch(407/1252) done. Loss: 0.3586  lr:0.100000  network_time: 0.0977
[ Tue Feb  2 07:35:32 2021 ] 	Batch(507/1252) done. Loss: 0.2806  lr:0.100000  network_time: 0.0991
[ Tue Feb  2 07:35:54 2021 ] 	Batch(607/1252) done. Loss: 0.5187  lr:0.100000  network_time: 0.0964
[ Tue Feb  2 07:36:16 2021 ] 	Batch(707/1252) done. Loss: 0.5805  lr:0.100000  network_time: 0.0866
[ Tue Feb  2 07:36:39 2021 ] 	Batch(807/1252) done. Loss: 0.6377  lr:0.100000  network_time: 0.0851
[ Tue Feb  2 07:37:01 2021 ] 	Batch(907/1252) done. Loss: 0.4442  lr:0.100000  network_time: 0.0783
[ Tue Feb  2 07:37:22 2021 ] 	Batch(1007/1252) done. Loss: 0.4057  lr:0.100000  network_time: 0.0907
[ Tue Feb  2 07:37:45 2021 ] 	Batch(1107/1252) done. Loss: 0.5613  lr:0.100000  network_time: 0.0925
[ Tue Feb  2 07:38:07 2021 ] 	Batch(1207/1252) done. Loss: 0.5270  lr:0.100000  network_time: 0.0781
[ Tue Feb  2 07:38:17 2021 ] Eval epoch: 47
[ Tue Feb  2 07:38:51 2021 ] 	Mean test loss of 258 batches: 0.7405114769935608.
[ Tue Feb  2 07:38:51 2021 ] 	Top1: 78.65%
[ Tue Feb  2 07:38:51 2021 ] 	Top5: 95.80%
[ Tue Feb  2 07:38:51 2021 ] Training epoch: 48
[ Tue Feb  2 07:39:07 2021 ] 	Batch(55/1252) done. Loss: 0.3316  lr:0.100000  network_time: 0.0807
[ Tue Feb  2 07:39:29 2021 ] 	Batch(155/1252) done. Loss: 0.4841  lr:0.100000  network_time: 0.0804
[ Tue Feb  2 07:39:51 2021 ] 	Batch(255/1252) done. Loss: 0.5250  lr:0.100000  network_time: 0.0809
[ Tue Feb  2 07:40:13 2021 ] 	Batch(355/1252) done. Loss: 0.6712  lr:0.100000  network_time: 0.0811
[ Tue Feb  2 07:40:35 2021 ] 	Batch(455/1252) done. Loss: 0.4837  lr:0.100000  network_time: 0.0761
[ Tue Feb  2 07:40:57 2021 ] 	Batch(555/1252) done. Loss: 0.3408  lr:0.100000  network_time: 0.1015
[ Tue Feb  2 07:41:19 2021 ] 	Batch(655/1252) done. Loss: 0.3449  lr:0.100000  network_time: 0.0858
[ Tue Feb  2 07:41:41 2021 ] 	Batch(755/1252) done. Loss: 0.3924  lr:0.100000  network_time: 0.0877
[ Tue Feb  2 07:42:04 2021 ] 	Batch(855/1252) done. Loss: 0.4102  lr:0.100000  network_time: 0.0836
[ Tue Feb  2 07:42:26 2021 ] 	Batch(955/1252) done. Loss: 0.5647  lr:0.100000  network_time: 0.0785
[ Tue Feb  2 07:42:48 2021 ] 	Batch(1055/1252) done. Loss: 0.4758  lr:0.100000  network_time: 0.0821
[ Tue Feb  2 07:43:10 2021 ] 	Batch(1155/1252) done. Loss: 0.3542  lr:0.100000  network_time: 0.0827
[ Tue Feb  2 07:43:32 2021 ] Eval epoch: 48
[ Tue Feb  2 07:44:06 2021 ] 	Mean test loss of 258 batches: 0.802725613117218.
[ Tue Feb  2 07:44:06 2021 ] 	Top1: 76.18%
[ Tue Feb  2 07:44:06 2021 ] 	Top5: 96.25%
[ Tue Feb  2 07:44:06 2021 ] Training epoch: 49
[ Tue Feb  2 07:44:10 2021 ] 	Batch(3/1252) done. Loss: 0.8169  lr:0.100000  network_time: 0.0856
[ Tue Feb  2 07:44:32 2021 ] 	Batch(103/1252) done. Loss: 0.4882  lr:0.100000  network_time: 0.0795
[ Tue Feb  2 07:44:54 2021 ] 	Batch(203/1252) done. Loss: 0.7488  lr:0.100000  network_time: 0.0795
[ Tue Feb  2 07:45:17 2021 ] 	Batch(303/1252) done. Loss: 0.6708  lr:0.100000  network_time: 0.0837
[ Tue Feb  2 07:45:39 2021 ] 	Batch(403/1252) done. Loss: 0.2628  lr:0.100000  network_time: 0.0870
[ Tue Feb  2 07:46:01 2021 ] 	Batch(503/1252) done. Loss: 0.4633  lr:0.100000  network_time: 0.0913
[ Tue Feb  2 07:46:23 2021 ] 	Batch(603/1252) done. Loss: 0.2664  lr:0.100000  network_time: 0.0815
[ Tue Feb  2 07:46:45 2021 ] 	Batch(703/1252) done. Loss: 0.3150  lr:0.100000  network_time: 0.0761
[ Tue Feb  2 07:47:07 2021 ] 	Batch(803/1252) done. Loss: 0.2971  lr:0.100000  network_time: 0.0775
[ Tue Feb  2 07:47:30 2021 ] 	Batch(903/1252) done. Loss: 0.4472  lr:0.100000  network_time: 0.0947
[ Tue Feb  2 07:47:52 2021 ] 	Batch(1003/1252) done. Loss: 0.6293  lr:0.100000  network_time: 0.0867
[ Tue Feb  2 07:48:14 2021 ] 	Batch(1103/1252) done. Loss: 0.6144  lr:0.100000  network_time: 0.0814
[ Tue Feb  2 07:48:36 2021 ] 	Batch(1203/1252) done. Loss: 0.6957  lr:0.100000  network_time: 0.0793
[ Tue Feb  2 07:48:47 2021 ] Eval epoch: 49
[ Tue Feb  2 07:49:21 2021 ] 	Mean test loss of 258 batches: 0.8872543573379517.
[ Tue Feb  2 07:49:22 2021 ] 	Top1: 74.74%
[ Tue Feb  2 07:49:22 2021 ] 	Top5: 94.35%
[ Tue Feb  2 07:49:22 2021 ] Training epoch: 50
[ Tue Feb  2 07:49:37 2021 ] 	Batch(51/1252) done. Loss: 0.5835  lr:0.100000  network_time: 0.0852
[ Tue Feb  2 07:49:59 2021 ] 	Batch(151/1252) done. Loss: 0.5090  lr:0.100000  network_time: 0.0997
[ Tue Feb  2 07:50:21 2021 ] 	Batch(251/1252) done. Loss: 0.6117  lr:0.100000  network_time: 0.0773
[ Tue Feb  2 07:50:43 2021 ] 	Batch(351/1252) done. Loss: 0.2697  lr:0.100000  network_time: 0.0759
[ Tue Feb  2 07:51:05 2021 ] 	Batch(451/1252) done. Loss: 0.3673  lr:0.100000  network_time: 0.0944
[ Tue Feb  2 07:51:27 2021 ] 	Batch(551/1252) done. Loss: 0.2850  lr:0.100000  network_time: 0.0924
[ Tue Feb  2 07:51:50 2021 ] 	Batch(651/1252) done. Loss: 0.5800  lr:0.100000  network_time: 0.0975
[ Tue Feb  2 07:52:14 2021 ] 	Batch(751/1252) done. Loss: 0.6441  lr:0.100000  network_time: 0.1071
[ Tue Feb  2 07:52:38 2021 ] 	Batch(851/1252) done. Loss: 0.6287  lr:0.100000  network_time: 0.0797
[ Tue Feb  2 07:53:02 2021 ] 	Batch(951/1252) done. Loss: 0.6306  lr:0.100000  network_time: 0.0878
[ Tue Feb  2 07:53:27 2021 ] 	Batch(1051/1252) done. Loss: 0.4050  lr:0.100000  network_time: 0.0897
[ Tue Feb  2 07:53:51 2021 ] 	Batch(1151/1252) done. Loss: 0.6323  lr:0.100000  network_time: 0.0909
[ Tue Feb  2 07:54:15 2021 ] 	Batch(1251/1252) done. Loss: 0.3514  lr:0.100000  network_time: 0.0880
[ Tue Feb  2 07:54:15 2021 ] Eval epoch: 50
[ Tue Feb  2 07:54:52 2021 ] 	Mean test loss of 258 batches: 0.7740264534950256.
[ Tue Feb  2 07:54:52 2021 ] 	Top1: 77.55%
[ Tue Feb  2 07:54:52 2021 ] 	Top5: 96.00%
[ Tue Feb  2 07:54:52 2021 ] Training epoch: 51
[ Tue Feb  2 07:55:19 2021 ] 	Batch(99/1252) done. Loss: 0.4513  lr:0.100000  network_time: 0.1000
[ Tue Feb  2 07:55:43 2021 ] 	Batch(199/1252) done. Loss: 0.3755  lr:0.100000  network_time: 0.0927
[ Tue Feb  2 07:56:07 2021 ] 	Batch(299/1252) done. Loss: 0.3881  lr:0.100000  network_time: 0.1078
[ Tue Feb  2 07:56:31 2021 ] 	Batch(399/1252) done. Loss: 0.5146  lr:0.100000  network_time: 0.0867
[ Tue Feb  2 07:56:55 2021 ] 	Batch(499/1252) done. Loss: 0.3407  lr:0.100000  network_time: 0.0955
[ Tue Feb  2 07:57:19 2021 ] 	Batch(599/1252) done. Loss: 0.4768  lr:0.100000  network_time: 0.0834
[ Tue Feb  2 07:57:43 2021 ] 	Batch(699/1252) done. Loss: 0.6228  lr:0.100000  network_time: 0.0877
[ Tue Feb  2 07:58:07 2021 ] 	Batch(799/1252) done. Loss: 0.4103  lr:0.100000  network_time: 0.0902
[ Tue Feb  2 07:58:31 2021 ] 	Batch(899/1252) done. Loss: 0.4095  lr:0.100000  network_time: 0.1117
[ Tue Feb  2 07:58:55 2021 ] 	Batch(999/1252) done. Loss: 0.4495  lr:0.100000  network_time: 0.1017
[ Tue Feb  2 07:59:19 2021 ] 	Batch(1099/1252) done. Loss: 0.4175  lr:0.100000  network_time: 0.0891
[ Tue Feb  2 07:59:43 2021 ] 	Batch(1199/1252) done. Loss: 0.3131  lr:0.100000  network_time: 0.1053
[ Tue Feb  2 07:59:56 2021 ] Eval epoch: 51
[ Tue Feb  2 08:00:32 2021 ] 	Mean test loss of 258 batches: 0.7029115557670593.
[ Tue Feb  2 08:00:32 2021 ] 	Top1: 79.32%
[ Tue Feb  2 08:00:33 2021 ] 	Top5: 96.63%
[ Tue Feb  2 08:00:33 2021 ] Training epoch: 52
[ Tue Feb  2 08:00:47 2021 ] 	Batch(47/1252) done. Loss: 0.8899  lr:0.100000  network_time: 0.0862
[ Tue Feb  2 08:01:11 2021 ] 	Batch(147/1252) done. Loss: 0.3816  lr:0.100000  network_time: 0.0909
[ Tue Feb  2 08:01:35 2021 ] 	Batch(247/1252) done. Loss: 0.6017  lr:0.100000  network_time: 0.0774
[ Tue Feb  2 08:01:59 2021 ] 	Batch(347/1252) done. Loss: 0.2071  lr:0.100000  network_time: 0.0912
[ Tue Feb  2 08:02:23 2021 ] 	Batch(447/1252) done. Loss: 1.2671  lr:0.100000  network_time: 0.1068
[ Tue Feb  2 08:02:45 2021 ] 	Batch(547/1252) done. Loss: 0.6393  lr:0.100000  network_time: 0.0792
[ Tue Feb  2 08:03:07 2021 ] 	Batch(647/1252) done. Loss: 0.3708  lr:0.100000  network_time: 0.0730
[ Tue Feb  2 08:03:29 2021 ] 	Batch(747/1252) done. Loss: 0.7015  lr:0.100000  network_time: 0.0783
[ Tue Feb  2 08:03:51 2021 ] 	Batch(847/1252) done. Loss: 0.3345  lr:0.100000  network_time: 0.0844
[ Tue Feb  2 08:04:13 2021 ] 	Batch(947/1252) done. Loss: 0.4182  lr:0.100000  network_time: 0.0878
[ Tue Feb  2 08:04:35 2021 ] 	Batch(1047/1252) done. Loss: 0.4545  lr:0.100000  network_time: 0.0853
[ Tue Feb  2 08:04:58 2021 ] 	Batch(1147/1252) done. Loss: 0.4411  lr:0.100000  network_time: 0.0744
[ Tue Feb  2 08:05:20 2021 ] 	Batch(1247/1252) done. Loss: 0.2983  lr:0.100000  network_time: 0.0799
[ Tue Feb  2 08:05:21 2021 ] Eval epoch: 52
[ Tue Feb  2 08:05:55 2021 ] 	Mean test loss of 258 batches: 0.7015998363494873.
[ Tue Feb  2 08:05:55 2021 ] 	Top1: 79.08%
[ Tue Feb  2 08:05:55 2021 ] 	Top5: 96.49%
[ Tue Feb  2 08:05:55 2021 ] Training epoch: 53
[ Tue Feb  2 08:06:20 2021 ] 	Batch(95/1252) done. Loss: 0.4752  lr:0.100000  network_time: 0.0822
[ Tue Feb  2 08:06:42 2021 ] 	Batch(195/1252) done. Loss: 0.5190  lr:0.100000  network_time: 0.1039
[ Tue Feb  2 08:07:04 2021 ] 	Batch(295/1252) done. Loss: 0.5881  lr:0.100000  network_time: 0.0848
[ Tue Feb  2 08:07:27 2021 ] 	Batch(395/1252) done. Loss: 0.4229  lr:0.100000  network_time: 0.0886
[ Tue Feb  2 08:07:49 2021 ] 	Batch(495/1252) done. Loss: 0.3591  lr:0.100000  network_time: 0.0750
[ Tue Feb  2 08:08:11 2021 ] 	Batch(595/1252) done. Loss: 0.6297  lr:0.100000  network_time: 0.0841
[ Tue Feb  2 08:08:33 2021 ] 	Batch(695/1252) done. Loss: 0.6306  lr:0.100000  network_time: 0.0832
[ Tue Feb  2 08:08:55 2021 ] 	Batch(795/1252) done. Loss: 0.3727  lr:0.100000  network_time: 0.0841
[ Tue Feb  2 08:09:17 2021 ] 	Batch(895/1252) done. Loss: 0.5394  lr:0.100000  network_time: 0.0818
[ Tue Feb  2 08:09:39 2021 ] 	Batch(995/1252) done. Loss: 0.5974  lr:0.100000  network_time: 0.0788
[ Tue Feb  2 08:10:01 2021 ] 	Batch(1095/1252) done. Loss: 0.6276  lr:0.100000  network_time: 0.0820
[ Tue Feb  2 08:10:23 2021 ] 	Batch(1195/1252) done. Loss: 0.5467  lr:0.100000  network_time: 0.0830
[ Tue Feb  2 08:10:36 2021 ] Eval epoch: 53
[ Tue Feb  2 08:11:10 2021 ] 	Mean test loss of 258 batches: 0.7594507336616516.
[ Tue Feb  2 08:11:10 2021 ] 	Top1: 78.33%
[ Tue Feb  2 08:11:10 2021 ] 	Top5: 95.86%
[ Tue Feb  2 08:11:10 2021 ] Training epoch: 54
[ Tue Feb  2 08:11:23 2021 ] 	Batch(43/1252) done. Loss: 0.6581  lr:0.100000  network_time: 0.0861
[ Tue Feb  2 08:11:45 2021 ] 	Batch(143/1252) done. Loss: 0.4256  lr:0.100000  network_time: 0.1042
[ Tue Feb  2 08:12:07 2021 ] 	Batch(243/1252) done. Loss: 0.2784  lr:0.100000  network_time: 0.0811
[ Tue Feb  2 08:12:29 2021 ] 	Batch(343/1252) done. Loss: 0.3346  lr:0.100000  network_time: 0.0730
[ Tue Feb  2 08:12:52 2021 ] 	Batch(443/1252) done. Loss: 0.3354  lr:0.100000  network_time: 0.0839
[ Tue Feb  2 08:13:14 2021 ] 	Batch(543/1252) done. Loss: 0.1807  lr:0.100000  network_time: 0.0812
[ Tue Feb  2 08:13:36 2021 ] 	Batch(643/1252) done. Loss: 0.4481  lr:0.100000  network_time: 0.0893
[ Tue Feb  2 08:13:58 2021 ] 	Batch(743/1252) done. Loss: 0.3279  lr:0.100000  network_time: 0.0837
[ Tue Feb  2 08:14:21 2021 ] 	Batch(843/1252) done. Loss: 0.5613  lr:0.100000  network_time: 0.0862
[ Tue Feb  2 08:14:43 2021 ] 	Batch(943/1252) done. Loss: 0.4414  lr:0.100000  network_time: 0.0834
[ Tue Feb  2 08:15:05 2021 ] 	Batch(1043/1252) done. Loss: 0.5242  lr:0.100000  network_time: 0.0866
[ Tue Feb  2 08:15:27 2021 ] 	Batch(1143/1252) done. Loss: 0.5851  lr:0.100000  network_time: 0.0818
[ Tue Feb  2 08:15:50 2021 ] 	Batch(1243/1252) done. Loss: 0.5144  lr:0.100000  network_time: 0.0984
[ Tue Feb  2 08:15:52 2021 ] Eval epoch: 54
[ Tue Feb  2 08:16:26 2021 ] 	Mean test loss of 258 batches: 0.7260130643844604.
[ Tue Feb  2 08:16:26 2021 ] 	Top1: 78.27%
[ Tue Feb  2 08:16:26 2021 ] 	Top5: 96.06%
[ Tue Feb  2 08:16:26 2021 ] Training epoch: 55
[ Tue Feb  2 08:16:50 2021 ] 	Batch(91/1252) done. Loss: 0.4832  lr:0.100000  network_time: 0.0983
[ Tue Feb  2 08:17:12 2021 ] 	Batch(191/1252) done. Loss: 0.3149  lr:0.100000  network_time: 0.0809
[ Tue Feb  2 08:17:34 2021 ] 	Batch(291/1252) done. Loss: 0.5344  lr:0.100000  network_time: 0.0873
[ Tue Feb  2 08:17:57 2021 ] 	Batch(391/1252) done. Loss: 0.5512  lr:0.100000  network_time: 0.0783
[ Tue Feb  2 08:18:19 2021 ] 	Batch(491/1252) done. Loss: 0.5607  lr:0.100000  network_time: 0.0808
[ Tue Feb  2 08:18:41 2021 ] 	Batch(591/1252) done. Loss: 0.7567  lr:0.100000  network_time: 0.0808
[ Tue Feb  2 08:19:03 2021 ] 	Batch(691/1252) done. Loss: 0.5742  lr:0.100000  network_time: 0.0874
[ Tue Feb  2 08:19:25 2021 ] 	Batch(791/1252) done. Loss: 0.2973  lr:0.100000  network_time: 0.0843
[ Tue Feb  2 08:19:47 2021 ] 	Batch(891/1252) done. Loss: 0.4697  lr:0.100000  network_time: 0.0788
[ Tue Feb  2 08:20:09 2021 ] 	Batch(991/1252) done. Loss: 0.7143  lr:0.100000  network_time: 0.0819
[ Tue Feb  2 08:20:31 2021 ] 	Batch(1091/1252) done. Loss: 0.7188  lr:0.100000  network_time: 0.0926
[ Tue Feb  2 08:20:54 2021 ] 	Batch(1191/1252) done. Loss: 0.4356  lr:0.100000  network_time: 0.0937
[ Tue Feb  2 08:21:07 2021 ] Eval epoch: 55
[ Tue Feb  2 08:21:41 2021 ] 	Mean test loss of 258 batches: 0.7638423442840576.
[ Tue Feb  2 08:21:41 2021 ] 	Top1: 77.75%
[ Tue Feb  2 08:21:42 2021 ] 	Top5: 96.25%
[ Tue Feb  2 08:21:42 2021 ] Training epoch: 56
[ Tue Feb  2 08:21:54 2021 ] 	Batch(39/1252) done. Loss: 0.4230  lr:0.100000  network_time: 0.0834
[ Tue Feb  2 08:22:16 2021 ] 	Batch(139/1252) done. Loss: 0.4144  lr:0.100000  network_time: 0.0852
[ Tue Feb  2 08:22:38 2021 ] 	Batch(239/1252) done. Loss: 0.4548  lr:0.100000  network_time: 0.0842
[ Tue Feb  2 08:23:00 2021 ] 	Batch(339/1252) done. Loss: 0.3902  lr:0.100000  network_time: 0.0792
[ Tue Feb  2 08:23:22 2021 ] 	Batch(439/1252) done. Loss: 0.7167  lr:0.100000  network_time: 0.0756
[ Tue Feb  2 08:23:44 2021 ] 	Batch(539/1252) done. Loss: 0.3268  lr:0.100000  network_time: 0.1132
[ Tue Feb  2 08:24:06 2021 ] 	Batch(639/1252) done. Loss: 0.4467  lr:0.100000  network_time: 0.0900
[ Tue Feb  2 08:24:29 2021 ] 	Batch(739/1252) done. Loss: 0.2988  lr:0.100000  network_time: 0.0866
[ Tue Feb  2 08:24:51 2021 ] 	Batch(839/1252) done. Loss: 0.6270  lr:0.100000  network_time: 0.0886
[ Tue Feb  2 08:25:13 2021 ] 	Batch(939/1252) done. Loss: 0.5875  lr:0.100000  network_time: 0.0826
[ Tue Feb  2 08:25:35 2021 ] 	Batch(1039/1252) done. Loss: 0.6882  lr:0.100000  network_time: 0.0884
[ Tue Feb  2 08:25:57 2021 ] 	Batch(1139/1252) done. Loss: 0.6630  lr:0.100000  network_time: 0.1003
[ Tue Feb  2 08:26:19 2021 ] 	Batch(1239/1252) done. Loss: 0.4128  lr:0.100000  network_time: 0.0933
[ Tue Feb  2 08:26:22 2021 ] Eval epoch: 56
[ Tue Feb  2 08:26:56 2021 ] 	Mean test loss of 258 batches: 0.8093899488449097.
[ Tue Feb  2 08:26:56 2021 ] 	Top1: 76.35%
[ Tue Feb  2 08:26:57 2021 ] 	Top5: 95.39%
[ Tue Feb  2 08:26:57 2021 ] Training epoch: 57
[ Tue Feb  2 08:27:19 2021 ] 	Batch(87/1252) done. Loss: 0.8388  lr:0.100000  network_time: 0.0800
[ Tue Feb  2 08:27:41 2021 ] 	Batch(187/1252) done. Loss: 0.4384  lr:0.100000  network_time: 0.0775
[ Tue Feb  2 08:28:04 2021 ] 	Batch(287/1252) done. Loss: 0.6820  lr:0.100000  network_time: 0.0821
[ Tue Feb  2 08:28:26 2021 ] 	Batch(387/1252) done. Loss: 0.6034  lr:0.100000  network_time: 0.0886
[ Tue Feb  2 08:28:48 2021 ] 	Batch(487/1252) done. Loss: 0.3285  lr:0.100000  network_time: 0.0714
[ Tue Feb  2 08:29:10 2021 ] 	Batch(587/1252) done. Loss: 0.2682  lr:0.100000  network_time: 0.0808
[ Tue Feb  2 08:29:32 2021 ] 	Batch(687/1252) done. Loss: 0.4183  lr:0.100000  network_time: 0.0682
[ Tue Feb  2 08:29:54 2021 ] 	Batch(787/1252) done. Loss: 0.5725  lr:0.100000  network_time: 0.0779
[ Tue Feb  2 08:30:16 2021 ] 	Batch(887/1252) done. Loss: 0.4340  lr:0.100000  network_time: 0.0805
[ Tue Feb  2 08:30:39 2021 ] 	Batch(987/1252) done. Loss: 1.0310  lr:0.100000  network_time: 0.0863
[ Tue Feb  2 08:31:01 2021 ] 	Batch(1087/1252) done. Loss: 0.5816  lr:0.100000  network_time: 0.0766
[ Tue Feb  2 08:31:23 2021 ] 	Batch(1187/1252) done. Loss: 0.1867  lr:0.100000  network_time: 0.0777
[ Tue Feb  2 08:31:37 2021 ] Eval epoch: 57
[ Tue Feb  2 08:32:12 2021 ] 	Mean test loss of 258 batches: 0.8250623941421509.
[ Tue Feb  2 08:32:12 2021 ] 	Top1: 76.39%
[ Tue Feb  2 08:32:12 2021 ] 	Top5: 95.75%
[ Tue Feb  2 08:32:12 2021 ] Training epoch: 58
[ Tue Feb  2 08:32:23 2021 ] 	Batch(35/1252) done. Loss: 0.3428  lr:0.100000  network_time: 0.0896
[ Tue Feb  2 08:32:46 2021 ] 	Batch(135/1252) done. Loss: 0.5539  lr:0.100000  network_time: 0.0731
[ Tue Feb  2 08:33:08 2021 ] 	Batch(235/1252) done. Loss: 0.7170  lr:0.100000  network_time: 0.0803
[ Tue Feb  2 08:33:29 2021 ] 	Batch(335/1252) done. Loss: 0.4596  lr:0.100000  network_time: 0.0883
[ Tue Feb  2 08:33:51 2021 ] 	Batch(435/1252) done. Loss: 0.5051  lr:0.100000  network_time: 0.0779
[ Tue Feb  2 08:34:14 2021 ] 	Batch(535/1252) done. Loss: 0.4592  lr:0.100000  network_time: 0.0839
[ Tue Feb  2 08:34:35 2021 ] 	Batch(635/1252) done. Loss: 0.9287  lr:0.100000  network_time: 0.0806
[ Tue Feb  2 08:34:58 2021 ] 	Batch(735/1252) done. Loss: 0.6379  lr:0.100000  network_time: 0.0837
[ Tue Feb  2 08:35:20 2021 ] 	Batch(835/1252) done. Loss: 0.2012  lr:0.100000  network_time: 0.0794
[ Tue Feb  2 08:35:42 2021 ] 	Batch(935/1252) done. Loss: 0.5092  lr:0.100000  network_time: 0.0837
[ Tue Feb  2 08:36:04 2021 ] 	Batch(1035/1252) done. Loss: 0.7770  lr:0.100000  network_time: 0.0935
[ Tue Feb  2 08:36:27 2021 ] 	Batch(1135/1252) done. Loss: 0.4971  lr:0.100000  network_time: 0.0973
[ Tue Feb  2 08:36:49 2021 ] 	Batch(1235/1252) done. Loss: 0.5513  lr:0.100000  network_time: 0.0853
[ Tue Feb  2 08:36:52 2021 ] Eval epoch: 58
[ Tue Feb  2 08:37:26 2021 ] 	Mean test loss of 258 batches: 0.6935462951660156.
[ Tue Feb  2 08:37:27 2021 ] 	Top1: 79.52%
[ Tue Feb  2 08:37:27 2021 ] 	Top5: 96.62%
[ Tue Feb  2 08:37:27 2021 ] Training epoch: 59
[ Tue Feb  2 08:37:48 2021 ] 	Batch(83/1252) done. Loss: 0.1932  lr:0.100000  network_time: 0.0874
[ Tue Feb  2 08:38:10 2021 ] 	Batch(183/1252) done. Loss: 0.3828  lr:0.100000  network_time: 0.0906
[ Tue Feb  2 08:38:33 2021 ] 	Batch(283/1252) done. Loss: 0.2581  lr:0.100000  network_time: 0.1030
[ Tue Feb  2 08:38:55 2021 ] 	Batch(383/1252) done. Loss: 0.5001  lr:0.100000  network_time: 0.0817
[ Tue Feb  2 08:39:17 2021 ] 	Batch(483/1252) done. Loss: 0.4763  lr:0.100000  network_time: 0.0855
[ Tue Feb  2 08:39:39 2021 ] 	Batch(583/1252) done. Loss: 0.4563  lr:0.100000  network_time: 0.0859
[ Tue Feb  2 08:40:01 2021 ] 	Batch(683/1252) done. Loss: 0.3794  lr:0.100000  network_time: 0.0813
[ Tue Feb  2 08:40:23 2021 ] 	Batch(783/1252) done. Loss: 0.3639  lr:0.100000  network_time: 0.0820
[ Tue Feb  2 08:40:45 2021 ] 	Batch(883/1252) done. Loss: 0.3083  lr:0.100000  network_time: 0.1092
[ Tue Feb  2 08:41:07 2021 ] 	Batch(983/1252) done. Loss: 0.2431  lr:0.100000  network_time: 0.0749
[ Tue Feb  2 08:41:28 2021 ] 	Batch(1083/1252) done. Loss: 0.6624  lr:0.100000  network_time: 0.0808
[ Tue Feb  2 08:41:50 2021 ] 	Batch(1183/1252) done. Loss: 0.4539  lr:0.100000  network_time: 0.0862
[ Tue Feb  2 08:42:05 2021 ] Eval epoch: 59
[ Tue Feb  2 08:42:39 2021 ] 	Mean test loss of 258 batches: 0.7746284604072571.
[ Tue Feb  2 08:42:39 2021 ] 	Top1: 76.99%
[ Tue Feb  2 08:42:39 2021 ] 	Top5: 96.18%
[ Tue Feb  2 08:42:39 2021 ] Training epoch: 60
[ Tue Feb  2 08:42:49 2021 ] 	Batch(31/1252) done. Loss: 0.1570  lr:0.100000  network_time: 0.0831
[ Tue Feb  2 08:43:11 2021 ] 	Batch(131/1252) done. Loss: 0.7188  lr:0.100000  network_time: 0.0822
[ Tue Feb  2 08:43:32 2021 ] 	Batch(231/1252) done. Loss: 0.4329  lr:0.100000  network_time: 0.0896
[ Tue Feb  2 08:43:54 2021 ] 	Batch(331/1252) done. Loss: 0.3693  lr:0.100000  network_time: 0.0793
[ Tue Feb  2 08:44:16 2021 ] 	Batch(431/1252) done. Loss: 0.3750  lr:0.100000  network_time: 0.0771
[ Tue Feb  2 08:44:37 2021 ] 	Batch(531/1252) done. Loss: 0.3343  lr:0.100000  network_time: 0.0893
[ Tue Feb  2 08:44:59 2021 ] 	Batch(631/1252) done. Loss: 0.6798  lr:0.100000  network_time: 0.0793
[ Tue Feb  2 08:45:21 2021 ] 	Batch(731/1252) done. Loss: 0.2937  lr:0.100000  network_time: 0.0834
[ Tue Feb  2 08:45:43 2021 ] 	Batch(831/1252) done. Loss: 0.5070  lr:0.100000  network_time: 0.0918
[ Tue Feb  2 08:46:05 2021 ] 	Batch(931/1252) done. Loss: 0.3056  lr:0.100000  network_time: 0.0851
[ Tue Feb  2 08:46:27 2021 ] 	Batch(1031/1252) done. Loss: 0.4612  lr:0.100000  network_time: 0.0933
[ Tue Feb  2 08:46:49 2021 ] 	Batch(1131/1252) done. Loss: 0.6790  lr:0.100000  network_time: 0.0735
[ Tue Feb  2 08:47:11 2021 ] 	Batch(1231/1252) done. Loss: 0.4383  lr:0.100000  network_time: 0.0822
[ Tue Feb  2 08:47:15 2021 ] Eval epoch: 60
[ Tue Feb  2 08:47:49 2021 ] 	Mean test loss of 258 batches: 0.721511960029602.
[ Tue Feb  2 08:47:50 2021 ] 	Top1: 78.63%
[ Tue Feb  2 08:47:50 2021 ] 	Top5: 96.32%
[ Tue Feb  2 08:47:50 2021 ] Training epoch: 61
[ Tue Feb  2 08:48:10 2021 ] 	Batch(79/1252) done. Loss: 0.6053  lr:0.010000  network_time: 0.0769
[ Tue Feb  2 08:48:32 2021 ] 	Batch(179/1252) done. Loss: 0.1313  lr:0.010000  network_time: 0.0807
[ Tue Feb  2 08:48:54 2021 ] 	Batch(279/1252) done. Loss: 0.7222  lr:0.010000  network_time: 0.0902
[ Tue Feb  2 08:49:16 2021 ] 	Batch(379/1252) done. Loss: 0.1491  lr:0.010000  network_time: 0.0838
[ Tue Feb  2 08:49:38 2021 ] 	Batch(479/1252) done. Loss: 0.3806  lr:0.010000  network_time: 0.0862
[ Tue Feb  2 08:50:00 2021 ] 	Batch(579/1252) done. Loss: 0.4684  lr:0.010000  network_time: 0.0879
[ Tue Feb  2 08:50:21 2021 ] 	Batch(679/1252) done. Loss: 0.3394  lr:0.010000  network_time: 0.0816
[ Tue Feb  2 08:50:43 2021 ] 	Batch(779/1252) done. Loss: 0.2847  lr:0.010000  network_time: 0.0923
[ Tue Feb  2 08:51:06 2021 ] 	Batch(879/1252) done. Loss: 0.3761  lr:0.010000  network_time: 0.0706
[ Tue Feb  2 08:51:28 2021 ] 	Batch(979/1252) done. Loss: 0.2208  lr:0.010000  network_time: 0.0843
[ Tue Feb  2 08:51:49 2021 ] 	Batch(1079/1252) done. Loss: 0.2303  lr:0.010000  network_time: 0.0751
[ Tue Feb  2 08:52:11 2021 ] 	Batch(1179/1252) done. Loss: 0.2522  lr:0.010000  network_time: 0.0937
[ Tue Feb  2 08:52:27 2021 ] Eval epoch: 61
[ Tue Feb  2 08:53:01 2021 ] 	Mean test loss of 258 batches: 0.5320362448692322.
[ Tue Feb  2 08:53:01 2021 ] 	Top1: 84.33%
[ Tue Feb  2 08:53:01 2021 ] 	Top5: 97.44%
[ Tue Feb  2 08:53:01 2021 ] Training epoch: 62
[ Tue Feb  2 08:53:11 2021 ] 	Batch(27/1252) done. Loss: 0.1640  lr:0.010000  network_time: 0.0792
[ Tue Feb  2 08:53:33 2021 ] 	Batch(127/1252) done. Loss: 0.3240  lr:0.010000  network_time: 0.0787
[ Tue Feb  2 08:53:55 2021 ] 	Batch(227/1252) done. Loss: 0.2982  lr:0.010000  network_time: 0.0811
[ Tue Feb  2 08:54:16 2021 ] 	Batch(327/1252) done. Loss: 0.2251  lr:0.010000  network_time: 0.0857
[ Tue Feb  2 08:54:39 2021 ] 	Batch(427/1252) done. Loss: 0.1974  lr:0.010000  network_time: 0.0777
[ Tue Feb  2 08:55:01 2021 ] 	Batch(527/1252) done. Loss: 0.2839  lr:0.010000  network_time: 0.0810
[ Tue Feb  2 08:55:23 2021 ] 	Batch(627/1252) done. Loss: 0.2179  lr:0.010000  network_time: 0.0797
[ Tue Feb  2 08:55:44 2021 ] 	Batch(727/1252) done. Loss: 0.1381  lr:0.010000  network_time: 0.0764
[ Tue Feb  2 08:56:06 2021 ] 	Batch(827/1252) done. Loss: 0.3164  lr:0.010000  network_time: 0.0819
[ Tue Feb  2 08:56:28 2021 ] 	Batch(927/1252) done. Loss: 0.2577  lr:0.010000  network_time: 0.0796
[ Tue Feb  2 08:56:50 2021 ] 	Batch(1027/1252) done. Loss: 0.4182  lr:0.010000  network_time: 0.0807
[ Tue Feb  2 08:57:12 2021 ] 	Batch(1127/1252) done. Loss: 0.2546  lr:0.010000  network_time: 0.0809
[ Tue Feb  2 08:57:34 2021 ] 	Batch(1227/1252) done. Loss: 0.3260  lr:0.010000  network_time: 0.0808
[ Tue Feb  2 08:57:40 2021 ] Eval epoch: 62
[ Tue Feb  2 08:58:13 2021 ] 	Mean test loss of 258 batches: 0.5222166776657104.
[ Tue Feb  2 08:58:14 2021 ] 	Top1: 84.54%
[ Tue Feb  2 08:58:14 2021 ] 	Top5: 97.54%
[ Tue Feb  2 08:58:14 2021 ] Training epoch: 63
[ Tue Feb  2 08:58:34 2021 ] 	Batch(75/1252) done. Loss: 0.4246  lr:0.010000  network_time: 0.0920
[ Tue Feb  2 08:58:56 2021 ] 	Batch(175/1252) done. Loss: 0.1751  lr:0.010000  network_time: 0.0882
[ Tue Feb  2 08:59:18 2021 ] 	Batch(275/1252) done. Loss: 0.3110  lr:0.010000  network_time: 0.0836
[ Tue Feb  2 08:59:40 2021 ] 	Batch(375/1252) done. Loss: 0.1365  lr:0.010000  network_time: 0.0964
[ Tue Feb  2 09:00:02 2021 ] 	Batch(475/1252) done. Loss: 0.1248  lr:0.010000  network_time: 0.0744
[ Tue Feb  2 09:00:24 2021 ] 	Batch(575/1252) done. Loss: 0.1466  lr:0.010000  network_time: 0.0837
[ Tue Feb  2 09:00:46 2021 ] 	Batch(675/1252) done. Loss: 0.0971  lr:0.010000  network_time: 0.0800
[ Tue Feb  2 09:01:08 2021 ] 	Batch(775/1252) done. Loss: 0.1550  lr:0.010000  network_time: 0.0852
[ Tue Feb  2 09:01:30 2021 ] 	Batch(875/1252) done. Loss: 0.2847  lr:0.010000  network_time: 0.0902
[ Tue Feb  2 09:01:52 2021 ] 	Batch(975/1252) done. Loss: 0.2625  lr:0.010000  network_time: 0.0837
[ Tue Feb  2 09:02:14 2021 ] 	Batch(1075/1252) done. Loss: 0.2010  lr:0.010000  network_time: 0.0915
[ Tue Feb  2 09:02:36 2021 ] 	Batch(1175/1252) done. Loss: 0.1933  lr:0.010000  network_time: 0.0881
[ Tue Feb  2 09:02:53 2021 ] Eval epoch: 63
[ Tue Feb  2 09:03:27 2021 ] 	Mean test loss of 258 batches: 0.5121922492980957.
[ Tue Feb  2 09:03:27 2021 ] 	Top1: 84.92%
[ Tue Feb  2 09:03:27 2021 ] 	Top5: 97.61%
[ Tue Feb  2 09:03:27 2021 ] Training epoch: 64
[ Tue Feb  2 09:03:35 2021 ] 	Batch(23/1252) done. Loss: 0.1841  lr:0.010000  network_time: 0.0792
[ Tue Feb  2 09:03:57 2021 ] 	Batch(123/1252) done. Loss: 0.2448  lr:0.010000  network_time: 0.0974
[ Tue Feb  2 09:04:19 2021 ] 	Batch(223/1252) done. Loss: 0.3032  lr:0.010000  network_time: 0.0691
[ Tue Feb  2 09:04:41 2021 ] 	Batch(323/1252) done. Loss: 0.1801  lr:0.010000  network_time: 0.0847
[ Tue Feb  2 09:05:02 2021 ] 	Batch(423/1252) done. Loss: 0.0570  lr:0.010000  network_time: 0.0896
[ Tue Feb  2 09:05:24 2021 ] 	Batch(523/1252) done. Loss: 0.1995  lr:0.010000  network_time: 0.0867
[ Tue Feb  2 09:05:46 2021 ] 	Batch(623/1252) done. Loss: 0.2840  lr:0.010000  network_time: 0.0962
[ Tue Feb  2 09:06:08 2021 ] 	Batch(723/1252) done. Loss: 0.2387  lr:0.010000  network_time: 0.0839
[ Tue Feb  2 09:06:30 2021 ] 	Batch(823/1252) done. Loss: 0.1218  lr:0.010000  network_time: 0.0743
[ Tue Feb  2 09:06:52 2021 ] 	Batch(923/1252) done. Loss: 0.1450  lr:0.010000  network_time: 0.0818
[ Tue Feb  2 09:07:14 2021 ] 	Batch(1023/1252) done. Loss: 0.3270  lr:0.010000  network_time: 0.0874
[ Tue Feb  2 09:07:36 2021 ] 	Batch(1123/1252) done. Loss: 0.1388  lr:0.010000  network_time: 0.0842
[ Tue Feb  2 09:07:58 2021 ] 	Batch(1223/1252) done. Loss: 0.1917  lr:0.010000  network_time: 0.0909
[ Tue Feb  2 09:08:04 2021 ] Eval epoch: 64
[ Tue Feb  2 09:08:38 2021 ] 	Mean test loss of 258 batches: 0.5022227168083191.
[ Tue Feb  2 09:08:38 2021 ] 	Top1: 85.02%
[ Tue Feb  2 09:08:38 2021 ] 	Top5: 97.79%
[ Tue Feb  2 09:08:38 2021 ] Training epoch: 65
[ Tue Feb  2 09:08:57 2021 ] 	Batch(71/1252) done. Loss: 0.0690  lr:0.010000  network_time: 0.0973
[ Tue Feb  2 09:09:19 2021 ] 	Batch(171/1252) done. Loss: 0.1388  lr:0.010000  network_time: 0.0957
[ Tue Feb  2 09:09:41 2021 ] 	Batch(271/1252) done. Loss: 0.0700  lr:0.010000  network_time: 0.0783
[ Tue Feb  2 09:10:02 2021 ] 	Batch(371/1252) done. Loss: 0.3278  lr:0.010000  network_time: 0.0826
[ Tue Feb  2 09:10:24 2021 ] 	Batch(471/1252) done. Loss: 0.2283  lr:0.010000  network_time: 0.0790
[ Tue Feb  2 09:10:46 2021 ] 	Batch(571/1252) done. Loss: 0.1190  lr:0.010000  network_time: 0.0801
[ Tue Feb  2 09:11:08 2021 ] 	Batch(671/1252) done. Loss: 0.0496  lr:0.010000  network_time: 0.0725
[ Tue Feb  2 09:11:30 2021 ] 	Batch(771/1252) done. Loss: 0.2594  lr:0.010000  network_time: 0.0792
[ Tue Feb  2 09:11:52 2021 ] 	Batch(871/1252) done. Loss: 0.2535  lr:0.010000  network_time: 0.0828
[ Tue Feb  2 09:12:14 2021 ] 	Batch(971/1252) done. Loss: 0.1022  lr:0.010000  network_time: 0.0864
[ Tue Feb  2 09:12:36 2021 ] 	Batch(1071/1252) done. Loss: 0.0888  lr:0.010000  network_time: 0.0742
[ Tue Feb  2 09:12:58 2021 ] 	Batch(1171/1252) done. Loss: 0.2377  lr:0.010000  network_time: 0.0844
[ Tue Feb  2 09:13:16 2021 ] Eval epoch: 65
[ Tue Feb  2 09:13:50 2021 ] 	Mean test loss of 258 batches: 0.5138508677482605.
[ Tue Feb  2 09:13:50 2021 ] 	Top1: 84.79%
[ Tue Feb  2 09:13:50 2021 ] 	Top5: 97.68%
[ Tue Feb  2 09:13:50 2021 ] Training epoch: 66
[ Tue Feb  2 09:13:57 2021 ] 	Batch(19/1252) done. Loss: 0.1574  lr:0.010000  network_time: 0.0873
[ Tue Feb  2 09:14:19 2021 ] 	Batch(119/1252) done. Loss: 0.2242  lr:0.010000  network_time: 0.0856
[ Tue Feb  2 09:14:41 2021 ] 	Batch(219/1252) done. Loss: 0.2722  lr:0.010000  network_time: 0.0756
[ Tue Feb  2 09:15:03 2021 ] 	Batch(319/1252) done. Loss: 0.1152  lr:0.010000  network_time: 0.0835
[ Tue Feb  2 09:15:25 2021 ] 	Batch(419/1252) done. Loss: 0.2349  lr:0.010000  network_time: 0.0855
[ Tue Feb  2 09:15:46 2021 ] 	Batch(519/1252) done. Loss: 0.0541  lr:0.010000  network_time: 0.0934
[ Tue Feb  2 09:16:08 2021 ] 	Batch(619/1252) done. Loss: 0.0660  lr:0.010000  network_time: 0.0832
[ Tue Feb  2 09:16:30 2021 ] 	Batch(719/1252) done. Loss: 0.2403  lr:0.010000  network_time: 0.0850
[ Tue Feb  2 09:16:52 2021 ] 	Batch(819/1252) done. Loss: 0.2378  lr:0.010000  network_time: 0.0957
[ Tue Feb  2 09:17:14 2021 ] 	Batch(919/1252) done. Loss: 0.1907  lr:0.010000  network_time: 0.0749
[ Tue Feb  2 09:17:36 2021 ] 	Batch(1019/1252) done. Loss: 0.1473  lr:0.010000  network_time: 0.0765
[ Tue Feb  2 09:17:58 2021 ] 	Batch(1119/1252) done. Loss: 0.0831  lr:0.010000  network_time: 0.0777
[ Tue Feb  2 09:18:19 2021 ] 	Batch(1219/1252) done. Loss: 0.2343  lr:0.010000  network_time: 0.0755
[ Tue Feb  2 09:18:27 2021 ] Eval epoch: 66
[ Tue Feb  2 09:19:00 2021 ] 	Mean test loss of 258 batches: 0.5094274282455444.
[ Tue Feb  2 09:19:01 2021 ] 	Top1: 85.00%
[ Tue Feb  2 09:19:01 2021 ] 	Top5: 97.71%
[ Tue Feb  2 09:19:01 2021 ] Training epoch: 67
[ Tue Feb  2 09:19:19 2021 ] 	Batch(67/1252) done. Loss: 0.0861  lr:0.010000  network_time: 0.0876
[ Tue Feb  2 09:19:40 2021 ] 	Batch(167/1252) done. Loss: 0.2089  lr:0.010000  network_time: 0.0971
[ Tue Feb  2 09:20:02 2021 ] 	Batch(267/1252) done. Loss: 0.2002  lr:0.010000  network_time: 0.0845
[ Tue Feb  2 09:20:24 2021 ] 	Batch(367/1252) done. Loss: 0.1517  lr:0.010000  network_time: 0.0862
[ Tue Feb  2 09:20:46 2021 ] 	Batch(467/1252) done. Loss: 0.2068  lr:0.010000  network_time: 0.0858
[ Tue Feb  2 09:21:08 2021 ] 	Batch(567/1252) done. Loss: 0.1451  lr:0.010000  network_time: 0.0735
[ Tue Feb  2 09:21:30 2021 ] 	Batch(667/1252) done. Loss: 0.2106  lr:0.010000  network_time: 0.0967
[ Tue Feb  2 09:21:52 2021 ] 	Batch(767/1252) done. Loss: 0.0806  lr:0.010000  network_time: 0.1018
[ Tue Feb  2 09:22:14 2021 ] 	Batch(867/1252) done. Loss: 0.2887  lr:0.010000  network_time: 0.1034
[ Tue Feb  2 09:22:36 2021 ] 	Batch(967/1252) done. Loss: 0.1869  lr:0.010000  network_time: 0.0859
[ Tue Feb  2 09:22:58 2021 ] 	Batch(1067/1252) done. Loss: 0.2080  lr:0.010000  network_time: 0.0792
[ Tue Feb  2 09:23:20 2021 ] 	Batch(1167/1252) done. Loss: 0.0694  lr:0.010000  network_time: 0.0881
[ Tue Feb  2 09:23:39 2021 ] Eval epoch: 67
[ Tue Feb  2 09:24:13 2021 ] 	Mean test loss of 258 batches: 0.5209064483642578.
[ Tue Feb  2 09:24:13 2021 ] 	Top1: 84.73%
[ Tue Feb  2 09:24:13 2021 ] 	Top5: 97.71%
[ Tue Feb  2 09:24:13 2021 ] Training epoch: 68
[ Tue Feb  2 09:24:20 2021 ] 	Batch(15/1252) done. Loss: 0.0821  lr:0.010000  network_time: 0.0763
[ Tue Feb  2 09:24:42 2021 ] 	Batch(115/1252) done. Loss: 0.1143  lr:0.010000  network_time: 0.0870
[ Tue Feb  2 09:25:04 2021 ] 	Batch(215/1252) done. Loss: 0.0410  lr:0.010000  network_time: 0.0734
[ Tue Feb  2 09:25:26 2021 ] 	Batch(315/1252) done. Loss: 0.0859  lr:0.010000  network_time: 0.0798
[ Tue Feb  2 09:25:47 2021 ] 	Batch(415/1252) done. Loss: 0.0484  lr:0.010000  network_time: 0.0853
[ Tue Feb  2 09:26:09 2021 ] 	Batch(515/1252) done. Loss: 0.0592  lr:0.010000  network_time: 0.0836
[ Tue Feb  2 09:26:31 2021 ] 	Batch(615/1252) done. Loss: 0.0851  lr:0.010000  network_time: 0.0824
[ Tue Feb  2 09:26:53 2021 ] 	Batch(715/1252) done. Loss: 0.1014  lr:0.010000  network_time: 0.0921
[ Tue Feb  2 09:27:15 2021 ] 	Batch(815/1252) done. Loss: 0.2064  lr:0.010000  network_time: 0.0802
[ Tue Feb  2 09:27:37 2021 ] 	Batch(915/1252) done. Loss: 0.2761  lr:0.010000  network_time: 0.0765
[ Tue Feb  2 09:27:59 2021 ] 	Batch(1015/1252) done. Loss: 0.1378  lr:0.010000  network_time: 0.0811
[ Tue Feb  2 09:28:21 2021 ] 	Batch(1115/1252) done. Loss: 0.1083  lr:0.010000  network_time: 0.0856
[ Tue Feb  2 09:28:43 2021 ] 	Batch(1215/1252) done. Loss: 0.1637  lr:0.010000  network_time: 0.0814
[ Tue Feb  2 09:28:51 2021 ] Eval epoch: 68
[ Tue Feb  2 09:29:25 2021 ] 	Mean test loss of 258 batches: 0.4952714443206787.
[ Tue Feb  2 09:29:25 2021 ] 	Top1: 85.03%
[ Tue Feb  2 09:29:25 2021 ] 	Top5: 97.79%
[ Tue Feb  2 09:29:25 2021 ] Training epoch: 69
[ Tue Feb  2 09:29:42 2021 ] 	Batch(63/1252) done. Loss: 0.0953  lr:0.010000  network_time: 0.0743
[ Tue Feb  2 09:30:04 2021 ] 	Batch(163/1252) done. Loss: 0.1034  lr:0.010000  network_time: 0.0858
[ Tue Feb  2 09:30:25 2021 ] 	Batch(263/1252) done. Loss: 0.1509  lr:0.010000  network_time: 0.0772
[ Tue Feb  2 09:30:47 2021 ] 	Batch(363/1252) done. Loss: 0.2211  lr:0.010000  network_time: 0.0930
[ Tue Feb  2 09:31:09 2021 ] 	Batch(463/1252) done. Loss: 0.3455  lr:0.010000  network_time: 0.0811
[ Tue Feb  2 09:31:31 2021 ] 	Batch(563/1252) done. Loss: 0.2084  lr:0.010000  network_time: 0.0733
[ Tue Feb  2 09:31:53 2021 ] 	Batch(663/1252) done. Loss: 0.1272  lr:0.010000  network_time: 0.0927
[ Tue Feb  2 09:32:15 2021 ] 	Batch(763/1252) done. Loss: 0.2658  lr:0.010000  network_time: 0.0839
[ Tue Feb  2 09:32:37 2021 ] 	Batch(863/1252) done. Loss: 0.1334  lr:0.010000  network_time: 0.0854
[ Tue Feb  2 09:32:59 2021 ] 	Batch(963/1252) done. Loss: 0.1301  lr:0.010000  network_time: 0.0861
[ Tue Feb  2 09:33:21 2021 ] 	Batch(1063/1252) done. Loss: 0.4719  lr:0.010000  network_time: 0.0852
[ Tue Feb  2 09:33:43 2021 ] 	Batch(1163/1252) done. Loss: 0.0620  lr:0.010000  network_time: 0.0893
[ Tue Feb  2 09:34:03 2021 ] Eval epoch: 69
[ Tue Feb  2 09:34:36 2021 ] 	Mean test loss of 258 batches: 0.5089598894119263.
[ Tue Feb  2 09:34:36 2021 ] 	Top1: 84.94%
[ Tue Feb  2 09:34:36 2021 ] 	Top5: 97.63%
[ Tue Feb  2 09:34:37 2021 ] Training epoch: 70
[ Tue Feb  2 09:34:42 2021 ] 	Batch(11/1252) done. Loss: 0.3384  lr:0.010000  network_time: 0.0917
[ Tue Feb  2 09:35:04 2021 ] 	Batch(111/1252) done. Loss: 0.0866  lr:0.010000  network_time: 0.0881
[ Tue Feb  2 09:35:26 2021 ] 	Batch(211/1252) done. Loss: 0.1511  lr:0.010000  network_time: 0.0814
[ Tue Feb  2 09:35:48 2021 ] 	Batch(311/1252) done. Loss: 0.1531  lr:0.010000  network_time: 0.0666
[ Tue Feb  2 09:36:10 2021 ] 	Batch(411/1252) done. Loss: 0.0630  lr:0.010000  network_time: 0.0860
[ Tue Feb  2 09:36:32 2021 ] 	Batch(511/1252) done. Loss: 0.1063  lr:0.010000  network_time: 0.0867
[ Tue Feb  2 09:36:54 2021 ] 	Batch(611/1252) done. Loss: 0.1471  lr:0.010000  network_time: 0.0792
[ Tue Feb  2 09:37:15 2021 ] 	Batch(711/1252) done. Loss: 0.0953  lr:0.010000  network_time: 0.0906
[ Tue Feb  2 09:37:38 2021 ] 	Batch(811/1252) done. Loss: 0.1254  lr:0.010000  network_time: 0.0749
[ Tue Feb  2 09:37:59 2021 ] 	Batch(911/1252) done. Loss: 0.1287  lr:0.010000  network_time: 0.0816
[ Tue Feb  2 09:38:21 2021 ] 	Batch(1011/1252) done. Loss: 0.1281  lr:0.010000  network_time: 0.0723
[ Tue Feb  2 09:38:43 2021 ] 	Batch(1111/1252) done. Loss: 0.1457  lr:0.010000  network_time: 0.0869
[ Tue Feb  2 09:39:06 2021 ] 	Batch(1211/1252) done. Loss: 0.1893  lr:0.010000  network_time: 0.0839
[ Tue Feb  2 09:39:15 2021 ] Eval epoch: 70
[ Tue Feb  2 09:39:49 2021 ] 	Mean test loss of 258 batches: 0.5087741613388062.
[ Tue Feb  2 09:39:49 2021 ] 	Top1: 85.16%
[ Tue Feb  2 09:39:49 2021 ] 	Top5: 97.77%
[ Tue Feb  2 09:39:49 2021 ] Training epoch: 71
[ Tue Feb  2 09:40:06 2021 ] 	Batch(59/1252) done. Loss: 0.2989  lr:0.010000  network_time: 0.0811
[ Tue Feb  2 09:40:28 2021 ] 	Batch(159/1252) done. Loss: 0.0906  lr:0.010000  network_time: 0.0906
[ Tue Feb  2 09:40:50 2021 ] 	Batch(259/1252) done. Loss: 0.1908  lr:0.010000  network_time: 0.0843
[ Tue Feb  2 09:41:12 2021 ] 	Batch(359/1252) done. Loss: 0.0981  lr:0.010000  network_time: 0.0878
[ Tue Feb  2 09:41:34 2021 ] 	Batch(459/1252) done. Loss: 0.0825  lr:0.010000  network_time: 0.0806
[ Tue Feb  2 09:41:56 2021 ] 	Batch(559/1252) done. Loss: 0.1900  lr:0.010000  network_time: 0.0836
[ Tue Feb  2 09:42:18 2021 ] 	Batch(659/1252) done. Loss: 0.1937  lr:0.010000  network_time: 0.0887
[ Tue Feb  2 09:42:40 2021 ] 	Batch(759/1252) done. Loss: 0.1976  lr:0.010000  network_time: 0.0914
[ Tue Feb  2 09:43:02 2021 ] 	Batch(859/1252) done. Loss: 0.0894  lr:0.010000  network_time: 0.0922
[ Tue Feb  2 09:43:24 2021 ] 	Batch(959/1252) done. Loss: 0.1068  lr:0.010000  network_time: 0.0764
[ Tue Feb  2 09:43:46 2021 ] 	Batch(1059/1252) done. Loss: 0.0958  lr:0.010000  network_time: 0.0968
[ Tue Feb  2 09:44:08 2021 ] 	Batch(1159/1252) done. Loss: 0.0824  lr:0.010000  network_time: 0.0885
[ Tue Feb  2 09:44:29 2021 ] Eval epoch: 71
[ Tue Feb  2 09:45:03 2021 ] 	Mean test loss of 258 batches: 0.5256426930427551.
[ Tue Feb  2 09:45:03 2021 ] 	Top1: 85.07%
[ Tue Feb  2 09:45:03 2021 ] 	Top5: 97.74%
[ Tue Feb  2 09:45:03 2021 ] Training epoch: 72
[ Tue Feb  2 09:45:08 2021 ] 	Batch(7/1252) done. Loss: 0.0661  lr:0.010000  network_time: 0.0764
[ Tue Feb  2 09:45:30 2021 ] 	Batch(107/1252) done. Loss: 0.0391  lr:0.010000  network_time: 0.0742
[ Tue Feb  2 09:45:52 2021 ] 	Batch(207/1252) done. Loss: 0.0762  lr:0.010000  network_time: 0.0955
[ Tue Feb  2 09:46:14 2021 ] 	Batch(307/1252) done. Loss: 0.1003  lr:0.010000  network_time: 0.0809
[ Tue Feb  2 09:46:37 2021 ] 	Batch(407/1252) done. Loss: 0.2307  lr:0.010000  network_time: 0.0818
[ Tue Feb  2 09:46:58 2021 ] 	Batch(507/1252) done. Loss: 0.1258  lr:0.010000  network_time: 0.0840
[ Tue Feb  2 09:47:21 2021 ] 	Batch(607/1252) done. Loss: 0.0920  lr:0.010000  network_time: 0.0877
[ Tue Feb  2 09:47:43 2021 ] 	Batch(707/1252) done. Loss: 0.0826  lr:0.010000  network_time: 0.0842
[ Tue Feb  2 09:48:05 2021 ] 	Batch(807/1252) done. Loss: 0.2676  lr:0.010000  network_time: 0.0807
[ Tue Feb  2 09:48:27 2021 ] 	Batch(907/1252) done. Loss: 0.0723  lr:0.010000  network_time: 0.0820
[ Tue Feb  2 09:48:49 2021 ] 	Batch(1007/1252) done. Loss: 0.1009  lr:0.010000  network_time: 0.0920
[ Tue Feb  2 09:49:11 2021 ] 	Batch(1107/1252) done. Loss: 0.2221  lr:0.010000  network_time: 0.0705
[ Tue Feb  2 09:49:33 2021 ] 	Batch(1207/1252) done. Loss: 0.1186  lr:0.010000  network_time: 0.0844
[ Tue Feb  2 09:49:43 2021 ] Eval epoch: 72
[ Tue Feb  2 09:50:17 2021 ] 	Mean test loss of 258 batches: 0.5374746322631836.
[ Tue Feb  2 09:50:17 2021 ] 	Top1: 84.42%
[ Tue Feb  2 09:50:17 2021 ] 	Top5: 97.66%
[ Tue Feb  2 09:50:17 2021 ] Training epoch: 73
[ Tue Feb  2 09:50:32 2021 ] 	Batch(55/1252) done. Loss: 0.0652  lr:0.010000  network_time: 0.0803
[ Tue Feb  2 09:50:54 2021 ] 	Batch(155/1252) done. Loss: 0.0601  lr:0.010000  network_time: 0.0901
[ Tue Feb  2 09:51:17 2021 ] 	Batch(255/1252) done. Loss: 0.0838  lr:0.010000  network_time: 0.0881
[ Tue Feb  2 09:51:39 2021 ] 	Batch(355/1252) done. Loss: 0.0665  lr:0.010000  network_time: 0.0903
[ Tue Feb  2 09:52:01 2021 ] 	Batch(455/1252) done. Loss: 0.0568  lr:0.010000  network_time: 0.0785
[ Tue Feb  2 09:52:23 2021 ] 	Batch(555/1252) done. Loss: 0.2141  lr:0.010000  network_time: 0.0917
[ Tue Feb  2 09:52:45 2021 ] 	Batch(655/1252) done. Loss: 0.0720  lr:0.010000  network_time: 0.0963
[ Tue Feb  2 09:53:07 2021 ] 	Batch(755/1252) done. Loss: 0.1389  lr:0.010000  network_time: 0.0824
[ Tue Feb  2 09:53:29 2021 ] 	Batch(855/1252) done. Loss: 0.1416  lr:0.010000  network_time: 0.0842
[ Tue Feb  2 09:53:51 2021 ] 	Batch(955/1252) done. Loss: 0.1282  lr:0.010000  network_time: 0.0837
[ Tue Feb  2 09:54:13 2021 ] 	Batch(1055/1252) done. Loss: 0.0914  lr:0.010000  network_time: 0.0957
[ Tue Feb  2 09:54:35 2021 ] 	Batch(1155/1252) done. Loss: 0.0748  lr:0.010000  network_time: 0.0818
[ Tue Feb  2 09:54:56 2021 ] Eval epoch: 73
[ Tue Feb  2 09:55:30 2021 ] 	Mean test loss of 258 batches: 0.5158731937408447.
[ Tue Feb  2 09:55:30 2021 ] 	Top1: 85.27%
[ Tue Feb  2 09:55:30 2021 ] 	Top5: 97.63%
[ Tue Feb  2 09:55:30 2021 ] Training epoch: 74
[ Tue Feb  2 09:55:35 2021 ] 	Batch(3/1252) done. Loss: 0.2216  lr:0.010000  network_time: 0.0824
[ Tue Feb  2 09:55:57 2021 ] 	Batch(103/1252) done. Loss: 0.1508  lr:0.010000  network_time: 0.0720
[ Tue Feb  2 09:56:19 2021 ] 	Batch(203/1252) done. Loss: 0.1508  lr:0.010000  network_time: 0.0686
[ Tue Feb  2 09:56:41 2021 ] 	Batch(303/1252) done. Loss: 0.2963  lr:0.010000  network_time: 0.0809
[ Tue Feb  2 09:57:03 2021 ] 	Batch(403/1252) done. Loss: 0.1531  lr:0.010000  network_time: 0.0836
[ Tue Feb  2 09:57:25 2021 ] 	Batch(503/1252) done. Loss: 0.1000  lr:0.010000  network_time: 0.0806
[ Tue Feb  2 09:57:47 2021 ] 	Batch(603/1252) done. Loss: 0.0767  lr:0.010000  network_time: 0.0818
[ Tue Feb  2 09:58:09 2021 ] 	Batch(703/1252) done. Loss: 0.1326  lr:0.010000  network_time: 0.0814
[ Tue Feb  2 09:58:31 2021 ] 	Batch(803/1252) done. Loss: 0.0939  lr:0.010000  network_time: 0.0794
[ Tue Feb  2 09:58:53 2021 ] 	Batch(903/1252) done. Loss: 0.1043  lr:0.010000  network_time: 0.0943
[ Tue Feb  2 09:59:15 2021 ] 	Batch(1003/1252) done. Loss: 0.3586  lr:0.010000  network_time: 0.0767
[ Tue Feb  2 09:59:37 2021 ] 	Batch(1103/1252) done. Loss: 0.1261  lr:0.010000  network_time: 0.0839
[ Tue Feb  2 09:59:58 2021 ] 	Batch(1203/1252) done. Loss: 0.1709  lr:0.010000  network_time: 0.0845
[ Tue Feb  2 10:00:09 2021 ] Eval epoch: 74
[ Tue Feb  2 10:00:43 2021 ] 	Mean test loss of 258 batches: 0.5143833756446838.
[ Tue Feb  2 10:00:43 2021 ] 	Top1: 85.16%
[ Tue Feb  2 10:00:43 2021 ] 	Top5: 97.76%
[ Tue Feb  2 10:00:43 2021 ] Training epoch: 75
[ Tue Feb  2 10:00:58 2021 ] 	Batch(51/1252) done. Loss: 0.1048  lr:0.010000  network_time: 0.0834
[ Tue Feb  2 10:01:20 2021 ] 	Batch(151/1252) done. Loss: 0.0432  lr:0.010000  network_time: 0.0796
[ Tue Feb  2 10:01:42 2021 ] 	Batch(251/1252) done. Loss: 0.0730  lr:0.010000  network_time: 0.0892
[ Tue Feb  2 10:02:04 2021 ] 	Batch(351/1252) done. Loss: 0.1470  lr:0.010000  network_time: 0.0754
[ Tue Feb  2 10:02:26 2021 ] 	Batch(451/1252) done. Loss: 0.1521  lr:0.010000  network_time: 0.0867
[ Tue Feb  2 10:02:49 2021 ] 	Batch(551/1252) done. Loss: 0.0514  lr:0.010000  network_time: 0.1008
[ Tue Feb  2 10:03:13 2021 ] 	Batch(651/1252) done. Loss: 0.0702  lr:0.010000  network_time: 0.1085
[ Tue Feb  2 10:03:37 2021 ] 	Batch(751/1252) done. Loss: 0.1677  lr:0.010000  network_time: 0.0948
[ Tue Feb  2 10:04:01 2021 ] 	Batch(851/1252) done. Loss: 0.2242  lr:0.010000  network_time: 0.0921
[ Tue Feb  2 10:04:24 2021 ] 	Batch(951/1252) done. Loss: 0.0889  lr:0.010000  network_time: 0.1024
[ Tue Feb  2 10:04:48 2021 ] 	Batch(1051/1252) done. Loss: 0.0744  lr:0.010000  network_time: 0.0913
[ Tue Feb  2 10:05:12 2021 ] 	Batch(1151/1252) done. Loss: 0.1451  lr:0.010000  network_time: 0.0920
[ Tue Feb  2 10:05:36 2021 ] 	Batch(1251/1252) done. Loss: 0.0696  lr:0.010000  network_time: 0.0967
[ Tue Feb  2 10:05:36 2021 ] Eval epoch: 75
[ Tue Feb  2 10:06:13 2021 ] 	Mean test loss of 258 batches: 0.5271158218383789.
[ Tue Feb  2 10:06:13 2021 ] 	Top1: 84.87%
[ Tue Feb  2 10:06:13 2021 ] 	Top5: 97.82%
[ Tue Feb  2 10:06:14 2021 ] Training epoch: 76
[ Tue Feb  2 10:06:40 2021 ] 	Batch(99/1252) done. Loss: 0.0873  lr:0.010000  network_time: 0.1180
[ Tue Feb  2 10:07:04 2021 ] 	Batch(199/1252) done. Loss: 0.0760  lr:0.010000  network_time: 0.1007
[ Tue Feb  2 10:07:27 2021 ] 	Batch(299/1252) done. Loss: 0.1637  lr:0.010000  network_time: 0.0922
[ Tue Feb  2 10:07:51 2021 ] 	Batch(399/1252) done. Loss: 0.1648  lr:0.010000  network_time: 0.0831
[ Tue Feb  2 10:08:14 2021 ] 	Batch(499/1252) done. Loss: 0.0763  lr:0.010000  network_time: 0.0916
[ Tue Feb  2 10:08:38 2021 ] 	Batch(599/1252) done. Loss: 0.0723  lr:0.010000  network_time: 0.0857
[ Tue Feb  2 10:09:01 2021 ] 	Batch(699/1252) done. Loss: 0.1546  lr:0.010000  network_time: 0.0951
[ Tue Feb  2 10:09:25 2021 ] 	Batch(799/1252) done. Loss: 0.0774  lr:0.010000  network_time: 0.0772
[ Tue Feb  2 10:09:48 2021 ] 	Batch(899/1252) done. Loss: 0.0452  lr:0.010000  network_time: 0.1064
[ Tue Feb  2 10:10:12 2021 ] 	Batch(999/1252) done. Loss: 0.1223  lr:0.010000  network_time: 0.1236
[ Tue Feb  2 10:10:35 2021 ] 	Batch(1099/1252) done. Loss: 0.1081  lr:0.010000  network_time: 0.1001
[ Tue Feb  2 10:10:59 2021 ] 	Batch(1199/1252) done. Loss: 0.1037  lr:0.010000  network_time: 0.0893
[ Tue Feb  2 10:11:11 2021 ] Eval epoch: 76
[ Tue Feb  2 10:11:47 2021 ] 	Mean test loss of 258 batches: 0.5146730542182922.
[ Tue Feb  2 10:11:48 2021 ] 	Top1: 85.04%
[ Tue Feb  2 10:11:48 2021 ] 	Top5: 97.71%
[ Tue Feb  2 10:11:48 2021 ] Training epoch: 77
[ Tue Feb  2 10:12:02 2021 ] 	Batch(47/1252) done. Loss: 0.0622  lr:0.010000  network_time: 0.0839
[ Tue Feb  2 10:12:25 2021 ] 	Batch(147/1252) done. Loss: 0.1258  lr:0.010000  network_time: 0.0852
[ Tue Feb  2 10:12:48 2021 ] 	Batch(247/1252) done. Loss: 0.0553  lr:0.010000  network_time: 0.0949
[ Tue Feb  2 10:13:10 2021 ] 	Batch(347/1252) done. Loss: 0.1204  lr:0.010000  network_time: 0.0859
[ Tue Feb  2 10:13:32 2021 ] 	Batch(447/1252) done. Loss: 0.1320  lr:0.010000  network_time: 0.0746
[ Tue Feb  2 10:13:54 2021 ] 	Batch(547/1252) done. Loss: 0.0556  lr:0.010000  network_time: 0.0940
[ Tue Feb  2 10:14:16 2021 ] 	Batch(647/1252) done. Loss: 0.0247  lr:0.010000  network_time: 0.0796
[ Tue Feb  2 10:14:38 2021 ] 	Batch(747/1252) done. Loss: 0.1093  lr:0.010000  network_time: 0.0813
[ Tue Feb  2 10:15:00 2021 ] 	Batch(847/1252) done. Loss: 0.1674  lr:0.010000  network_time: 0.0832
[ Tue Feb  2 10:15:22 2021 ] 	Batch(947/1252) done. Loss: 0.0588  lr:0.010000  network_time: 0.0725
[ Tue Feb  2 10:15:44 2021 ] 	Batch(1047/1252) done. Loss: 0.0944  lr:0.010000  network_time: 0.0862
[ Tue Feb  2 10:16:06 2021 ] 	Batch(1147/1252) done. Loss: 0.1770  lr:0.010000  network_time: 0.0790
[ Tue Feb  2 10:16:28 2021 ] 	Batch(1247/1252) done. Loss: 0.0968  lr:0.010000  network_time: 0.0881
[ Tue Feb  2 10:16:29 2021 ] Eval epoch: 77
[ Tue Feb  2 10:17:03 2021 ] 	Mean test loss of 258 batches: 0.530888020992279.
[ Tue Feb  2 10:17:04 2021 ] 	Top1: 84.95%
[ Tue Feb  2 10:17:04 2021 ] 	Top5: 97.56%
[ Tue Feb  2 10:17:04 2021 ] Training epoch: 78
[ Tue Feb  2 10:17:28 2021 ] 	Batch(95/1252) done. Loss: 0.0408  lr:0.010000  network_time: 0.0814
[ Tue Feb  2 10:17:50 2021 ] 	Batch(195/1252) done. Loss: 0.1232  lr:0.010000  network_time: 0.0791
[ Tue Feb  2 10:18:12 2021 ] 	Batch(295/1252) done. Loss: 0.2282  lr:0.010000  network_time: 0.0958
[ Tue Feb  2 10:18:34 2021 ] 	Batch(395/1252) done. Loss: 0.0615  lr:0.010000  network_time: 0.0958
[ Tue Feb  2 10:18:56 2021 ] 	Batch(495/1252) done. Loss: 0.0468  lr:0.010000  network_time: 0.0855
[ Tue Feb  2 10:19:18 2021 ] 	Batch(595/1252) done. Loss: 0.0737  lr:0.010000  network_time: 0.0940
[ Tue Feb  2 10:19:40 2021 ] 	Batch(695/1252) done. Loss: 0.0315  lr:0.010000  network_time: 0.0872
[ Tue Feb  2 10:20:03 2021 ] 	Batch(795/1252) done. Loss: 0.1037  lr:0.010000  network_time: 0.0875
[ Tue Feb  2 10:20:25 2021 ] 	Batch(895/1252) done. Loss: 0.0784  lr:0.010000  network_time: 0.1030
[ Tue Feb  2 10:20:47 2021 ] 	Batch(995/1252) done. Loss: 0.0771  lr:0.010000  network_time: 0.0983
[ Tue Feb  2 10:21:09 2021 ] 	Batch(1095/1252) done. Loss: 0.0863  lr:0.010000  network_time: 0.0848
[ Tue Feb  2 10:21:31 2021 ] 	Batch(1195/1252) done. Loss: 0.2194  lr:0.010000  network_time: 0.0838
[ Tue Feb  2 10:21:44 2021 ] Eval epoch: 78
[ Tue Feb  2 10:22:18 2021 ] 	Mean test loss of 258 batches: 0.5372651815414429.
[ Tue Feb  2 10:22:18 2021 ] 	Top1: 84.49%
[ Tue Feb  2 10:22:18 2021 ] 	Top5: 97.70%
[ Tue Feb  2 10:22:18 2021 ] Training epoch: 79
[ Tue Feb  2 10:22:31 2021 ] 	Batch(43/1252) done. Loss: 0.1437  lr:0.010000  network_time: 0.0593
[ Tue Feb  2 10:22:53 2021 ] 	Batch(143/1252) done. Loss: 0.0952  lr:0.010000  network_time: 0.0874
[ Tue Feb  2 10:23:15 2021 ] 	Batch(243/1252) done. Loss: 0.1153  lr:0.010000  network_time: 0.0886
[ Tue Feb  2 10:23:37 2021 ] 	Batch(343/1252) done. Loss: 0.0880  lr:0.010000  network_time: 0.0861
[ Tue Feb  2 10:24:00 2021 ] 	Batch(443/1252) done. Loss: 0.1420  lr:0.010000  network_time: 0.1132
[ Tue Feb  2 10:24:22 2021 ] 	Batch(543/1252) done. Loss: 0.1648  lr:0.010000  network_time: 0.0762
[ Tue Feb  2 10:24:44 2021 ] 	Batch(643/1252) done. Loss: 0.0499  lr:0.010000  network_time: 0.0695
[ Tue Feb  2 10:25:06 2021 ] 	Batch(743/1252) done. Loss: 0.1360  lr:0.010000  network_time: 0.0892
[ Tue Feb  2 10:25:28 2021 ] 	Batch(843/1252) done. Loss: 0.0535  lr:0.010000  network_time: 0.0798
[ Tue Feb  2 10:25:50 2021 ] 	Batch(943/1252) done. Loss: 0.1620  lr:0.010000  network_time: 0.0915
[ Tue Feb  2 10:26:12 2021 ] 	Batch(1043/1252) done. Loss: 0.0716  lr:0.010000  network_time: 0.0862
[ Tue Feb  2 10:26:34 2021 ] 	Batch(1143/1252) done. Loss: 0.1319  lr:0.010000  network_time: 0.0832
[ Tue Feb  2 10:26:57 2021 ] 	Batch(1243/1252) done. Loss: 0.0489  lr:0.010000  network_time: 0.0903
[ Tue Feb  2 10:26:59 2021 ] Eval epoch: 79
[ Tue Feb  2 10:27:33 2021 ] 	Mean test loss of 258 batches: 0.5364495515823364.
[ Tue Feb  2 10:27:33 2021 ] 	Top1: 84.53%
[ Tue Feb  2 10:27:33 2021 ] 	Top5: 97.59%
[ Tue Feb  2 10:27:33 2021 ] Training epoch: 80
[ Tue Feb  2 10:27:56 2021 ] 	Batch(91/1252) done. Loss: 0.0305  lr:0.010000  network_time: 0.0765
[ Tue Feb  2 10:28:18 2021 ] 	Batch(191/1252) done. Loss: 0.1162  lr:0.010000  network_time: 0.0728
[ Tue Feb  2 10:28:40 2021 ] 	Batch(291/1252) done. Loss: 0.0958  lr:0.010000  network_time: 0.0764
[ Tue Feb  2 10:29:02 2021 ] 	Batch(391/1252) done. Loss: 0.0563  lr:0.010000  network_time: 0.0803
[ Tue Feb  2 10:29:24 2021 ] 	Batch(491/1252) done. Loss: 0.1263  lr:0.010000  network_time: 0.0776
[ Tue Feb  2 10:29:46 2021 ] 	Batch(591/1252) done. Loss: 0.0435  lr:0.010000  network_time: 0.0866
[ Tue Feb  2 10:30:08 2021 ] 	Batch(691/1252) done. Loss: 0.0849  lr:0.010000  network_time: 0.1000
[ Tue Feb  2 10:30:30 2021 ] 	Batch(791/1252) done. Loss: 0.0296  lr:0.010000  network_time: 0.0848
[ Tue Feb  2 10:30:52 2021 ] 	Batch(891/1252) done. Loss: 0.2186  lr:0.010000  network_time: 0.0900
[ Tue Feb  2 10:31:14 2021 ] 	Batch(991/1252) done. Loss: 0.0818  lr:0.010000  network_time: 0.0884
[ Tue Feb  2 10:31:36 2021 ] 	Batch(1091/1252) done. Loss: 0.2152  lr:0.010000  network_time: 0.0859
[ Tue Feb  2 10:31:58 2021 ] 	Batch(1191/1252) done. Loss: 0.0375  lr:0.010000  network_time: 0.0864
[ Tue Feb  2 10:32:12 2021 ] Eval epoch: 80
[ Tue Feb  2 10:32:46 2021 ] 	Mean test loss of 258 batches: 0.534456193447113.
[ Tue Feb  2 10:32:46 2021 ] 	Top1: 84.72%
[ Tue Feb  2 10:32:46 2021 ] 	Top5: 97.59%
[ Tue Feb  2 10:32:46 2021 ] Training epoch: 81
[ Tue Feb  2 10:32:58 2021 ] 	Batch(39/1252) done. Loss: 0.0207  lr:0.001000  network_time: 0.0857
[ Tue Feb  2 10:33:20 2021 ] 	Batch(139/1252) done. Loss: 0.0631  lr:0.001000  network_time: 0.0930
[ Tue Feb  2 10:33:42 2021 ] 	Batch(239/1252) done. Loss: 0.0858  lr:0.001000  network_time: 0.0841
[ Tue Feb  2 10:34:04 2021 ] 	Batch(339/1252) done. Loss: 0.1529  lr:0.001000  network_time: 0.0875
[ Tue Feb  2 10:34:26 2021 ] 	Batch(439/1252) done. Loss: 0.1080  lr:0.001000  network_time: 0.0826
[ Tue Feb  2 10:34:48 2021 ] 	Batch(539/1252) done. Loss: 0.0903  lr:0.001000  network_time: 0.0838
[ Tue Feb  2 10:35:10 2021 ] 	Batch(639/1252) done. Loss: 0.0526  lr:0.001000  network_time: 0.0840
[ Tue Feb  2 10:35:32 2021 ] 	Batch(739/1252) done. Loss: 0.0491  lr:0.001000  network_time: 0.0808
[ Tue Feb  2 10:35:54 2021 ] 	Batch(839/1252) done. Loss: 0.0303  lr:0.001000  network_time: 0.0902
[ Tue Feb  2 10:36:16 2021 ] 	Batch(939/1252) done. Loss: 0.0661  lr:0.001000  network_time: 0.0785
[ Tue Feb  2 10:36:38 2021 ] 	Batch(1039/1252) done. Loss: 0.0992  lr:0.001000  network_time: 0.0896
[ Tue Feb  2 10:37:00 2021 ] 	Batch(1139/1252) done. Loss: 0.0584  lr:0.001000  network_time: 0.0796
[ Tue Feb  2 10:37:22 2021 ] 	Batch(1239/1252) done. Loss: 0.0810  lr:0.001000  network_time: 0.0782
[ Tue Feb  2 10:37:25 2021 ] Eval epoch: 81
[ Tue Feb  2 10:37:59 2021 ] 	Mean test loss of 258 batches: 0.5219265222549438.
[ Tue Feb  2 10:37:59 2021 ] 	Top1: 85.29%
[ Tue Feb  2 10:37:59 2021 ] 	Top5: 97.71%
[ Tue Feb  2 10:38:00 2021 ] Training epoch: 82
[ Tue Feb  2 10:38:22 2021 ] 	Batch(87/1252) done. Loss: 0.0902  lr:0.001000  network_time: 0.0923
[ Tue Feb  2 10:38:44 2021 ] 	Batch(187/1252) done. Loss: 0.1347  lr:0.001000  network_time: 0.0793
[ Tue Feb  2 10:39:06 2021 ] 	Batch(287/1252) done. Loss: 0.0748  lr:0.001000  network_time: 0.0744
[ Tue Feb  2 10:39:28 2021 ] 	Batch(387/1252) done. Loss: 0.1522  lr:0.001000  network_time: 0.0839
[ Tue Feb  2 10:39:50 2021 ] 	Batch(487/1252) done. Loss: 0.0396  lr:0.001000  network_time: 0.0834
[ Tue Feb  2 10:40:11 2021 ] 	Batch(587/1252) done. Loss: 0.1060  lr:0.001000  network_time: 0.0829
[ Tue Feb  2 10:40:34 2021 ] 	Batch(687/1252) done. Loss: 0.0232  lr:0.001000  network_time: 0.0969
[ Tue Feb  2 10:40:56 2021 ] 	Batch(787/1252) done. Loss: 0.0588  lr:0.001000  network_time: 0.0714
[ Tue Feb  2 10:41:18 2021 ] 	Batch(887/1252) done. Loss: 0.1394  lr:0.001000  network_time: 0.0941
[ Tue Feb  2 10:41:40 2021 ] 	Batch(987/1252) done. Loss: 0.0513  lr:0.001000  network_time: 0.0862
[ Tue Feb  2 10:42:02 2021 ] 	Batch(1087/1252) done. Loss: 0.0456  lr:0.001000  network_time: 0.1006
[ Tue Feb  2 10:42:24 2021 ] 	Batch(1187/1252) done. Loss: 0.0951  lr:0.001000  network_time: 0.0850
[ Tue Feb  2 10:42:38 2021 ] Eval epoch: 82
[ Tue Feb  2 10:43:12 2021 ] 	Mean test loss of 258 batches: 0.5212866067886353.
[ Tue Feb  2 10:43:12 2021 ] 	Top1: 85.53%
[ Tue Feb  2 10:43:13 2021 ] 	Top5: 97.68%
[ Tue Feb  2 10:43:13 2021 ] Training epoch: 83
[ Tue Feb  2 10:43:23 2021 ] 	Batch(35/1252) done. Loss: 0.0287  lr:0.001000  network_time: 0.0770
[ Tue Feb  2 10:43:45 2021 ] 	Batch(135/1252) done. Loss: 0.0733  lr:0.001000  network_time: 0.0857
[ Tue Feb  2 10:44:07 2021 ] 	Batch(235/1252) done. Loss: 0.0952  lr:0.001000  network_time: 0.0865
[ Tue Feb  2 10:44:29 2021 ] 	Batch(335/1252) done. Loss: 0.0788  lr:0.001000  network_time: 0.0946
[ Tue Feb  2 10:44:51 2021 ] 	Batch(435/1252) done. Loss: 0.0836  lr:0.001000  network_time: 0.0838
[ Tue Feb  2 10:45:13 2021 ] 	Batch(535/1252) done. Loss: 0.1351  lr:0.001000  network_time: 0.0854
[ Tue Feb  2 10:45:35 2021 ] 	Batch(635/1252) done. Loss: 0.0267  lr:0.001000  network_time: 0.0907
[ Tue Feb  2 10:45:57 2021 ] 	Batch(735/1252) done. Loss: 0.1318  lr:0.001000  network_time: 0.0798
[ Tue Feb  2 10:46:19 2021 ] 	Batch(835/1252) done. Loss: 0.0555  lr:0.001000  network_time: 0.0837
[ Tue Feb  2 10:46:41 2021 ] 	Batch(935/1252) done. Loss: 0.0258  lr:0.001000  network_time: 0.0839
[ Tue Feb  2 10:47:04 2021 ] 	Batch(1035/1252) done. Loss: 0.0661  lr:0.001000  network_time: 0.0903
[ Tue Feb  2 10:47:25 2021 ] 	Batch(1135/1252) done. Loss: 0.0208  lr:0.001000  network_time: 0.0873
[ Tue Feb  2 10:47:47 2021 ] 	Batch(1235/1252) done. Loss: 0.0997  lr:0.001000  network_time: 0.0723
[ Tue Feb  2 10:47:51 2021 ] Eval epoch: 83
[ Tue Feb  2 10:48:26 2021 ] 	Mean test loss of 258 batches: 0.5217751860618591.
[ Tue Feb  2 10:48:26 2021 ] 	Top1: 85.40%
[ Tue Feb  2 10:48:26 2021 ] 	Top5: 97.65%
[ Tue Feb  2 10:48:26 2021 ] Training epoch: 84
[ Tue Feb  2 10:48:48 2021 ] 	Batch(83/1252) done. Loss: 0.0518  lr:0.001000  network_time: 0.0774
[ Tue Feb  2 10:49:10 2021 ] 	Batch(183/1252) done. Loss: 0.0353  lr:0.001000  network_time: 0.0990
[ Tue Feb  2 10:49:31 2021 ] 	Batch(283/1252) done. Loss: 0.0352  lr:0.001000  network_time: 0.0783
[ Tue Feb  2 10:49:53 2021 ] 	Batch(383/1252) done. Loss: 0.0329  lr:0.001000  network_time: 0.0771
[ Tue Feb  2 10:50:15 2021 ] 	Batch(483/1252) done. Loss: 0.0409  lr:0.001000  network_time: 0.0821
[ Tue Feb  2 10:50:37 2021 ] 	Batch(583/1252) done. Loss: 0.1147  lr:0.001000  network_time: 0.0792
[ Tue Feb  2 10:50:59 2021 ] 	Batch(683/1252) done. Loss: 0.0380  lr:0.001000  network_time: 0.0713
[ Tue Feb  2 10:51:21 2021 ] 	Batch(783/1252) done. Loss: 0.0949  lr:0.001000  network_time: 0.0887
[ Tue Feb  2 10:51:44 2021 ] 	Batch(883/1252) done. Loss: 0.0721  lr:0.001000  network_time: 0.0960
[ Tue Feb  2 10:52:06 2021 ] 	Batch(983/1252) done. Loss: 0.0668  lr:0.001000  network_time: 0.0832
[ Tue Feb  2 10:52:28 2021 ] 	Batch(1083/1252) done. Loss: 0.0244  lr:0.001000  network_time: 0.1073
[ Tue Feb  2 10:52:51 2021 ] 	Batch(1183/1252) done. Loss: 0.0268  lr:0.001000  network_time: 0.0743
[ Tue Feb  2 10:53:06 2021 ] Eval epoch: 84
[ Tue Feb  2 10:53:41 2021 ] 	Mean test loss of 258 batches: 0.5295446515083313.
[ Tue Feb  2 10:53:41 2021 ] 	Top1: 85.54%
[ Tue Feb  2 10:53:41 2021 ] 	Top5: 97.70%
[ Tue Feb  2 10:53:41 2021 ] Training epoch: 85
[ Tue Feb  2 10:53:51 2021 ] 	Batch(31/1252) done. Loss: 0.0528  lr:0.001000  network_time: 0.0921
[ Tue Feb  2 10:54:13 2021 ] 	Batch(131/1252) done. Loss: 0.0451  lr:0.001000  network_time: 0.0849
[ Tue Feb  2 10:54:36 2021 ] 	Batch(231/1252) done. Loss: 0.0571  lr:0.001000  network_time: 0.0882
[ Tue Feb  2 10:54:58 2021 ] 	Batch(331/1252) done. Loss: 0.0289  lr:0.001000  network_time: 0.0821
[ Tue Feb  2 10:55:21 2021 ] 	Batch(431/1252) done. Loss: 0.0390  lr:0.001000  network_time: 0.0808
[ Tue Feb  2 10:55:43 2021 ] 	Batch(531/1252) done. Loss: 0.0639  lr:0.001000  network_time: 0.0893
[ Tue Feb  2 10:56:06 2021 ] 	Batch(631/1252) done. Loss: 0.0540  lr:0.001000  network_time: 0.0888
[ Tue Feb  2 10:56:28 2021 ] 	Batch(731/1252) done. Loss: 0.0163  lr:0.001000  network_time: 0.0863
[ Tue Feb  2 10:56:51 2021 ] 	Batch(831/1252) done. Loss: 0.1131  lr:0.001000  network_time: 0.0945
[ Tue Feb  2 10:57:13 2021 ] 	Batch(931/1252) done. Loss: 0.1038  lr:0.001000  network_time: 0.0854
[ Tue Feb  2 10:57:35 2021 ] 	Batch(1031/1252) done. Loss: 0.0996  lr:0.001000  network_time: 0.0828
[ Tue Feb  2 10:57:58 2021 ] 	Batch(1131/1252) done. Loss: 0.0258  lr:0.001000  network_time: 0.0839
[ Tue Feb  2 10:58:20 2021 ] 	Batch(1231/1252) done. Loss: 0.0356  lr:0.001000  network_time: 0.0847
[ Tue Feb  2 10:58:25 2021 ] Eval epoch: 85
[ Tue Feb  2 10:58:59 2021 ] 	Mean test loss of 258 batches: 0.535408079624176.
[ Tue Feb  2 10:58:59 2021 ] 	Top1: 85.29%
[ Tue Feb  2 10:58:59 2021 ] 	Top5: 97.64%
[ Tue Feb  2 10:58:59 2021 ] Training epoch: 86
[ Tue Feb  2 10:59:20 2021 ] 	Batch(79/1252) done. Loss: 0.0922  lr:0.001000  network_time: 0.0737
[ Tue Feb  2 10:59:43 2021 ] 	Batch(179/1252) done. Loss: 0.0422  lr:0.001000  network_time: 0.0950
[ Tue Feb  2 11:00:05 2021 ] 	Batch(279/1252) done. Loss: 0.0261  lr:0.001000  network_time: 0.0970
[ Tue Feb  2 11:00:27 2021 ] 	Batch(379/1252) done. Loss: 0.0809  lr:0.001000  network_time: 0.0997
[ Tue Feb  2 11:00:50 2021 ] 	Batch(479/1252) done. Loss: 0.0690  lr:0.001000  network_time: 0.0821
[ Tue Feb  2 11:01:12 2021 ] 	Batch(579/1252) done. Loss: 0.0554  lr:0.001000  network_time: 0.0927
[ Tue Feb  2 11:01:34 2021 ] 	Batch(679/1252) done. Loss: 0.1798  lr:0.001000  network_time: 0.0852
[ Tue Feb  2 11:01:57 2021 ] 	Batch(779/1252) done. Loss: 0.0969  lr:0.001000  network_time: 0.1008
[ Tue Feb  2 11:02:19 2021 ] 	Batch(879/1252) done. Loss: 0.0483  lr:0.001000  network_time: 0.0928
[ Tue Feb  2 11:02:42 2021 ] 	Batch(979/1252) done. Loss: 0.0414  lr:0.001000  network_time: 0.0892
[ Tue Feb  2 11:03:04 2021 ] 	Batch(1079/1252) done. Loss: 0.0155  lr:0.001000  network_time: 0.0839
[ Tue Feb  2 11:03:26 2021 ] 	Batch(1179/1252) done. Loss: 0.0624  lr:0.001000  network_time: 0.0898
[ Tue Feb  2 11:03:42 2021 ] Eval epoch: 86
[ Tue Feb  2 11:04:17 2021 ] 	Mean test loss of 258 batches: 0.5282506346702576.
[ Tue Feb  2 11:04:17 2021 ] 	Top1: 85.54%
[ Tue Feb  2 11:04:17 2021 ] 	Top5: 97.67%
[ Tue Feb  2 11:04:17 2021 ] Training epoch: 87
[ Tue Feb  2 11:04:27 2021 ] 	Batch(27/1252) done. Loss: 0.0249  lr:0.001000  network_time: 0.0840
[ Tue Feb  2 11:04:49 2021 ] 	Batch(127/1252) done. Loss: 0.1227  lr:0.001000  network_time: 0.0828
[ Tue Feb  2 11:05:11 2021 ] 	Batch(227/1252) done. Loss: 0.0253  lr:0.001000  network_time: 0.0876
[ Tue Feb  2 11:05:34 2021 ] 	Batch(327/1252) done. Loss: 0.0872  lr:0.001000  network_time: 0.0927
[ Tue Feb  2 11:05:56 2021 ] 	Batch(427/1252) done. Loss: 0.0335  lr:0.001000  network_time: 0.0872
[ Tue Feb  2 11:06:19 2021 ] 	Batch(527/1252) done. Loss: 0.0606  lr:0.001000  network_time: 0.0753
[ Tue Feb  2 11:06:41 2021 ] 	Batch(627/1252) done. Loss: 0.0223  lr:0.001000  network_time: 0.0840
[ Tue Feb  2 11:07:04 2021 ] 	Batch(727/1252) done. Loss: 0.0234  lr:0.001000  network_time: 0.0815
[ Tue Feb  2 11:07:26 2021 ] 	Batch(827/1252) done. Loss: 0.0512  lr:0.001000  network_time: 0.1043
[ Tue Feb  2 11:07:48 2021 ] 	Batch(927/1252) done. Loss: 0.0494  lr:0.001000  network_time: 0.0936
[ Tue Feb  2 11:08:11 2021 ] 	Batch(1027/1252) done. Loss: 0.0759  lr:0.001000  network_time: 0.0948
[ Tue Feb  2 11:08:33 2021 ] 	Batch(1127/1252) done. Loss: 0.0611  lr:0.001000  network_time: 0.0900
[ Tue Feb  2 11:08:56 2021 ] 	Batch(1227/1252) done. Loss: 0.0540  lr:0.001000  network_time: 0.0983
[ Tue Feb  2 11:09:01 2021 ] Eval epoch: 87
[ Tue Feb  2 11:09:36 2021 ] 	Mean test loss of 258 batches: 0.5174376964569092.
[ Tue Feb  2 11:09:36 2021 ] 	Top1: 85.55%
[ Tue Feb  2 11:09:36 2021 ] 	Top5: 97.77%
[ Tue Feb  2 11:09:36 2021 ] Training epoch: 88
[ Tue Feb  2 11:09:56 2021 ] 	Batch(75/1252) done. Loss: 0.0340  lr:0.001000  network_time: 0.0815
[ Tue Feb  2 11:10:19 2021 ] 	Batch(175/1252) done. Loss: 0.0708  lr:0.001000  network_time: 0.0835
[ Tue Feb  2 11:10:41 2021 ] 	Batch(275/1252) done. Loss: 0.1020  lr:0.001000  network_time: 0.0988
[ Tue Feb  2 11:11:03 2021 ] 	Batch(375/1252) done. Loss: 0.0306  lr:0.001000  network_time: 0.0902
[ Tue Feb  2 11:11:25 2021 ] 	Batch(475/1252) done. Loss: 0.0291  lr:0.001000  network_time: 0.0991
[ Tue Feb  2 11:11:48 2021 ] 	Batch(575/1252) done. Loss: 0.0463  lr:0.001000  network_time: 0.0845
[ Tue Feb  2 11:12:10 2021 ] 	Batch(675/1252) done. Loss: 0.0893  lr:0.001000  network_time: 0.1087
[ Tue Feb  2 11:12:33 2021 ] 	Batch(775/1252) done. Loss: 0.0379  lr:0.001000  network_time: 0.0819
[ Tue Feb  2 11:12:55 2021 ] 	Batch(875/1252) done. Loss: 0.1125  lr:0.001000  network_time: 0.0751
[ Tue Feb  2 11:13:17 2021 ] 	Batch(975/1252) done. Loss: 0.0172  lr:0.001000  network_time: 0.0839
[ Tue Feb  2 11:13:40 2021 ] 	Batch(1075/1252) done. Loss: 0.0449  lr:0.001000  network_time: 0.0966
[ Tue Feb  2 11:14:02 2021 ] 	Batch(1175/1252) done. Loss: 0.0290  lr:0.001000  network_time: 0.0871
[ Tue Feb  2 11:14:19 2021 ] Eval epoch: 88
[ Tue Feb  2 11:14:54 2021 ] 	Mean test loss of 258 batches: 0.5161665678024292.
[ Tue Feb  2 11:14:54 2021 ] 	Top1: 85.65%
[ Tue Feb  2 11:14:54 2021 ] 	Top5: 97.70%
[ Tue Feb  2 11:14:54 2021 ] Training epoch: 89
[ Tue Feb  2 11:15:02 2021 ] 	Batch(23/1252) done. Loss: 0.0939  lr:0.001000  network_time: 0.0828
[ Tue Feb  2 11:15:25 2021 ] 	Batch(123/1252) done. Loss: 0.1075  lr:0.001000  network_time: 0.0864
[ Tue Feb  2 11:15:47 2021 ] 	Batch(223/1252) done. Loss: 0.0408  lr:0.001000  network_time: 0.0854
[ Tue Feb  2 11:16:09 2021 ] 	Batch(323/1252) done. Loss: 0.0667  lr:0.001000  network_time: 0.0894
[ Tue Feb  2 11:16:31 2021 ] 	Batch(423/1252) done. Loss: 0.0545  lr:0.001000  network_time: 0.0875
[ Tue Feb  2 11:16:54 2021 ] 	Batch(523/1252) done. Loss: 0.0547  lr:0.001000  network_time: 0.0861
[ Tue Feb  2 11:17:16 2021 ] 	Batch(623/1252) done. Loss: 0.0333  lr:0.001000  network_time: 0.1089
[ Tue Feb  2 11:17:39 2021 ] 	Batch(723/1252) done. Loss: 0.0351  lr:0.001000  network_time: 0.0803
[ Tue Feb  2 11:18:01 2021 ] 	Batch(823/1252) done. Loss: 0.0312  lr:0.001000  network_time: 0.0951
[ Tue Feb  2 11:18:23 2021 ] 	Batch(923/1252) done. Loss: 0.0523  lr:0.001000  network_time: 0.0887
[ Tue Feb  2 11:18:46 2021 ] 	Batch(1023/1252) done. Loss: 0.0332  lr:0.001000  network_time: 0.0796
[ Tue Feb  2 11:19:08 2021 ] 	Batch(1123/1252) done. Loss: 0.1075  lr:0.001000  network_time: 0.0863
[ Tue Feb  2 11:19:30 2021 ] 	Batch(1223/1252) done. Loss: 0.0926  lr:0.001000  network_time: 0.0731
[ Tue Feb  2 11:19:37 2021 ] Eval epoch: 89
[ Tue Feb  2 11:20:11 2021 ] 	Mean test loss of 258 batches: 0.5206111669540405.
[ Tue Feb  2 11:20:11 2021 ] 	Top1: 85.54%
[ Tue Feb  2 11:20:12 2021 ] 	Top5: 97.69%
[ Tue Feb  2 11:20:12 2021 ] Training epoch: 90
[ Tue Feb  2 11:20:31 2021 ] 	Batch(71/1252) done. Loss: 0.0178  lr:0.001000  network_time: 0.0853
[ Tue Feb  2 11:20:53 2021 ] 	Batch(171/1252) done. Loss: 0.0539  lr:0.001000  network_time: 0.0862
[ Tue Feb  2 11:21:16 2021 ] 	Batch(271/1252) done. Loss: 0.0414  lr:0.001000  network_time: 0.0812
[ Tue Feb  2 11:21:38 2021 ] 	Batch(371/1252) done. Loss: 0.0335  lr:0.001000  network_time: 0.0866
[ Tue Feb  2 11:22:01 2021 ] 	Batch(471/1252) done. Loss: 0.0315  lr:0.001000  network_time: 0.0842
[ Tue Feb  2 11:22:23 2021 ] 	Batch(571/1252) done. Loss: 0.0638  lr:0.001000  network_time: 0.0837
[ Tue Feb  2 11:22:45 2021 ] 	Batch(671/1252) done. Loss: 0.0852  lr:0.001000  network_time: 0.0903
[ Tue Feb  2 11:23:07 2021 ] 	Batch(771/1252) done. Loss: 0.0412  lr:0.001000  network_time: 0.0829
[ Tue Feb  2 11:23:29 2021 ] 	Batch(871/1252) done. Loss: 0.0436  lr:0.001000  network_time: 0.1313
[ Tue Feb  2 11:23:52 2021 ] 	Batch(971/1252) done. Loss: 0.0555  lr:0.001000  network_time: 0.0780
[ Tue Feb  2 11:24:14 2021 ] 	Batch(1071/1252) done. Loss: 0.0204  lr:0.001000  network_time: 0.0811
[ Tue Feb  2 11:24:37 2021 ] 	Batch(1171/1252) done. Loss: 0.0757  lr:0.001000  network_time: 0.0867
[ Tue Feb  2 11:24:55 2021 ] Eval epoch: 90
[ Tue Feb  2 11:25:29 2021 ] 	Mean test loss of 258 batches: 0.5268945097923279.
[ Tue Feb  2 11:25:29 2021 ] 	Top1: 85.39%
[ Tue Feb  2 11:25:29 2021 ] 	Top5: 97.67%
[ Tue Feb  2 11:25:29 2021 ] Training epoch: 91
[ Tue Feb  2 11:25:37 2021 ] 	Batch(19/1252) done. Loss: 0.0672  lr:0.001000  network_time: 0.0889
[ Tue Feb  2 11:25:59 2021 ] 	Batch(119/1252) done. Loss: 0.0336  lr:0.001000  network_time: 0.0857
[ Tue Feb  2 11:26:21 2021 ] 	Batch(219/1252) done. Loss: 0.0158  lr:0.001000  network_time: 0.0814
[ Tue Feb  2 11:26:43 2021 ] 	Batch(319/1252) done. Loss: 0.0731  lr:0.001000  network_time: 0.0922
[ Tue Feb  2 11:27:05 2021 ] 	Batch(419/1252) done. Loss: 0.0519  lr:0.001000  network_time: 0.0794
[ Tue Feb  2 11:27:27 2021 ] 	Batch(519/1252) done. Loss: 0.0866  lr:0.001000  network_time: 0.0936
[ Tue Feb  2 11:27:49 2021 ] 	Batch(619/1252) done. Loss: 0.0286  lr:0.001000  network_time: 0.1025
[ Tue Feb  2 11:28:11 2021 ] 	Batch(719/1252) done. Loss: 0.1331  lr:0.001000  network_time: 0.0781
[ Tue Feb  2 11:28:34 2021 ] 	Batch(819/1252) done. Loss: 0.0249  lr:0.001000  network_time: 0.0943
[ Tue Feb  2 11:28:56 2021 ] 	Batch(919/1252) done. Loss: 0.0362  lr:0.001000  network_time: 0.0828
[ Tue Feb  2 11:29:18 2021 ] 	Batch(1019/1252) done. Loss: 0.0312  lr:0.001000  network_time: 0.0866
[ Tue Feb  2 11:29:40 2021 ] 	Batch(1119/1252) done. Loss: 0.0432  lr:0.001000  network_time: 0.0874
[ Tue Feb  2 11:30:02 2021 ] 	Batch(1219/1252) done. Loss: 0.0672  lr:0.001000  network_time: 0.0800
[ Tue Feb  2 11:30:10 2021 ] Eval epoch: 91
[ Tue Feb  2 11:30:44 2021 ] 	Mean test loss of 258 batches: 0.5307554602622986.
[ Tue Feb  2 11:30:44 2021 ] 	Top1: 85.26%
[ Tue Feb  2 11:30:44 2021 ] 	Top5: 97.66%
[ Tue Feb  2 11:30:44 2021 ] Training epoch: 92
[ Tue Feb  2 11:31:02 2021 ] 	Batch(67/1252) done. Loss: 0.0136  lr:0.001000  network_time: 0.0859
[ Tue Feb  2 11:31:25 2021 ] 	Batch(167/1252) done. Loss: 0.1294  lr:0.001000  network_time: 0.0883
[ Tue Feb  2 11:31:47 2021 ] 	Batch(267/1252) done. Loss: 0.0327  lr:0.001000  network_time: 0.0784
[ Tue Feb  2 11:32:09 2021 ] 	Batch(367/1252) done. Loss: 0.0489  lr:0.001000  network_time: 0.0786
[ Tue Feb  2 11:32:31 2021 ] 	Batch(467/1252) done. Loss: 0.0988  lr:0.001000  network_time: 0.0793
[ Tue Feb  2 11:32:53 2021 ] 	Batch(567/1252) done. Loss: 0.0288  lr:0.001000  network_time: 0.0851
[ Tue Feb  2 11:33:16 2021 ] 	Batch(667/1252) done. Loss: 0.0433  lr:0.001000  network_time: 0.0902
[ Tue Feb  2 11:33:38 2021 ] 	Batch(767/1252) done. Loss: 0.0252  lr:0.001000  network_time: 0.0725
[ Tue Feb  2 11:34:00 2021 ] 	Batch(867/1252) done. Loss: 0.0479  lr:0.001000  network_time: 0.0977
[ Tue Feb  2 11:34:22 2021 ] 	Batch(967/1252) done. Loss: 0.0243  lr:0.001000  network_time: 0.0790
[ Tue Feb  2 11:34:45 2021 ] 	Batch(1067/1252) done. Loss: 0.0989  lr:0.001000  network_time: 0.0852
[ Tue Feb  2 11:35:07 2021 ] 	Batch(1167/1252) done. Loss: 0.1119  lr:0.001000  network_time: 0.0842
[ Tue Feb  2 11:35:26 2021 ] Eval epoch: 92
[ Tue Feb  2 11:36:00 2021 ] 	Mean test loss of 258 batches: 0.5172970294952393.
[ Tue Feb  2 11:36:00 2021 ] 	Top1: 85.59%
[ Tue Feb  2 11:36:00 2021 ] 	Top5: 97.72%
[ Tue Feb  2 11:36:00 2021 ] Training epoch: 93
[ Tue Feb  2 11:36:07 2021 ] 	Batch(15/1252) done. Loss: 0.0362  lr:0.001000  network_time: 0.0837
[ Tue Feb  2 11:36:29 2021 ] 	Batch(115/1252) done. Loss: 0.0256  lr:0.001000  network_time: 0.0851
[ Tue Feb  2 11:36:51 2021 ] 	Batch(215/1252) done. Loss: 0.0287  lr:0.001000  network_time: 0.1001
[ Tue Feb  2 11:37:13 2021 ] 	Batch(315/1252) done. Loss: 0.0563  lr:0.001000  network_time: 0.0875
[ Tue Feb  2 11:37:36 2021 ] 	Batch(415/1252) done. Loss: 0.0168  lr:0.001000  network_time: 0.0839
[ Tue Feb  2 11:37:58 2021 ] 	Batch(515/1252) done. Loss: 0.0233  lr:0.001000  network_time: 0.0923
[ Tue Feb  2 11:38:20 2021 ] 	Batch(615/1252) done. Loss: 0.0807  lr:0.001000  network_time: 0.0804
[ Tue Feb  2 11:38:42 2021 ] 	Batch(715/1252) done. Loss: 0.0567  lr:0.001000  network_time: 0.0984
[ Tue Feb  2 11:39:05 2021 ] 	Batch(815/1252) done. Loss: 0.0525  lr:0.001000  network_time: 0.0809
[ Tue Feb  2 11:39:27 2021 ] 	Batch(915/1252) done. Loss: 0.0180  lr:0.001000  network_time: 0.0860
[ Tue Feb  2 11:39:49 2021 ] 	Batch(1015/1252) done. Loss: 0.0458  lr:0.001000  network_time: 0.0808
[ Tue Feb  2 11:40:11 2021 ] 	Batch(1115/1252) done. Loss: 0.0147  lr:0.001000  network_time: 0.0836
[ Tue Feb  2 11:40:34 2021 ] 	Batch(1215/1252) done. Loss: 0.0311  lr:0.001000  network_time: 0.0873
[ Tue Feb  2 11:40:42 2021 ] Eval epoch: 93
[ Tue Feb  2 11:41:16 2021 ] 	Mean test loss of 258 batches: 0.5204243063926697.
[ Tue Feb  2 11:41:16 2021 ] 	Top1: 85.55%
[ Tue Feb  2 11:41:16 2021 ] 	Top5: 97.63%
[ Tue Feb  2 11:41:16 2021 ] Training epoch: 94
[ Tue Feb  2 11:41:34 2021 ] 	Batch(63/1252) done. Loss: 0.0138  lr:0.001000  network_time: 0.0786
[ Tue Feb  2 11:41:56 2021 ] 	Batch(163/1252) done. Loss: 0.0605  lr:0.001000  network_time: 0.0812
[ Tue Feb  2 11:42:18 2021 ] 	Batch(263/1252) done. Loss: 0.1097  lr:0.001000  network_time: 0.1028
[ Tue Feb  2 11:42:41 2021 ] 	Batch(363/1252) done. Loss: 0.1404  lr:0.001000  network_time: 0.0860
[ Tue Feb  2 11:43:03 2021 ] 	Batch(463/1252) done. Loss: 0.0313  lr:0.001000  network_time: 0.0799
[ Tue Feb  2 11:43:25 2021 ] 	Batch(563/1252) done. Loss: 0.0782  lr:0.001000  network_time: 0.0968
[ Tue Feb  2 11:43:48 2021 ] 	Batch(663/1252) done. Loss: 0.0285  lr:0.001000  network_time: 0.0876
[ Tue Feb  2 11:44:10 2021 ] 	Batch(763/1252) done. Loss: 0.0780  lr:0.001000  network_time: 0.0939
[ Tue Feb  2 11:44:32 2021 ] 	Batch(863/1252) done. Loss: 0.0202  lr:0.001000  network_time: 0.0861
[ Tue Feb  2 11:44:54 2021 ] 	Batch(963/1252) done. Loss: 0.0184  lr:0.001000  network_time: 0.0839
[ Tue Feb  2 11:45:16 2021 ] 	Batch(1063/1252) done. Loss: 0.0647  lr:0.001000  network_time: 0.0847
[ Tue Feb  2 11:45:39 2021 ] 	Batch(1163/1252) done. Loss: 0.0265  lr:0.001000  network_time: 0.1010
[ Tue Feb  2 11:45:58 2021 ] Eval epoch: 94
[ Tue Feb  2 11:46:33 2021 ] 	Mean test loss of 258 batches: 0.5185120105743408.
[ Tue Feb  2 11:46:33 2021 ] 	Top1: 85.75%
[ Tue Feb  2 11:46:33 2021 ] 	Top5: 97.73%
[ Tue Feb  2 11:46:33 2021 ] Training epoch: 95
[ Tue Feb  2 11:46:39 2021 ] 	Batch(11/1252) done. Loss: 0.0256  lr:0.001000  network_time: 0.0816
[ Tue Feb  2 11:47:01 2021 ] 	Batch(111/1252) done. Loss: 0.1042  lr:0.001000  network_time: 0.0835
[ Tue Feb  2 11:47:23 2021 ] 	Batch(211/1252) done. Loss: 0.0315  lr:0.001000  network_time: 0.0856
[ Tue Feb  2 11:47:45 2021 ] 	Batch(311/1252) done. Loss: 0.0315  lr:0.001000  network_time: 0.0924
[ Tue Feb  2 11:48:07 2021 ] 	Batch(411/1252) done. Loss: 0.0525  lr:0.001000  network_time: 0.0856
[ Tue Feb  2 11:48:30 2021 ] 	Batch(511/1252) done. Loss: 0.0673  lr:0.001000  network_time: 0.0930
[ Tue Feb  2 11:48:52 2021 ] 	Batch(611/1252) done. Loss: 0.0779  lr:0.001000  network_time: 0.0780
[ Tue Feb  2 11:49:14 2021 ] 	Batch(711/1252) done. Loss: 0.0370  lr:0.001000  network_time: 0.0872
[ Tue Feb  2 11:49:36 2021 ] 	Batch(811/1252) done. Loss: 0.0346  lr:0.001000  network_time: 0.0915
[ Tue Feb  2 11:49:58 2021 ] 	Batch(911/1252) done. Loss: 0.0729  lr:0.001000  network_time: 0.1037
[ Tue Feb  2 11:50:21 2021 ] 	Batch(1011/1252) done. Loss: 0.0641  lr:0.001000  network_time: 0.0923
[ Tue Feb  2 11:50:43 2021 ] 	Batch(1111/1252) done. Loss: 0.0686  lr:0.001000  network_time: 0.0847
[ Tue Feb  2 11:51:05 2021 ] 	Batch(1211/1252) done. Loss: 0.0421  lr:0.001000  network_time: 0.0868
[ Tue Feb  2 11:51:14 2021 ] Eval epoch: 95
[ Tue Feb  2 11:51:48 2021 ] 	Mean test loss of 258 batches: 0.5252206325531006.
[ Tue Feb  2 11:51:49 2021 ] 	Top1: 85.55%
[ Tue Feb  2 11:51:49 2021 ] 	Top5: 97.74%
[ Tue Feb  2 11:51:49 2021 ] Training epoch: 96
[ Tue Feb  2 11:52:06 2021 ] 	Batch(59/1252) done. Loss: 0.0660  lr:0.001000  network_time: 0.1063
[ Tue Feb  2 11:52:31 2021 ] 	Batch(159/1252) done. Loss: 0.0418  lr:0.001000  network_time: 0.1116
[ Tue Feb  2 11:52:55 2021 ] 	Batch(259/1252) done. Loss: 0.0299  lr:0.001000  network_time: 0.0921
[ Tue Feb  2 11:53:19 2021 ] 	Batch(359/1252) done. Loss: 0.0316  lr:0.001000  network_time: 0.1076
[ Tue Feb  2 11:53:43 2021 ] 	Batch(459/1252) done. Loss: 0.0495  lr:0.001000  network_time: 0.0903
[ Tue Feb  2 11:54:07 2021 ] 	Batch(559/1252) done. Loss: 0.0365  lr:0.001000  network_time: 0.0829
[ Tue Feb  2 11:54:32 2021 ] 	Batch(659/1252) done. Loss: 0.0959  lr:0.001000  network_time: 0.0927
[ Tue Feb  2 11:54:56 2021 ] 	Batch(759/1252) done. Loss: 0.0344  lr:0.001000  network_time: 0.0947
[ Tue Feb  2 11:55:20 2021 ] 	Batch(859/1252) done. Loss: 0.0178  lr:0.001000  network_time: 0.1033
[ Tue Feb  2 11:55:44 2021 ] 	Batch(959/1252) done. Loss: 0.0347  lr:0.001000  network_time: 0.0966
[ Tue Feb  2 11:56:08 2021 ] 	Batch(1059/1252) done. Loss: 0.0318  lr:0.001000  network_time: 0.0915
[ Tue Feb  2 11:56:33 2021 ] 	Batch(1159/1252) done. Loss: 0.0376  lr:0.001000  network_time: 0.1095
[ Tue Feb  2 11:56:55 2021 ] Eval epoch: 96
[ Tue Feb  2 11:57:32 2021 ] 	Mean test loss of 258 batches: 0.514654815196991.
[ Tue Feb  2 11:57:32 2021 ] 	Top1: 85.71%
[ Tue Feb  2 11:57:32 2021 ] 	Top5: 97.79%
[ Tue Feb  2 11:57:32 2021 ] Training epoch: 97
[ Tue Feb  2 11:57:37 2021 ] 	Batch(7/1252) done. Loss: 0.0386  lr:0.001000  network_time: 0.0999
[ Tue Feb  2 11:58:01 2021 ] 	Batch(107/1252) done. Loss: 0.0197  lr:0.001000  network_time: 0.0897
[ Tue Feb  2 11:58:25 2021 ] 	Batch(207/1252) done. Loss: 0.0284  lr:0.001000  network_time: 0.0882
[ Tue Feb  2 11:58:49 2021 ] 	Batch(307/1252) done. Loss: 0.0348  lr:0.001000  network_time: 0.0865
[ Tue Feb  2 11:59:13 2021 ] 	Batch(407/1252) done. Loss: 0.0362  lr:0.001000  network_time: 0.1018
[ Tue Feb  2 11:59:37 2021 ] 	Batch(507/1252) done. Loss: 0.0168  lr:0.001000  network_time: 0.0790
[ Tue Feb  2 12:00:02 2021 ] 	Batch(607/1252) done. Loss: 0.0357  lr:0.001000  network_time: 0.0950
[ Tue Feb  2 12:00:26 2021 ] 	Batch(707/1252) done. Loss: 0.0483  lr:0.001000  network_time: 0.0963
[ Tue Feb  2 12:00:50 2021 ] 	Batch(807/1252) done. Loss: 0.0549  lr:0.001000  network_time: 0.0926
[ Tue Feb  2 12:01:14 2021 ] 	Batch(907/1252) done. Loss: 0.0405  lr:0.001000  network_time: 0.0951
[ Tue Feb  2 12:01:38 2021 ] 	Batch(1007/1252) done. Loss: 0.0681  lr:0.001000  network_time: 0.0972
[ Tue Feb  2 12:02:02 2021 ] 	Batch(1107/1252) done. Loss: 0.0305  lr:0.001000  network_time: 0.0827
[ Tue Feb  2 12:02:26 2021 ] 	Batch(1207/1252) done. Loss: 0.0336  lr:0.001000  network_time: 0.0963
[ Tue Feb  2 12:02:37 2021 ] Eval epoch: 97
[ Tue Feb  2 12:03:12 2021 ] 	Mean test loss of 258 batches: 0.5110501050949097.
[ Tue Feb  2 12:03:13 2021 ] 	Top1: 85.80%
[ Tue Feb  2 12:03:13 2021 ] 	Top5: 97.74%
[ Tue Feb  2 12:03:13 2021 ] Training epoch: 98
[ Tue Feb  2 12:03:29 2021 ] 	Batch(55/1252) done. Loss: 0.0573  lr:0.001000  network_time: 0.0988
[ Tue Feb  2 12:03:52 2021 ] 	Batch(155/1252) done. Loss: 0.0121  lr:0.001000  network_time: 0.0972
[ Tue Feb  2 12:04:15 2021 ] 	Batch(255/1252) done. Loss: 0.0219  lr:0.001000  network_time: 0.0977
[ Tue Feb  2 12:04:38 2021 ] 	Batch(355/1252) done. Loss: 0.0343  lr:0.001000  network_time: 0.0910
[ Tue Feb  2 12:05:01 2021 ] 	Batch(455/1252) done. Loss: 0.1416  lr:0.001000  network_time: 0.1136
[ Tue Feb  2 12:05:24 2021 ] 	Batch(555/1252) done. Loss: 0.0143  lr:0.001000  network_time: 0.0890
[ Tue Feb  2 12:05:47 2021 ] 	Batch(655/1252) done. Loss: 0.0394  lr:0.001000  network_time: 0.1099
[ Tue Feb  2 12:06:10 2021 ] 	Batch(755/1252) done. Loss: 0.0524  lr:0.001000  network_time: 0.0969
[ Tue Feb  2 12:06:33 2021 ] 	Batch(855/1252) done. Loss: 0.0341  lr:0.001000  network_time: 0.1048
[ Tue Feb  2 12:06:56 2021 ] 	Batch(955/1252) done. Loss: 0.0358  lr:0.001000  network_time: 0.1072
[ Tue Feb  2 12:07:19 2021 ] 	Batch(1055/1252) done. Loss: 0.0420  lr:0.001000  network_time: 0.0907
[ Tue Feb  2 12:07:42 2021 ] 	Batch(1155/1252) done. Loss: 0.0191  lr:0.001000  network_time: 0.1009
[ Tue Feb  2 12:08:04 2021 ] Eval epoch: 98
[ Tue Feb  2 12:08:39 2021 ] 	Mean test loss of 258 batches: 0.5331078171730042.
[ Tue Feb  2 12:08:39 2021 ] 	Top1: 85.18%
[ Tue Feb  2 12:08:39 2021 ] 	Top5: 97.69%
[ Tue Feb  2 12:08:39 2021 ] Training epoch: 99
[ Tue Feb  2 12:08:44 2021 ] 	Batch(3/1252) done. Loss: 0.0352  lr:0.001000  network_time: 0.1115
[ Tue Feb  2 12:09:07 2021 ] 	Batch(103/1252) done. Loss: 0.0360  lr:0.001000  network_time: 0.0999
[ Tue Feb  2 12:09:30 2021 ] 	Batch(203/1252) done. Loss: 0.0103  lr:0.001000  network_time: 0.1025
[ Tue Feb  2 12:09:53 2021 ] 	Batch(303/1252) done. Loss: 0.0593  lr:0.001000  network_time: 0.1044
[ Tue Feb  2 12:10:16 2021 ] 	Batch(403/1252) done. Loss: 0.0323  lr:0.001000  network_time: 0.0915
[ Tue Feb  2 12:10:39 2021 ] 	Batch(503/1252) done. Loss: 0.0664  lr:0.001000  network_time: 0.0977
[ Tue Feb  2 12:11:02 2021 ] 	Batch(603/1252) done. Loss: 0.0274  lr:0.001000  network_time: 0.0807
[ Tue Feb  2 12:11:24 2021 ] 	Batch(703/1252) done. Loss: 0.0737  lr:0.001000  network_time: 0.0872
[ Tue Feb  2 12:11:47 2021 ] 	Batch(803/1252) done. Loss: 0.0296  lr:0.001000  network_time: 0.1075
[ Tue Feb  2 12:12:10 2021 ] 	Batch(903/1252) done. Loss: 0.0513  lr:0.001000  network_time: 0.1031
[ Tue Feb  2 12:12:33 2021 ] 	Batch(1003/1252) done. Loss: 0.0217  lr:0.001000  network_time: 0.0830
[ Tue Feb  2 12:12:56 2021 ] 	Batch(1103/1252) done. Loss: 0.1273  lr:0.001000  network_time: 0.0967
[ Tue Feb  2 12:13:19 2021 ] 	Batch(1203/1252) done. Loss: 0.0316  lr:0.001000  network_time: 0.0905
[ Tue Feb  2 12:13:30 2021 ] Eval epoch: 99
[ Tue Feb  2 12:14:05 2021 ] 	Mean test loss of 258 batches: 0.520084798336029.
[ Tue Feb  2 12:14:05 2021 ] 	Top1: 85.46%
[ Tue Feb  2 12:14:05 2021 ] 	Top5: 97.78%
[ Tue Feb  2 12:14:05 2021 ] Training epoch: 100
[ Tue Feb  2 12:14:20 2021 ] 	Batch(51/1252) done. Loss: 0.0509  lr:0.001000  network_time: 0.0987
[ Tue Feb  2 12:14:43 2021 ] 	Batch(151/1252) done. Loss: 0.0353  lr:0.001000  network_time: 0.0996
[ Tue Feb  2 12:15:07 2021 ] 	Batch(251/1252) done. Loss: 0.0805  lr:0.001000  network_time: 0.1060
[ Tue Feb  2 12:15:29 2021 ] 	Batch(351/1252) done. Loss: 0.0480  lr:0.001000  network_time: 0.0893
[ Tue Feb  2 12:15:52 2021 ] 	Batch(451/1252) done. Loss: 0.0692  lr:0.001000  network_time: 0.0891
[ Tue Feb  2 12:16:15 2021 ] 	Batch(551/1252) done. Loss: 0.0694  lr:0.001000  network_time: 0.1061
[ Tue Feb  2 12:16:38 2021 ] 	Batch(651/1252) done. Loss: 0.0643  lr:0.001000  network_time: 0.0958
[ Tue Feb  2 12:17:01 2021 ] 	Batch(751/1252) done. Loss: 0.0308  lr:0.001000  network_time: 0.0906
[ Tue Feb  2 12:17:24 2021 ] 	Batch(851/1252) done. Loss: 0.0689  lr:0.001000  network_time: 0.1017
[ Tue Feb  2 12:17:46 2021 ] 	Batch(951/1252) done. Loss: 0.0246  lr:0.001000  network_time: 0.0910
[ Tue Feb  2 12:18:09 2021 ] 	Batch(1051/1252) done. Loss: 0.0456  lr:0.001000  network_time: 0.1159
[ Tue Feb  2 12:18:32 2021 ] 	Batch(1151/1252) done. Loss: 0.0335  lr:0.001000  network_time: 0.1118
[ Tue Feb  2 12:18:55 2021 ] 	Batch(1251/1252) done. Loss: 0.0589  lr:0.001000  network_time: 0.0899
[ Tue Feb  2 12:18:55 2021 ] Eval epoch: 100
[ Tue Feb  2 12:19:30 2021 ] 	Mean test loss of 258 batches: 0.5300157070159912.
[ Tue Feb  2 12:19:30 2021 ] 	Top1: 85.65%
[ Tue Feb  2 12:19:30 2021 ] 	Top5: 97.76%
[ Tue Feb  2 12:19:30 2021 ] Training epoch: 101
[ Tue Feb  2 12:19:57 2021 ] 	Batch(99/1252) done. Loss: 0.0272  lr:0.000100  network_time: 0.0916
[ Tue Feb  2 12:20:19 2021 ] 	Batch(199/1252) done. Loss: 0.0547  lr:0.000100  network_time: 0.0944
[ Tue Feb  2 12:20:42 2021 ] 	Batch(299/1252) done. Loss: 0.0190  lr:0.000100  network_time: 0.1236
[ Tue Feb  2 12:21:05 2021 ] 	Batch(399/1252) done. Loss: 0.0404  lr:0.000100  network_time: 0.1268
[ Tue Feb  2 12:21:28 2021 ] 	Batch(499/1252) done. Loss: 0.0239  lr:0.000100  network_time: 0.0933
[ Tue Feb  2 12:21:51 2021 ] 	Batch(599/1252) done. Loss: 0.0541  lr:0.000100  network_time: 0.1001
[ Tue Feb  2 12:22:14 2021 ] 	Batch(699/1252) done. Loss: 0.0396  lr:0.000100  network_time: 0.1057
[ Tue Feb  2 12:22:37 2021 ] 	Batch(799/1252) done. Loss: 0.0122  lr:0.000100  network_time: 0.1109
[ Tue Feb  2 12:23:01 2021 ] 	Batch(899/1252) done. Loss: 0.0595  lr:0.000100  network_time: 0.0994
[ Tue Feb  2 12:23:24 2021 ] 	Batch(999/1252) done. Loss: 0.0691  lr:0.000100  network_time: 0.1038
[ Tue Feb  2 12:23:47 2021 ] 	Batch(1099/1252) done. Loss: 0.0472  lr:0.000100  network_time: 0.0985
[ Tue Feb  2 12:24:10 2021 ] 	Batch(1199/1252) done. Loss: 0.0754  lr:0.000100  network_time: 0.1105
[ Tue Feb  2 12:24:22 2021 ] Eval epoch: 101
[ Tue Feb  2 12:24:58 2021 ] 	Mean test loss of 258 batches: 0.5188906192779541.
[ Tue Feb  2 12:24:58 2021 ] 	Top1: 85.64%
[ Tue Feb  2 12:24:58 2021 ] 	Top5: 97.73%
[ Tue Feb  2 12:24:58 2021 ] Training epoch: 102
[ Tue Feb  2 12:25:12 2021 ] 	Batch(47/1252) done. Loss: 0.0167  lr:0.000100  network_time: 0.1065
[ Tue Feb  2 12:25:35 2021 ] 	Batch(147/1252) done. Loss: 0.0577  lr:0.000100  network_time: 0.0957
[ Tue Feb  2 12:25:58 2021 ] 	Batch(247/1252) done. Loss: 0.0256  lr:0.000100  network_time: 0.1062
[ Tue Feb  2 12:26:21 2021 ] 	Batch(347/1252) done. Loss: 0.0487  lr:0.000100  network_time: 0.0886
[ Tue Feb  2 12:26:44 2021 ] 	Batch(447/1252) done. Loss: 0.0404  lr:0.000100  network_time: 0.1033
[ Tue Feb  2 12:27:07 2021 ] 	Batch(547/1252) done. Loss: 0.0225  lr:0.000100  network_time: 0.0955
[ Tue Feb  2 12:27:30 2021 ] 	Batch(647/1252) done. Loss: 0.0337  lr:0.000100  network_time: 0.1003
[ Tue Feb  2 12:27:53 2021 ] 	Batch(747/1252) done. Loss: 0.0147  lr:0.000100  network_time: 0.0927
[ Tue Feb  2 12:28:17 2021 ] 	Batch(847/1252) done. Loss: 0.0634  lr:0.000100  network_time: 0.1133
[ Tue Feb  2 12:28:40 2021 ] 	Batch(947/1252) done. Loss: 0.0512  lr:0.000100  network_time: 0.1083
[ Tue Feb  2 12:29:03 2021 ] 	Batch(1047/1252) done. Loss: 0.0255  lr:0.000100  network_time: 0.0949
[ Tue Feb  2 12:29:26 2021 ] 	Batch(1147/1252) done. Loss: 0.0167  lr:0.000100  network_time: 0.0909
[ Tue Feb  2 12:29:49 2021 ] 	Batch(1247/1252) done. Loss: 0.0694  lr:0.000100  network_time: 0.1049
[ Tue Feb  2 12:29:51 2021 ] Eval epoch: 102
[ Tue Feb  2 12:30:25 2021 ] 	Mean test loss of 258 batches: 0.5315766930580139.
[ Tue Feb  2 12:30:26 2021 ] 	Top1: 85.51%
[ Tue Feb  2 12:30:26 2021 ] 	Top5: 97.71%
[ Tue Feb  2 12:30:26 2021 ] Training epoch: 103
[ Tue Feb  2 12:30:51 2021 ] 	Batch(95/1252) done. Loss: 0.0303  lr:0.000100  network_time: 0.0990
[ Tue Feb  2 12:31:14 2021 ] 	Batch(195/1252) done. Loss: 0.0372  lr:0.000100  network_time: 0.0983
[ Tue Feb  2 12:31:37 2021 ] 	Batch(295/1252) done. Loss: 0.0317  lr:0.000100  network_time: 0.0985
[ Tue Feb  2 12:32:01 2021 ] 	Batch(395/1252) done. Loss: 0.0459  lr:0.000100  network_time: 0.1073
[ Tue Feb  2 12:32:24 2021 ] 	Batch(495/1252) done. Loss: 0.0289  lr:0.000100  network_time: 0.1107
[ Tue Feb  2 12:32:47 2021 ] 	Batch(595/1252) done. Loss: 0.0091  lr:0.000100  network_time: 0.0927
[ Tue Feb  2 12:33:10 2021 ] 	Batch(695/1252) done. Loss: 0.0338  lr:0.000100  network_time: 0.1035
[ Tue Feb  2 12:33:33 2021 ] 	Batch(795/1252) done. Loss: 0.0386  lr:0.000100  network_time: 0.1025
[ Tue Feb  2 12:33:57 2021 ] 	Batch(895/1252) done. Loss: 0.0208  lr:0.000100  network_time: 0.0973
[ Tue Feb  2 12:34:20 2021 ] 	Batch(995/1252) done. Loss: 0.0312  lr:0.000100  network_time: 0.1020
[ Tue Feb  2 12:34:43 2021 ] 	Batch(1095/1252) done. Loss: 0.0392  lr:0.000100  network_time: 0.1159
[ Tue Feb  2 12:35:06 2021 ] 	Batch(1195/1252) done. Loss: 0.0219  lr:0.000100  network_time: 0.0970
[ Tue Feb  2 12:35:20 2021 ] Eval epoch: 103
[ Tue Feb  2 12:35:55 2021 ] 	Mean test loss of 258 batches: 0.5234056711196899.
[ Tue Feb  2 12:35:55 2021 ] 	Top1: 85.75%
[ Tue Feb  2 12:35:55 2021 ] 	Top5: 97.69%
[ Tue Feb  2 12:35:55 2021 ] Training epoch: 104
[ Tue Feb  2 12:36:08 2021 ] 	Batch(43/1252) done. Loss: 0.0331  lr:0.000100  network_time: 0.0899
[ Tue Feb  2 12:36:32 2021 ] 	Batch(143/1252) done. Loss: 0.0094  lr:0.000100  network_time: 0.0948
[ Tue Feb  2 12:36:55 2021 ] 	Batch(243/1252) done. Loss: 0.0312  lr:0.000100  network_time: 0.0986
[ Tue Feb  2 12:37:18 2021 ] 	Batch(343/1252) done. Loss: 0.0226  lr:0.000100  network_time: 0.1021
[ Tue Feb  2 12:37:41 2021 ] 	Batch(443/1252) done. Loss: 0.0309  lr:0.000100  network_time: 0.1032
[ Tue Feb  2 12:38:04 2021 ] 	Batch(543/1252) done. Loss: 0.0376  lr:0.000100  network_time: 0.1102
[ Tue Feb  2 12:38:27 2021 ] 	Batch(643/1252) done. Loss: 0.0236  lr:0.000100  network_time: 0.0937
[ Tue Feb  2 12:38:51 2021 ] 	Batch(743/1252) done. Loss: 0.0233  lr:0.000100  network_time: 0.1039
[ Tue Feb  2 12:39:14 2021 ] 	Batch(843/1252) done. Loss: 0.0523  lr:0.000100  network_time: 0.1024
[ Tue Feb  2 12:39:37 2021 ] 	Batch(943/1252) done. Loss: 0.0384  lr:0.000100  network_time: 0.1133
[ Tue Feb  2 12:40:01 2021 ] 	Batch(1043/1252) done. Loss: 0.0456  lr:0.000100  network_time: 0.0894
[ Tue Feb  2 12:40:24 2021 ] 	Batch(1143/1252) done. Loss: 0.0900  lr:0.000100  network_time: 0.1078
[ Tue Feb  2 12:40:47 2021 ] 	Batch(1243/1252) done. Loss: 0.0459  lr:0.000100  network_time: 0.0966
[ Tue Feb  2 12:40:49 2021 ] Eval epoch: 104
[ Tue Feb  2 12:41:24 2021 ] 	Mean test loss of 258 batches: 0.539130449295044.
[ Tue Feb  2 12:41:24 2021 ] 	Top1: 85.36%
[ Tue Feb  2 12:41:24 2021 ] 	Top5: 97.71%
[ Tue Feb  2 12:41:24 2021 ] Training epoch: 105
[ Tue Feb  2 12:41:48 2021 ] 	Batch(91/1252) done. Loss: 0.0167  lr:0.000100  network_time: 0.1048
[ Tue Feb  2 12:42:11 2021 ] 	Batch(191/1252) done. Loss: 0.0261  lr:0.000100  network_time: 0.0939
[ Tue Feb  2 12:42:34 2021 ] 	Batch(291/1252) done. Loss: 0.0322  lr:0.000100  network_time: 0.0945
[ Tue Feb  2 12:42:57 2021 ] 	Batch(391/1252) done. Loss: 0.0440  lr:0.000100  network_time: 0.1044
[ Tue Feb  2 12:43:21 2021 ] 	Batch(491/1252) done. Loss: 0.0535  lr:0.000100  network_time: 0.0935
[ Tue Feb  2 12:43:44 2021 ] 	Batch(591/1252) done. Loss: 0.0365  lr:0.000100  network_time: 0.1076
[ Tue Feb  2 12:44:07 2021 ] 	Batch(691/1252) done. Loss: 0.0209  lr:0.000100  network_time: 0.1101
[ Tue Feb  2 12:44:30 2021 ] 	Batch(791/1252) done. Loss: 0.0401  lr:0.000100  network_time: 0.0957
[ Tue Feb  2 12:44:53 2021 ] 	Batch(891/1252) done. Loss: 0.0189  lr:0.000100  network_time: 0.0909
[ Tue Feb  2 12:45:17 2021 ] 	Batch(991/1252) done. Loss: 0.0307  lr:0.000100  network_time: 0.0992
[ Tue Feb  2 12:45:40 2021 ] 	Batch(1091/1252) done. Loss: 0.0415  lr:0.000100  network_time: 0.1314
[ Tue Feb  2 12:46:03 2021 ] 	Batch(1191/1252) done. Loss: 0.0445  lr:0.000100  network_time: 0.0944
[ Tue Feb  2 12:46:17 2021 ] Eval epoch: 105
[ Tue Feb  2 12:46:52 2021 ] 	Mean test loss of 258 batches: 0.532581627368927.
[ Tue Feb  2 12:46:52 2021 ] 	Top1: 85.50%
[ Tue Feb  2 12:46:53 2021 ] 	Top5: 97.72%
[ Tue Feb  2 12:46:53 2021 ] Training epoch: 106
[ Tue Feb  2 12:47:05 2021 ] 	Batch(39/1252) done. Loss: 0.0442  lr:0.000100  network_time: 0.1039
[ Tue Feb  2 12:47:28 2021 ] 	Batch(139/1252) done. Loss: 0.0274  lr:0.000100  network_time: 0.1063
[ Tue Feb  2 12:47:51 2021 ] 	Batch(239/1252) done. Loss: 0.0216  lr:0.000100  network_time: 0.1188
[ Tue Feb  2 12:48:14 2021 ] 	Batch(339/1252) done. Loss: 0.0335  lr:0.000100  network_time: 0.1001
[ Tue Feb  2 12:48:37 2021 ] 	Batch(439/1252) done. Loss: 0.0394  lr:0.000100  network_time: 0.0940
[ Tue Feb  2 12:48:59 2021 ] 	Batch(539/1252) done. Loss: 0.0273  lr:0.000100  network_time: 0.0905
[ Tue Feb  2 12:49:23 2021 ] 	Batch(639/1252) done. Loss: 0.0341  lr:0.000100  network_time: 0.0966
[ Tue Feb  2 12:49:45 2021 ] 	Batch(739/1252) done. Loss: 0.0843  lr:0.000100  network_time: 0.0920
[ Tue Feb  2 12:50:08 2021 ] 	Batch(839/1252) done. Loss: 0.0521  lr:0.000100  network_time: 0.0930
[ Tue Feb  2 12:50:31 2021 ] 	Batch(939/1252) done. Loss: 0.0284  lr:0.000100  network_time: 0.0906
[ Tue Feb  2 12:50:54 2021 ] 	Batch(1039/1252) done. Loss: 0.0171  lr:0.000100  network_time: 0.0918
[ Tue Feb  2 12:51:17 2021 ] 	Batch(1139/1252) done. Loss: 0.0564  lr:0.000100  network_time: 0.0979
[ Tue Feb  2 12:51:40 2021 ] 	Batch(1239/1252) done. Loss: 0.0554  lr:0.000100  network_time: 0.0978
[ Tue Feb  2 12:51:43 2021 ] Eval epoch: 106
[ Tue Feb  2 12:52:18 2021 ] 	Mean test loss of 258 batches: 0.5227578282356262.
[ Tue Feb  2 12:52:18 2021 ] 	Top1: 85.60%
[ Tue Feb  2 12:52:18 2021 ] 	Top5: 97.66%
[ Tue Feb  2 12:52:18 2021 ] Training epoch: 107
[ Tue Feb  2 12:52:42 2021 ] 	Batch(87/1252) done. Loss: 0.0522  lr:0.000100  network_time: 0.0984
[ Tue Feb  2 12:53:04 2021 ] 	Batch(187/1252) done. Loss: 0.0238  lr:0.000100  network_time: 0.0899
[ Tue Feb  2 12:53:27 2021 ] 	Batch(287/1252) done. Loss: 0.0465  lr:0.000100  network_time: 0.0978
[ Tue Feb  2 12:53:50 2021 ] 	Batch(387/1252) done. Loss: 0.0616  lr:0.000100  network_time: 0.0973
[ Tue Feb  2 12:54:13 2021 ] 	Batch(487/1252) done. Loss: 0.0326  lr:0.000100  network_time: 0.0912
[ Tue Feb  2 12:54:36 2021 ] 	Batch(587/1252) done. Loss: 0.0461  lr:0.000100  network_time: 0.0867
[ Tue Feb  2 12:54:59 2021 ] 	Batch(687/1252) done. Loss: 0.0499  lr:0.000100  network_time: 0.0969
[ Tue Feb  2 12:55:21 2021 ] 	Batch(787/1252) done. Loss: 0.0366  lr:0.000100  network_time: 0.0899
[ Tue Feb  2 12:55:44 2021 ] 	Batch(887/1252) done. Loss: 0.0325  lr:0.000100  network_time: 0.1058
[ Tue Feb  2 12:56:07 2021 ] 	Batch(987/1252) done. Loss: 0.0270  lr:0.000100  network_time: 0.0918
[ Tue Feb  2 12:56:30 2021 ] 	Batch(1087/1252) done. Loss: 0.0248  lr:0.000100  network_time: 0.0895
[ Tue Feb  2 12:56:52 2021 ] 	Batch(1187/1252) done. Loss: 0.0279  lr:0.000100  network_time: 0.0977
[ Tue Feb  2 12:57:07 2021 ] Eval epoch: 107
[ Tue Feb  2 12:57:42 2021 ] 	Mean test loss of 258 batches: 0.524258017539978.
[ Tue Feb  2 12:57:43 2021 ] 	Top1: 85.61%
[ Tue Feb  2 12:57:43 2021 ] 	Top5: 97.65%
[ Tue Feb  2 12:57:43 2021 ] Training epoch: 108
[ Tue Feb  2 12:57:54 2021 ] 	Batch(35/1252) done. Loss: 0.0203  lr:0.000100  network_time: 0.0988
[ Tue Feb  2 12:58:17 2021 ] 	Batch(135/1252) done. Loss: 0.0267  lr:0.000100  network_time: 0.0983
[ Tue Feb  2 12:58:40 2021 ] 	Batch(235/1252) done. Loss: 0.0371  lr:0.000100  network_time: 0.1023
[ Tue Feb  2 12:59:03 2021 ] 	Batch(335/1252) done. Loss: 0.0221  lr:0.000100  network_time: 0.0884
[ Tue Feb  2 12:59:26 2021 ] 	Batch(435/1252) done. Loss: 0.0159  lr:0.000100  network_time: 0.1127
[ Tue Feb  2 12:59:49 2021 ] 	Batch(535/1252) done. Loss: 0.0208  lr:0.000100  network_time: 0.0971
[ Tue Feb  2 13:00:12 2021 ] 	Batch(635/1252) done. Loss: 0.0263  lr:0.000100  network_time: 0.0997
[ Tue Feb  2 13:00:35 2021 ] 	Batch(735/1252) done. Loss: 0.0342  lr:0.000100  network_time: 0.0948
[ Tue Feb  2 13:00:58 2021 ] 	Batch(835/1252) done. Loss: 0.0262  lr:0.000100  network_time: 0.0918
[ Tue Feb  2 13:01:21 2021 ] 	Batch(935/1252) done. Loss: 0.0649  lr:0.000100  network_time: 0.0985
[ Tue Feb  2 13:01:44 2021 ] 	Batch(1035/1252) done. Loss: 0.1214  lr:0.000100  network_time: 0.1021
[ Tue Feb  2 13:02:07 2021 ] 	Batch(1135/1252) done. Loss: 0.0381  lr:0.000100  network_time: 0.0925
[ Tue Feb  2 13:02:30 2021 ] 	Batch(1235/1252) done. Loss: 0.0432  lr:0.000100  network_time: 0.0913
[ Tue Feb  2 13:02:34 2021 ] Eval epoch: 108
[ Tue Feb  2 13:03:08 2021 ] 	Mean test loss of 258 batches: 0.5273831486701965.
[ Tue Feb  2 13:03:09 2021 ] 	Top1: 85.36%
[ Tue Feb  2 13:03:09 2021 ] 	Top5: 97.70%
[ Tue Feb  2 13:03:09 2021 ] Training epoch: 109
[ Tue Feb  2 13:03:31 2021 ] 	Batch(83/1252) done. Loss: 0.0424  lr:0.000100  network_time: 0.0889
[ Tue Feb  2 13:03:54 2021 ] 	Batch(183/1252) done. Loss: 0.0481  lr:0.000100  network_time: 0.0951
[ Tue Feb  2 13:04:17 2021 ] 	Batch(283/1252) done. Loss: 0.0113  lr:0.000100  network_time: 0.1036
[ Tue Feb  2 13:04:39 2021 ] 	Batch(383/1252) done. Loss: 0.0328  lr:0.000100  network_time: 0.0952
[ Tue Feb  2 13:05:02 2021 ] 	Batch(483/1252) done. Loss: 0.0357  lr:0.000100  network_time: 0.0869
[ Tue Feb  2 13:05:25 2021 ] 	Batch(583/1252) done. Loss: 0.0625  lr:0.000100  network_time: 0.1056
[ Tue Feb  2 13:05:48 2021 ] 	Batch(683/1252) done. Loss: 0.0125  lr:0.000100  network_time: 0.1005
[ Tue Feb  2 13:06:11 2021 ] 	Batch(783/1252) done. Loss: 0.0147  lr:0.000100  network_time: 0.1138
[ Tue Feb  2 13:06:34 2021 ] 	Batch(883/1252) done. Loss: 0.0677  lr:0.000100  network_time: 0.0882
[ Tue Feb  2 13:06:57 2021 ] 	Batch(983/1252) done. Loss: 0.0176  lr:0.000100  network_time: 0.1007
[ Tue Feb  2 13:07:20 2021 ] 	Batch(1083/1252) done. Loss: 0.0247  lr:0.000100  network_time: 0.0855
[ Tue Feb  2 13:07:43 2021 ] 	Batch(1183/1252) done. Loss: 0.0368  lr:0.000100  network_time: 0.0962
[ Tue Feb  2 13:07:58 2021 ] Eval epoch: 109
[ Tue Feb  2 13:08:33 2021 ] 	Mean test loss of 258 batches: 0.5300115346908569.
[ Tue Feb  2 13:08:33 2021 ] 	Top1: 85.47%
[ Tue Feb  2 13:08:34 2021 ] 	Top5: 97.74%
[ Tue Feb  2 13:08:34 2021 ] Training epoch: 110
[ Tue Feb  2 13:08:44 2021 ] 	Batch(31/1252) done. Loss: 0.0143  lr:0.000100  network_time: 0.0933
[ Tue Feb  2 13:09:07 2021 ] 	Batch(131/1252) done. Loss: 0.0279  lr:0.000100  network_time: 0.1097
[ Tue Feb  2 13:09:30 2021 ] 	Batch(231/1252) done. Loss: 0.0186  lr:0.000100  network_time: 0.1135
[ Tue Feb  2 13:09:53 2021 ] 	Batch(331/1252) done. Loss: 0.0626  lr:0.000100  network_time: 0.0936
[ Tue Feb  2 13:10:16 2021 ] 	Batch(431/1252) done. Loss: 0.0210  lr:0.000100  network_time: 0.0900
[ Tue Feb  2 13:10:38 2021 ] 	Batch(531/1252) done. Loss: 0.0556  lr:0.000100  network_time: 0.1307
[ Tue Feb  2 13:11:01 2021 ] 	Batch(631/1252) done. Loss: 0.0429  lr:0.000100  network_time: 0.0930
[ Tue Feb  2 13:11:24 2021 ] 	Batch(731/1252) done. Loss: 0.0273  lr:0.000100  network_time: 0.0903
[ Tue Feb  2 13:11:47 2021 ] 	Batch(831/1252) done. Loss: 0.0197  lr:0.000100  network_time: 0.1046
[ Tue Feb  2 13:12:10 2021 ] 	Batch(931/1252) done. Loss: 0.0241  lr:0.000100  network_time: 0.1161
[ Tue Feb  2 13:12:33 2021 ] 	Batch(1031/1252) done. Loss: 0.0281  lr:0.000100  network_time: 0.0926
[ Tue Feb  2 13:12:55 2021 ] 	Batch(1131/1252) done. Loss: 0.0253  lr:0.000100  network_time: 0.0896
[ Tue Feb  2 13:13:18 2021 ] 	Batch(1231/1252) done. Loss: 0.0254  lr:0.000100  network_time: 0.1145
[ Tue Feb  2 13:13:23 2021 ] Eval epoch: 110
[ Tue Feb  2 13:13:58 2021 ] 	Mean test loss of 258 batches: 0.5281593203544617.
[ Tue Feb  2 13:13:58 2021 ] 	Top1: 85.61%
[ Tue Feb  2 13:13:59 2021 ] 	Top5: 97.75%
[ Tue Feb  2 13:13:59 2021 ] Training epoch: 111
[ Tue Feb  2 13:14:20 2021 ] 	Batch(79/1252) done. Loss: 0.0511  lr:0.000100  network_time: 0.0978
[ Tue Feb  2 13:14:43 2021 ] 	Batch(179/1252) done. Loss: 0.0242  lr:0.000100  network_time: 0.0893
[ Tue Feb  2 13:15:06 2021 ] 	Batch(279/1252) done. Loss: 0.0503  lr:0.000100  network_time: 0.0858
[ Tue Feb  2 13:15:29 2021 ] 	Batch(379/1252) done. Loss: 0.0233  lr:0.000100  network_time: 0.1076
[ Tue Feb  2 13:15:51 2021 ] 	Batch(479/1252) done. Loss: 0.0370  lr:0.000100  network_time: 0.0927
[ Tue Feb  2 13:16:14 2021 ] 	Batch(579/1252) done. Loss: 0.0431  lr:0.000100  network_time: 0.1007
[ Tue Feb  2 13:16:37 2021 ] 	Batch(679/1252) done. Loss: 0.0169  lr:0.000100  network_time: 0.0938
[ Tue Feb  2 13:17:00 2021 ] 	Batch(779/1252) done. Loss: 0.0104  lr:0.000100  network_time: 0.0929
[ Tue Feb  2 13:17:23 2021 ] 	Batch(879/1252) done. Loss: 0.0324  lr:0.000100  network_time: 0.1037
[ Tue Feb  2 13:17:46 2021 ] 	Batch(979/1252) done. Loss: 0.0364  lr:0.000100  network_time: 0.0966
[ Tue Feb  2 13:18:09 2021 ] 	Batch(1079/1252) done. Loss: 0.0648  lr:0.000100  network_time: 0.0922
[ Tue Feb  2 13:18:32 2021 ] 	Batch(1179/1252) done. Loss: 0.1261  lr:0.000100  network_time: 0.0944
[ Tue Feb  2 13:18:48 2021 ] Eval epoch: 111
[ Tue Feb  2 13:19:23 2021 ] 	Mean test loss of 258 batches: 0.5168763995170593.
[ Tue Feb  2 13:19:23 2021 ] 	Top1: 85.86%
[ Tue Feb  2 13:19:23 2021 ] 	Top5: 97.76%
[ Tue Feb  2 13:19:23 2021 ] Training epoch: 112
[ Tue Feb  2 13:19:33 2021 ] 	Batch(27/1252) done. Loss: 0.0734  lr:0.000100  network_time: 0.0920
[ Tue Feb  2 13:19:56 2021 ] 	Batch(127/1252) done. Loss: 0.0672  lr:0.000100  network_time: 0.0939
[ Tue Feb  2 13:20:19 2021 ] 	Batch(227/1252) done. Loss: 0.0384  lr:0.000100  network_time: 0.0950
[ Tue Feb  2 13:20:42 2021 ] 	Batch(327/1252) done. Loss: 0.0687  lr:0.000100  network_time: 0.0968
[ Tue Feb  2 13:21:04 2021 ] 	Batch(427/1252) done. Loss: 0.0225  lr:0.000100  network_time: 0.1377
[ Tue Feb  2 13:21:27 2021 ] 	Batch(527/1252) done. Loss: 0.0425  lr:0.000100  network_time: 0.0980
[ Tue Feb  2 13:21:50 2021 ] 	Batch(627/1252) done. Loss: 0.0300  lr:0.000100  network_time: 0.0983
[ Tue Feb  2 13:22:13 2021 ] 	Batch(727/1252) done. Loss: 0.0172  lr:0.000100  network_time: 0.1011
[ Tue Feb  2 13:22:36 2021 ] 	Batch(827/1252) done. Loss: 0.0358  lr:0.000100  network_time: 0.1039
[ Tue Feb  2 13:22:59 2021 ] 	Batch(927/1252) done. Loss: 0.0571  lr:0.000100  network_time: 0.0961
[ Tue Feb  2 13:23:22 2021 ] 	Batch(1027/1252) done. Loss: 0.0257  lr:0.000100  network_time: 0.0963
[ Tue Feb  2 13:23:45 2021 ] 	Batch(1127/1252) done. Loss: 0.0352  lr:0.000100  network_time: 0.0968
[ Tue Feb  2 13:24:07 2021 ] 	Batch(1227/1252) done. Loss: 0.0301  lr:0.000100  network_time: 0.0944
[ Tue Feb  2 13:24:13 2021 ] Eval epoch: 112
[ Tue Feb  2 13:24:48 2021 ] 	Mean test loss of 258 batches: 0.518246054649353.
[ Tue Feb  2 13:24:48 2021 ] 	Top1: 85.73%
[ Tue Feb  2 13:24:48 2021 ] 	Top5: 97.71%
[ Tue Feb  2 13:24:48 2021 ] Training epoch: 113
[ Tue Feb  2 13:25:09 2021 ] 	Batch(75/1252) done. Loss: 0.0222  lr:0.000100  network_time: 0.0915
[ Tue Feb  2 13:25:32 2021 ] 	Batch(175/1252) done. Loss: 0.0447  lr:0.000100  network_time: 0.1041
[ Tue Feb  2 13:25:55 2021 ] 	Batch(275/1252) done. Loss: 0.0549  lr:0.000100  network_time: 0.1047
[ Tue Feb  2 13:26:18 2021 ] 	Batch(375/1252) done. Loss: 0.0095  lr:0.000100  network_time: 0.0928
[ Tue Feb  2 13:26:40 2021 ] 	Batch(475/1252) done. Loss: 0.0260  lr:0.000100  network_time: 0.1065
[ Tue Feb  2 13:27:03 2021 ] 	Batch(575/1252) done. Loss: 0.0176  lr:0.000100  network_time: 0.1012
[ Tue Feb  2 13:27:26 2021 ] 	Batch(675/1252) done. Loss: 0.0148  lr:0.000100  network_time: 0.1067
[ Tue Feb  2 13:27:49 2021 ] 	Batch(775/1252) done. Loss: 0.0563  lr:0.000100  network_time: 0.1007
[ Tue Feb  2 13:28:12 2021 ] 	Batch(875/1252) done. Loss: 0.0294  lr:0.000100  network_time: 0.0943
[ Tue Feb  2 13:28:35 2021 ] 	Batch(975/1252) done. Loss: 0.0238  lr:0.000100  network_time: 0.0884
[ Tue Feb  2 13:28:58 2021 ] 	Batch(1075/1252) done. Loss: 0.0243  lr:0.000100  network_time: 0.0976
[ Tue Feb  2 13:29:20 2021 ] 	Batch(1175/1252) done. Loss: 0.0304  lr:0.000100  network_time: 0.1020
[ Tue Feb  2 13:29:38 2021 ] Eval epoch: 113
[ Tue Feb  2 13:30:13 2021 ] 	Mean test loss of 258 batches: 0.5240065455436707.
[ Tue Feb  2 13:30:13 2021 ] 	Top1: 85.46%
[ Tue Feb  2 13:30:13 2021 ] 	Top5: 97.82%
[ Tue Feb  2 13:30:14 2021 ] Training epoch: 114
[ Tue Feb  2 13:30:22 2021 ] 	Batch(23/1252) done. Loss: 0.0273  lr:0.000100  network_time: 0.0905
[ Tue Feb  2 13:30:45 2021 ] 	Batch(123/1252) done. Loss: 0.0378  lr:0.000100  network_time: 0.0928
[ Tue Feb  2 13:31:08 2021 ] 	Batch(223/1252) done. Loss: 0.0158  lr:0.000100  network_time: 0.0967
[ Tue Feb  2 13:31:31 2021 ] 	Batch(323/1252) done. Loss: 0.0777  lr:0.000100  network_time: 0.0978
[ Tue Feb  2 13:31:54 2021 ] 	Batch(423/1252) done. Loss: 0.0518  lr:0.000100  network_time: 0.0981
[ Tue Feb  2 13:32:17 2021 ] 	Batch(523/1252) done. Loss: 0.0897  lr:0.000100  network_time: 0.0898
[ Tue Feb  2 13:32:39 2021 ] 	Batch(623/1252) done. Loss: 0.0271  lr:0.000100  network_time: 0.0927
[ Tue Feb  2 13:33:02 2021 ] 	Batch(723/1252) done. Loss: 0.0322  lr:0.000100  network_time: 0.0982
[ Tue Feb  2 13:33:25 2021 ] 	Batch(823/1252) done. Loss: 0.0462  lr:0.000100  network_time: 0.0991
[ Tue Feb  2 13:33:48 2021 ] 	Batch(923/1252) done. Loss: 0.0257  lr:0.000100  network_time: 0.0916
[ Tue Feb  2 13:34:11 2021 ] 	Batch(1023/1252) done. Loss: 0.0403  lr:0.000100  network_time: 0.0916
[ Tue Feb  2 13:34:34 2021 ] 	Batch(1123/1252) done. Loss: 0.0704  lr:0.000100  network_time: 0.1100
[ Tue Feb  2 13:34:57 2021 ] 	Batch(1223/1252) done. Loss: 0.0174  lr:0.000100  network_time: 0.1004
[ Tue Feb  2 13:35:04 2021 ] Eval epoch: 114
[ Tue Feb  2 13:35:38 2021 ] 	Mean test loss of 258 batches: 0.5238326787948608.
[ Tue Feb  2 13:35:39 2021 ] 	Top1: 85.55%
[ Tue Feb  2 13:35:39 2021 ] 	Top5: 97.68%
[ Tue Feb  2 13:35:39 2021 ] Training epoch: 115
[ Tue Feb  2 13:35:58 2021 ] 	Batch(71/1252) done. Loss: 0.0594  lr:0.000100  network_time: 0.0917
[ Tue Feb  2 13:36:21 2021 ] 	Batch(171/1252) done. Loss: 0.0250  lr:0.000100  network_time: 0.1210
[ Tue Feb  2 13:36:44 2021 ] 	Batch(271/1252) done. Loss: 0.0198  lr:0.000100  network_time: 0.0979
[ Tue Feb  2 13:37:07 2021 ] 	Batch(371/1252) done. Loss: 0.0792  lr:0.000100  network_time: 0.1047
[ Tue Feb  2 13:37:30 2021 ] 	Batch(471/1252) done. Loss: 0.0100  lr:0.000100  network_time: 0.0956
[ Tue Feb  2 13:37:52 2021 ] 	Batch(571/1252) done. Loss: 0.0221  lr:0.000100  network_time: 0.1066
[ Tue Feb  2 13:38:15 2021 ] 	Batch(671/1252) done. Loss: 0.0844  lr:0.000100  network_time: 0.0949
[ Tue Feb  2 13:38:38 2021 ] 	Batch(771/1252) done. Loss: 0.0195  lr:0.000100  network_time: 0.0880
[ Tue Feb  2 13:39:01 2021 ] 	Batch(871/1252) done. Loss: 0.0206  lr:0.000100  network_time: 0.0959
[ Tue Feb  2 13:39:24 2021 ] 	Batch(971/1252) done. Loss: 0.0532  lr:0.000100  network_time: 0.0931
[ Tue Feb  2 13:39:47 2021 ] 	Batch(1071/1252) done. Loss: 0.0355  lr:0.000100  network_time: 0.0971
[ Tue Feb  2 13:40:09 2021 ] 	Batch(1171/1252) done. Loss: 0.0355  lr:0.000100  network_time: 0.1031
[ Tue Feb  2 13:40:28 2021 ] Eval epoch: 115
[ Tue Feb  2 13:41:03 2021 ] 	Mean test loss of 258 batches: 0.5283903479576111.
[ Tue Feb  2 13:41:03 2021 ] 	Top1: 85.54%
[ Tue Feb  2 13:41:03 2021 ] 	Top5: 97.73%
[ Tue Feb  2 13:41:03 2021 ] Training epoch: 116
[ Tue Feb  2 13:41:11 2021 ] 	Batch(19/1252) done. Loss: 0.0228  lr:0.000100  network_time: 0.1071
[ Tue Feb  2 13:41:34 2021 ] 	Batch(119/1252) done. Loss: 0.0374  lr:0.000100  network_time: 0.0934
[ Tue Feb  2 13:41:57 2021 ] 	Batch(219/1252) done. Loss: 0.0857  lr:0.000100  network_time: 0.1025
[ Tue Feb  2 13:42:20 2021 ] 	Batch(319/1252) done. Loss: 0.0275  lr:0.000100  network_time: 0.1001
[ Tue Feb  2 13:42:43 2021 ] 	Batch(419/1252) done. Loss: 0.0237  lr:0.000100  network_time: 0.0919
[ Tue Feb  2 13:43:06 2021 ] 	Batch(519/1252) done. Loss: 0.0249  lr:0.000100  network_time: 0.1341
[ Tue Feb  2 13:43:28 2021 ] 	Batch(619/1252) done. Loss: 0.0461  lr:0.000100  network_time: 0.0941
[ Tue Feb  2 13:43:51 2021 ] 	Batch(719/1252) done. Loss: 0.0565  lr:0.000100  network_time: 0.1020
[ Tue Feb  2 13:44:14 2021 ] 	Batch(819/1252) done. Loss: 0.0332  lr:0.000100  network_time: 0.1005
[ Tue Feb  2 13:44:37 2021 ] 	Batch(919/1252) done. Loss: 0.0342  lr:0.000100  network_time: 0.1009
[ Tue Feb  2 13:45:00 2021 ] 	Batch(1019/1252) done. Loss: 0.0401  lr:0.000100  network_time: 0.0968
[ Tue Feb  2 13:45:23 2021 ] 	Batch(1119/1252) done. Loss: 0.0379  lr:0.000100  network_time: 0.0936
[ Tue Feb  2 13:45:46 2021 ] 	Batch(1219/1252) done. Loss: 0.0246  lr:0.000100  network_time: 0.0961
[ Tue Feb  2 13:45:53 2021 ] Eval epoch: 116
[ Tue Feb  2 13:46:28 2021 ] 	Mean test loss of 258 batches: 0.525884211063385.
[ Tue Feb  2 13:46:29 2021 ] 	Top1: 85.36%
[ Tue Feb  2 13:46:29 2021 ] 	Top5: 97.72%
[ Tue Feb  2 13:46:29 2021 ] Training epoch: 117
[ Tue Feb  2 13:46:47 2021 ] 	Batch(67/1252) done. Loss: 0.0385  lr:0.000100  network_time: 0.0845
[ Tue Feb  2 13:47:10 2021 ] 	Batch(167/1252) done. Loss: 0.0118  lr:0.000100  network_time: 0.0899
[ Tue Feb  2 13:47:33 2021 ] 	Batch(267/1252) done. Loss: 0.0303  lr:0.000100  network_time: 0.0969
[ Tue Feb  2 13:47:55 2021 ] 	Batch(367/1252) done. Loss: 0.0116  lr:0.000100  network_time: 0.1000
[ Tue Feb  2 13:48:18 2021 ] 	Batch(467/1252) done. Loss: 0.0196  lr:0.000100  network_time: 0.1025
[ Tue Feb  2 13:48:41 2021 ] 	Batch(567/1252) done. Loss: 0.0513  lr:0.000100  network_time: 0.0910
[ Tue Feb  2 13:49:04 2021 ] 	Batch(667/1252) done. Loss: 0.0338  lr:0.000100  network_time: 0.0989
[ Tue Feb  2 13:49:26 2021 ] 	Batch(767/1252) done. Loss: 0.0518  lr:0.000100  network_time: 0.1082
[ Tue Feb  2 13:49:49 2021 ] 	Batch(867/1252) done. Loss: 0.0418  lr:0.000100  network_time: 0.0961
[ Tue Feb  2 13:50:11 2021 ] 	Batch(967/1252) done. Loss: 0.0276  lr:0.000100  network_time: 0.0890
[ Tue Feb  2 13:50:34 2021 ] 	Batch(1067/1252) done. Loss: 0.0937  lr:0.000100  network_time: 0.0953
[ Tue Feb  2 13:50:57 2021 ] 	Batch(1167/1252) done. Loss: 0.0445  lr:0.000100  network_time: 0.1001
[ Tue Feb  2 13:51:16 2021 ] Eval epoch: 117
[ Tue Feb  2 13:51:50 2021 ] 	Mean test loss of 258 batches: 0.5283967852592468.
[ Tue Feb  2 13:51:50 2021 ] 	Top1: 85.67%
[ Tue Feb  2 13:51:50 2021 ] 	Top5: 97.79%
[ Tue Feb  2 13:51:50 2021 ] Training epoch: 118
[ Tue Feb  2 13:51:57 2021 ] 	Batch(15/1252) done. Loss: 0.0231  lr:0.000100  network_time: 0.0800
[ Tue Feb  2 13:52:19 2021 ] 	Batch(115/1252) done. Loss: 0.0372  lr:0.000100  network_time: 0.0948
[ Tue Feb  2 13:52:41 2021 ] 	Batch(215/1252) done. Loss: 0.0557  lr:0.000100  network_time: 0.0772
[ Tue Feb  2 13:53:03 2021 ] 	Batch(315/1252) done. Loss: 0.0540  lr:0.000100  network_time: 0.0803
[ Tue Feb  2 13:53:25 2021 ] 	Batch(415/1252) done. Loss: 0.0472  lr:0.000100  network_time: 0.1090
[ Tue Feb  2 13:53:47 2021 ] 	Batch(515/1252) done. Loss: 0.0739  lr:0.000100  network_time: 0.0843
[ Tue Feb  2 13:54:09 2021 ] 	Batch(615/1252) done. Loss: 0.0547  lr:0.000100  network_time: 0.1055
[ Tue Feb  2 13:54:31 2021 ] 	Batch(715/1252) done. Loss: 0.0280  lr:0.000100  network_time: 0.0860
[ Tue Feb  2 13:54:54 2021 ] 	Batch(815/1252) done. Loss: 0.0712  lr:0.000100  network_time: 0.1021
[ Tue Feb  2 13:55:17 2021 ] 	Batch(915/1252) done. Loss: 0.0208  lr:0.000100  network_time: 0.1045
[ Tue Feb  2 13:55:39 2021 ] 	Batch(1015/1252) done. Loss: 0.0159  lr:0.000100  network_time: 0.0994
[ Tue Feb  2 13:56:02 2021 ] 	Batch(1115/1252) done. Loss: 0.0449  lr:0.000100  network_time: 0.1064
[ Tue Feb  2 13:56:25 2021 ] 	Batch(1215/1252) done. Loss: 0.0402  lr:0.000100  network_time: 0.1021
[ Tue Feb  2 13:56:33 2021 ] Eval epoch: 118
[ Tue Feb  2 13:57:09 2021 ] 	Mean test loss of 258 batches: 0.5294965505599976.
[ Tue Feb  2 13:57:09 2021 ] 	Top1: 85.49%
[ Tue Feb  2 13:57:09 2021 ] 	Top5: 97.72%
[ Tue Feb  2 13:57:09 2021 ] Training epoch: 119
[ Tue Feb  2 13:57:26 2021 ] 	Batch(63/1252) done. Loss: 0.0322  lr:0.000100  network_time: 0.0920
[ Tue Feb  2 13:57:48 2021 ] 	Batch(163/1252) done. Loss: 0.0564  lr:0.000100  network_time: 0.0997
[ Tue Feb  2 13:58:11 2021 ] 	Batch(263/1252) done. Loss: 0.0406  lr:0.000100  network_time: 0.0977
[ Tue Feb  2 13:58:33 2021 ] 	Batch(363/1252) done. Loss: 0.0820  lr:0.000100  network_time: 0.0922
[ Tue Feb  2 13:58:55 2021 ] 	Batch(463/1252) done. Loss: 0.0539  lr:0.000100  network_time: 0.1023
[ Tue Feb  2 13:59:18 2021 ] 	Batch(563/1252) done. Loss: 0.0473  lr:0.000100  network_time: 0.0895
[ Tue Feb  2 13:59:40 2021 ] 	Batch(663/1252) done. Loss: 0.0763  lr:0.000100  network_time: 0.1028
[ Tue Feb  2 14:00:02 2021 ] 	Batch(763/1252) done. Loss: 0.0297  lr:0.000100  network_time: 0.1032
[ Tue Feb  2 14:00:25 2021 ] 	Batch(863/1252) done. Loss: 0.0262  lr:0.000100  network_time: 0.0903
[ Tue Feb  2 14:00:47 2021 ] 	Batch(963/1252) done. Loss: 0.0414  lr:0.000100  network_time: 0.0970
[ Tue Feb  2 14:01:09 2021 ] 	Batch(1063/1252) done. Loss: 0.0688  lr:0.000100  network_time: 0.0794
[ Tue Feb  2 14:01:30 2021 ] 	Batch(1163/1252) done. Loss: 0.0810  lr:0.000100  network_time: 0.0731
[ Tue Feb  2 14:01:49 2021 ] Eval epoch: 119
[ Tue Feb  2 14:02:22 2021 ] 	Mean test loss of 258 batches: 0.5281287431716919.
[ Tue Feb  2 14:02:22 2021 ] 	Top1: 85.50%
[ Tue Feb  2 14:02:22 2021 ] 	Top5: 97.79%
[ Tue Feb  2 14:02:23 2021 ] Training epoch: 120
[ Tue Feb  2 14:02:28 2021 ] 	Batch(11/1252) done. Loss: 0.0478  lr:0.000100  network_time: 0.0804
[ Tue Feb  2 14:02:50 2021 ] 	Batch(111/1252) done. Loss: 0.0144  lr:0.000100  network_time: 0.0844
[ Tue Feb  2 14:03:12 2021 ] 	Batch(211/1252) done. Loss: 0.0346  lr:0.000100  network_time: 0.0969
[ Tue Feb  2 14:03:33 2021 ] 	Batch(311/1252) done. Loss: 0.0467  lr:0.000100  network_time: 0.0990
[ Tue Feb  2 14:03:55 2021 ] 	Batch(411/1252) done. Loss: 0.0204  lr:0.000100  network_time: 0.0837
[ Tue Feb  2 14:04:17 2021 ] 	Batch(511/1252) done. Loss: 0.0311  lr:0.000100  network_time: 0.0903
[ Tue Feb  2 14:04:40 2021 ] 	Batch(611/1252) done. Loss: 0.0397  lr:0.000100  network_time: 0.1013
[ Tue Feb  2 14:05:03 2021 ] 	Batch(711/1252) done. Loss: 0.0175  lr:0.000100  network_time: 0.0945
[ Tue Feb  2 14:05:25 2021 ] 	Batch(811/1252) done. Loss: 0.0228  lr:0.000100  network_time: 0.0915
[ Tue Feb  2 14:05:48 2021 ] 	Batch(911/1252) done. Loss: 0.0223  lr:0.000100  network_time: 0.0955
[ Tue Feb  2 14:06:10 2021 ] 	Batch(1011/1252) done. Loss: 0.0304  lr:0.000100  network_time: 0.0980
[ Tue Feb  2 14:06:33 2021 ] 	Batch(1111/1252) done. Loss: 0.0408  lr:0.000100  network_time: 0.1024
[ Tue Feb  2 14:06:56 2021 ] 	Batch(1211/1252) done. Loss: 0.0251  lr:0.000100  network_time: 0.0919
[ Tue Feb  2 14:07:05 2021 ] Eval epoch: 120
[ Tue Feb  2 14:07:39 2021 ] 	Mean test loss of 258 batches: 0.5246978998184204.
[ Tue Feb  2 14:07:39 2021 ] 	Top1: 85.52%
[ Tue Feb  2 14:07:39 2021 ] 	Top5: 97.77%
[ Tue Feb  2 14:07:39 2021 ] Training epoch: 121
[ Tue Feb  2 14:07:56 2021 ] 	Batch(59/1252) done. Loss: 0.0170  lr:0.000100  network_time: 0.1109
[ Tue Feb  2 14:08:17 2021 ] 	Batch(159/1252) done. Loss: 0.0237  lr:0.000100  network_time: 0.0925
[ Tue Feb  2 14:08:39 2021 ] 	Batch(259/1252) done. Loss: 0.0228  lr:0.000100  network_time: 0.0795
[ Tue Feb  2 14:09:00 2021 ] 	Batch(359/1252) done. Loss: 0.0377  lr:0.000100  network_time: 0.0719
[ Tue Feb  2 14:09:21 2021 ] 	Batch(459/1252) done. Loss: 0.0359  lr:0.000100  network_time: 0.1061
[ Tue Feb  2 14:09:43 2021 ] 	Batch(559/1252) done. Loss: 0.0141  lr:0.000100  network_time: 0.0835
[ Tue Feb  2 14:10:04 2021 ] 	Batch(659/1252) done. Loss: 0.0800  lr:0.000100  network_time: 0.0934
[ Tue Feb  2 14:10:26 2021 ] 	Batch(759/1252) done. Loss: 0.0196  lr:0.000100  network_time: 0.0968
[ Tue Feb  2 14:10:48 2021 ] 	Batch(859/1252) done. Loss: 0.0237  lr:0.000100  network_time: 0.1067
[ Tue Feb  2 14:11:11 2021 ] 	Batch(959/1252) done. Loss: 0.0459  lr:0.000100  network_time: 0.0895
[ Tue Feb  2 14:11:34 2021 ] 	Batch(1059/1252) done. Loss: 0.0226  lr:0.000100  network_time: 0.0967
[ Tue Feb  2 14:11:57 2021 ] 	Batch(1159/1252) done. Loss: 0.0491  lr:0.000100  network_time: 0.0891
[ Tue Feb  2 14:12:18 2021 ] Eval epoch: 121
[ Tue Feb  2 14:12:52 2021 ] 	Mean test loss of 258 batches: 0.5207938551902771.
[ Tue Feb  2 14:12:52 2021 ] 	Top1: 85.68%
[ Tue Feb  2 14:12:52 2021 ] 	Top5: 97.69%
[ Tue Feb  2 14:12:52 2021 ] Training epoch: 122
[ Tue Feb  2 14:12:57 2021 ] 	Batch(7/1252) done. Loss: 0.0171  lr:0.000100  network_time: 0.0961
[ Tue Feb  2 14:13:19 2021 ] 	Batch(107/1252) done. Loss: 0.0561  lr:0.000100  network_time: 0.0903
[ Tue Feb  2 14:13:42 2021 ] 	Batch(207/1252) done. Loss: 0.0789  lr:0.000100  network_time: 0.1021
[ Tue Feb  2 14:14:05 2021 ] 	Batch(307/1252) done. Loss: 0.0791  lr:0.000100  network_time: 0.0906
[ Tue Feb  2 14:14:28 2021 ] 	Batch(407/1252) done. Loss: 0.0139  lr:0.000100  network_time: 0.0926
[ Tue Feb  2 14:14:51 2021 ] 	Batch(507/1252) done. Loss: 0.0262  lr:0.000100  network_time: 0.0908
[ Tue Feb  2 14:15:14 2021 ] 	Batch(607/1252) done. Loss: 0.0242  lr:0.000100  network_time: 0.1075
[ Tue Feb  2 14:15:37 2021 ] 	Batch(707/1252) done. Loss: 0.0344  lr:0.000100  network_time: 0.0995
[ Tue Feb  2 14:15:59 2021 ] 	Batch(807/1252) done. Loss: 0.0370  lr:0.000100  network_time: 0.0898
[ Tue Feb  2 14:16:22 2021 ] 	Batch(907/1252) done. Loss: 0.0273  lr:0.000100  network_time: 0.0893
[ Tue Feb  2 14:16:45 2021 ] 	Batch(1007/1252) done. Loss: 0.0439  lr:0.000100  network_time: 0.1113
[ Tue Feb  2 14:17:08 2021 ] 	Batch(1107/1252) done. Loss: 0.0435  lr:0.000100  network_time: 0.1040
[ Tue Feb  2 14:17:31 2021 ] 	Batch(1207/1252) done. Loss: 0.0174  lr:0.000100  network_time: 0.0975
[ Tue Feb  2 14:17:41 2021 ] Eval epoch: 122
[ Tue Feb  2 14:18:15 2021 ] 	Mean test loss of 258 batches: 0.5187976360321045.
[ Tue Feb  2 14:18:16 2021 ] 	Top1: 85.61%
[ Tue Feb  2 14:18:16 2021 ] 	Top5: 97.71%
[ Tue Feb  2 14:18:16 2021 ] Training epoch: 123
[ Tue Feb  2 14:18:32 2021 ] 	Batch(55/1252) done. Loss: 0.0583  lr:0.000100  network_time: 0.0878
[ Tue Feb  2 14:18:54 2021 ] 	Batch(155/1252) done. Loss: 0.0713  lr:0.000100  network_time: 0.0997
[ Tue Feb  2 14:19:17 2021 ] 	Batch(255/1252) done. Loss: 0.0230  lr:0.000100  network_time: 0.1009
[ Tue Feb  2 14:19:40 2021 ] 	Batch(355/1252) done. Loss: 0.0110  lr:0.000100  network_time: 0.1001
[ Tue Feb  2 14:20:03 2021 ] 	Batch(455/1252) done. Loss: 0.0503  lr:0.000100  network_time: 0.0980
[ Tue Feb  2 14:20:25 2021 ] 	Batch(555/1252) done. Loss: 0.0207  lr:0.000100  network_time: 0.0969
[ Tue Feb  2 14:20:48 2021 ] 	Batch(655/1252) done. Loss: 0.0517  lr:0.000100  network_time: 0.1070
[ Tue Feb  2 14:21:11 2021 ] 	Batch(755/1252) done. Loss: 0.0083  lr:0.000100  network_time: 0.0981
[ Tue Feb  2 14:21:34 2021 ] 	Batch(855/1252) done. Loss: 0.0309  lr:0.000100  network_time: 0.0894
[ Tue Feb  2 14:21:57 2021 ] 	Batch(955/1252) done. Loss: 0.0984  lr:0.000100  network_time: 0.1036
[ Tue Feb  2 14:22:20 2021 ] 	Batch(1055/1252) done. Loss: 0.0120  lr:0.000100  network_time: 0.1019
[ Tue Feb  2 14:22:42 2021 ] 	Batch(1155/1252) done. Loss: 0.0871  lr:0.000100  network_time: 0.1052
[ Tue Feb  2 14:23:04 2021 ] Eval epoch: 123
[ Tue Feb  2 14:23:37 2021 ] 	Mean test loss of 258 batches: 0.5329718589782715.
[ Tue Feb  2 14:23:37 2021 ] 	Top1: 85.38%
[ Tue Feb  2 14:23:38 2021 ] 	Top5: 97.76%
[ Tue Feb  2 14:23:38 2021 ] Training epoch: 124
[ Tue Feb  2 14:23:42 2021 ] 	Batch(3/1252) done. Loss: 0.0730  lr:0.000100  network_time: 0.0912
[ Tue Feb  2 14:24:04 2021 ] 	Batch(103/1252) done. Loss: 0.0721  lr:0.000100  network_time: 0.0864
[ Tue Feb  2 14:24:27 2021 ] 	Batch(203/1252) done. Loss: 0.0472  lr:0.000100  network_time: 0.1066
[ Tue Feb  2 14:24:50 2021 ] 	Batch(303/1252) done. Loss: 0.0768  lr:0.000100  network_time: 0.0883
[ Tue Feb  2 14:25:12 2021 ] 	Batch(403/1252) done. Loss: 0.0559  lr:0.000100  network_time: 0.0865
[ Tue Feb  2 14:25:35 2021 ] 	Batch(503/1252) done. Loss: 0.0568  lr:0.000100  network_time: 0.0858
[ Tue Feb  2 14:25:58 2021 ] 	Batch(603/1252) done. Loss: 0.0168  lr:0.000100  network_time: 0.0913
[ Tue Feb  2 14:26:21 2021 ] 	Batch(703/1252) done. Loss: 0.0220  lr:0.000100  network_time: 0.0912
[ Tue Feb  2 14:26:43 2021 ] 	Batch(803/1252) done. Loss: 0.0270  lr:0.000100  network_time: 0.0865
[ Tue Feb  2 14:27:05 2021 ] 	Batch(903/1252) done. Loss: 0.0166  lr:0.000100  network_time: 0.0824
[ Tue Feb  2 14:27:28 2021 ] 	Batch(1003/1252) done. Loss: 0.0712  lr:0.000100  network_time: 0.0824
[ Tue Feb  2 14:27:50 2021 ] 	Batch(1103/1252) done. Loss: 0.0268  lr:0.000100  network_time: 0.0976
[ Tue Feb  2 14:28:12 2021 ] 	Batch(1203/1252) done. Loss: 0.0292  lr:0.000100  network_time: 0.0847
[ Tue Feb  2 14:28:23 2021 ] Eval epoch: 124
[ Tue Feb  2 14:28:57 2021 ] 	Mean test loss of 258 batches: 0.5253838896751404.
[ Tue Feb  2 14:28:57 2021 ] 	Top1: 85.43%
[ Tue Feb  2 14:28:57 2021 ] 	Top5: 97.65%
[ Tue Feb  2 14:28:57 2021 ] Training epoch: 125
[ Tue Feb  2 14:29:12 2021 ] 	Batch(51/1252) done. Loss: 0.0322  lr:0.000100  network_time: 0.1041
[ Tue Feb  2 14:29:35 2021 ] 	Batch(151/1252) done. Loss: 0.0374  lr:0.000100  network_time: 0.0993
[ Tue Feb  2 14:29:57 2021 ] 	Batch(251/1252) done. Loss: 0.0485  lr:0.000100  network_time: 0.0694
[ Tue Feb  2 14:30:19 2021 ] 	Batch(351/1252) done. Loss: 0.0923  lr:0.000100  network_time: 0.0899
[ Tue Feb  2 14:30:41 2021 ] 	Batch(451/1252) done. Loss: 0.0487  lr:0.000100  network_time: 0.0890
[ Tue Feb  2 14:31:05 2021 ] 	Batch(551/1252) done. Loss: 0.0385  lr:0.000100  network_time: 0.0909
[ Tue Feb  2 14:31:29 2021 ] 	Batch(651/1252) done. Loss: 0.0197  lr:0.000100  network_time: 0.0921
[ Tue Feb  2 14:31:52 2021 ] 	Batch(751/1252) done. Loss: 0.0169  lr:0.000100  network_time: 0.0850
[ Tue Feb  2 14:32:17 2021 ] 	Batch(851/1252) done. Loss: 0.0530  lr:0.000100  network_time: 0.0916
[ Tue Feb  2 14:32:41 2021 ] 	Batch(951/1252) done. Loss: 0.0608  lr:0.000100  network_time: 0.0925
[ Tue Feb  2 14:33:05 2021 ] 	Batch(1051/1252) done. Loss: 0.0613  lr:0.000100  network_time: 0.0869
[ Tue Feb  2 14:33:29 2021 ] 	Batch(1151/1252) done. Loss: 0.0133  lr:0.000100  network_time: 0.1064
[ Tue Feb  2 14:33:53 2021 ] 	Batch(1251/1252) done. Loss: 0.0360  lr:0.000100  network_time: 0.0897
[ Tue Feb  2 14:33:53 2021 ] Eval epoch: 125
[ Tue Feb  2 14:34:28 2021 ] 	Mean test loss of 258 batches: 0.5300421118736267.
[ Tue Feb  2 14:34:28 2021 ] 	Top1: 85.44%
[ Tue Feb  2 14:34:28 2021 ] 	Top5: 97.76%
[ Tue Feb  2 14:34:28 2021 ] Training epoch: 126
[ Tue Feb  2 14:34:55 2021 ] 	Batch(99/1252) done. Loss: 0.0357  lr:0.000100  network_time: 0.0910
[ Tue Feb  2 14:35:19 2021 ] 	Batch(199/1252) done. Loss: 0.0710  lr:0.000100  network_time: 0.0928
[ Tue Feb  2 14:35:43 2021 ] 	Batch(299/1252) done. Loss: 0.0318  lr:0.000100  network_time: 0.1055
[ Tue Feb  2 14:36:07 2021 ] 	Batch(399/1252) done. Loss: 0.0709  lr:0.000100  network_time: 0.0970
[ Tue Feb  2 14:36:31 2021 ] 	Batch(499/1252) done. Loss: 0.0259  lr:0.000100  network_time: 0.0955
[ Tue Feb  2 14:36:55 2021 ] 	Batch(599/1252) done. Loss: 0.0312  lr:0.000100  network_time: 0.0920
[ Tue Feb  2 14:37:19 2021 ] 	Batch(699/1252) done. Loss: 0.0316  lr:0.000100  network_time: 0.1059
[ Tue Feb  2 14:37:43 2021 ] 	Batch(799/1252) done. Loss: 0.1154  lr:0.000100  network_time: 0.0911
[ Tue Feb  2 14:38:08 2021 ] 	Batch(899/1252) done. Loss: 0.0354  lr:0.000100  network_time: 0.1013
[ Tue Feb  2 14:38:32 2021 ] 	Batch(999/1252) done. Loss: 0.0335  lr:0.000100  network_time: 0.0951
[ Tue Feb  2 14:38:56 2021 ] 	Batch(1099/1252) done. Loss: 0.0152  lr:0.000100  network_time: 0.0906
[ Tue Feb  2 14:39:19 2021 ] 	Batch(1199/1252) done. Loss: 0.0138  lr:0.000100  network_time: 0.0946
[ Tue Feb  2 14:39:32 2021 ] Eval epoch: 126
[ Tue Feb  2 14:40:07 2021 ] 	Mean test loss of 258 batches: 0.5292816758155823.
[ Tue Feb  2 14:40:08 2021 ] 	Top1: 85.62%
[ Tue Feb  2 14:40:08 2021 ] 	Top5: 97.72%
[ Tue Feb  2 14:40:08 2021 ] Training epoch: 127
[ Tue Feb  2 14:40:22 2021 ] 	Batch(47/1252) done. Loss: 0.0288  lr:0.000100  network_time: 0.0974
[ Tue Feb  2 14:40:46 2021 ] 	Batch(147/1252) done. Loss: 0.0317  lr:0.000100  network_time: 0.0848
[ Tue Feb  2 14:41:10 2021 ] 	Batch(247/1252) done. Loss: 0.0408  lr:0.000100  network_time: 0.0886
[ Tue Feb  2 14:41:34 2021 ] 	Batch(347/1252) done. Loss: 0.0459  lr:0.000100  network_time: 0.0955
[ Tue Feb  2 14:41:58 2021 ] 	Batch(447/1252) done. Loss: 0.0309  lr:0.000100  network_time: 0.0954
[ Tue Feb  2 14:42:22 2021 ] 	Batch(547/1252) done. Loss: 0.0229  lr:0.000100  network_time: 0.0898
[ Tue Feb  2 14:42:45 2021 ] 	Batch(647/1252) done. Loss: 0.0096  lr:0.000100  network_time: 0.0916
[ Tue Feb  2 14:43:07 2021 ] 	Batch(747/1252) done. Loss: 0.0283  lr:0.000100  network_time: 0.0829
[ Tue Feb  2 14:43:29 2021 ] 	Batch(847/1252) done. Loss: 0.0417  lr:0.000100  network_time: 0.0866
[ Tue Feb  2 14:43:52 2021 ] 	Batch(947/1252) done. Loss: 0.0193  lr:0.000100  network_time: 0.0816
[ Tue Feb  2 14:44:14 2021 ] 	Batch(1047/1252) done. Loss: 0.0294  lr:0.000100  network_time: 0.0765
[ Tue Feb  2 14:44:36 2021 ] 	Batch(1147/1252) done. Loss: 0.0515  lr:0.000100  network_time: 0.0777
[ Tue Feb  2 14:44:58 2021 ] 	Batch(1247/1252) done. Loss: 0.0446  lr:0.000100  network_time: 0.0789
[ Tue Feb  2 14:44:59 2021 ] Eval epoch: 127
[ Tue Feb  2 14:45:34 2021 ] 	Mean test loss of 258 batches: 0.5236638188362122.
[ Tue Feb  2 14:45:34 2021 ] 	Top1: 85.52%
[ Tue Feb  2 14:45:34 2021 ] 	Top5: 97.72%
[ Tue Feb  2 14:45:34 2021 ] Training epoch: 128
[ Tue Feb  2 14:45:58 2021 ] 	Batch(95/1252) done. Loss: 0.0507  lr:0.000100  network_time: 0.1038
[ Tue Feb  2 14:46:20 2021 ] 	Batch(195/1252) done. Loss: 0.0291  lr:0.000100  network_time: 0.0837
[ Tue Feb  2 14:46:42 2021 ] 	Batch(295/1252) done. Loss: 0.0168  lr:0.000100  network_time: 0.0869
[ Tue Feb  2 14:47:04 2021 ] 	Batch(395/1252) done. Loss: 0.0184  lr:0.000100  network_time: 0.0882
[ Tue Feb  2 14:47:26 2021 ] 	Batch(495/1252) done. Loss: 0.0432  lr:0.000100  network_time: 0.0936
[ Tue Feb  2 14:47:48 2021 ] 	Batch(595/1252) done. Loss: 0.0891  lr:0.000100  network_time: 0.0957
[ Tue Feb  2 14:48:10 2021 ] 	Batch(695/1252) done. Loss: 0.0587  lr:0.000100  network_time: 0.0901
[ Tue Feb  2 14:48:32 2021 ] 	Batch(795/1252) done. Loss: 0.0341  lr:0.000100  network_time: 0.0810
[ Tue Feb  2 14:48:55 2021 ] 	Batch(895/1252) done. Loss: 0.0582  lr:0.000100  network_time: 0.0851
[ Tue Feb  2 14:49:17 2021 ] 	Batch(995/1252) done. Loss: 0.0170  lr:0.000100  network_time: 0.0789
[ Tue Feb  2 14:49:39 2021 ] 	Batch(1095/1252) done. Loss: 0.0178  lr:0.000100  network_time: 0.0993
[ Tue Feb  2 14:50:01 2021 ] 	Batch(1195/1252) done. Loss: 0.0345  lr:0.000100  network_time: 0.0691
[ Tue Feb  2 14:50:13 2021 ] Eval epoch: 128
[ Tue Feb  2 14:50:47 2021 ] 	Mean test loss of 258 batches: 0.5189607739448547.
[ Tue Feb  2 14:50:47 2021 ] 	Top1: 85.52%
[ Tue Feb  2 14:50:47 2021 ] 	Top5: 97.73%
[ Tue Feb  2 14:50:47 2021 ] Training epoch: 129
[ Tue Feb  2 14:51:00 2021 ] 	Batch(43/1252) done. Loss: 0.0290  lr:0.000100  network_time: 0.0936
[ Tue Feb  2 14:51:23 2021 ] 	Batch(143/1252) done. Loss: 0.0603  lr:0.000100  network_time: 0.0912
[ Tue Feb  2 14:51:45 2021 ] 	Batch(243/1252) done. Loss: 0.0405  lr:0.000100  network_time: 0.0927
[ Tue Feb  2 14:52:07 2021 ] 	Batch(343/1252) done. Loss: 0.0704  lr:0.000100  network_time: 0.1244
[ Tue Feb  2 14:52:29 2021 ] 	Batch(443/1252) done. Loss: 0.0513  lr:0.000100  network_time: 0.0742
[ Tue Feb  2 14:52:51 2021 ] 	Batch(543/1252) done. Loss: 0.0379  lr:0.000100  network_time: 0.0775
[ Tue Feb  2 14:53:14 2021 ] 	Batch(643/1252) done. Loss: 0.0664  lr:0.000100  network_time: 0.0964
[ Tue Feb  2 14:53:36 2021 ] 	Batch(743/1252) done. Loss: 0.0386  lr:0.000100  network_time: 0.0820
[ Tue Feb  2 14:53:58 2021 ] 	Batch(843/1252) done. Loss: 0.1146  lr:0.000100  network_time: 0.0834
[ Tue Feb  2 14:54:20 2021 ] 	Batch(943/1252) done. Loss: 0.0404  lr:0.000100  network_time: 0.0802
[ Tue Feb  2 14:54:43 2021 ] 	Batch(1043/1252) done. Loss: 0.0506  lr:0.000100  network_time: 0.1010
[ Tue Feb  2 14:55:05 2021 ] 	Batch(1143/1252) done. Loss: 0.0383  lr:0.000100  network_time: 0.0834
[ Tue Feb  2 14:55:27 2021 ] 	Batch(1243/1252) done. Loss: 0.0357  lr:0.000100  network_time: 0.0805
[ Tue Feb  2 14:55:29 2021 ] Eval epoch: 129
[ Tue Feb  2 14:56:03 2021 ] 	Mean test loss of 258 batches: 0.5188441872596741.
[ Tue Feb  2 14:56:03 2021 ] 	Top1: 85.63%
[ Tue Feb  2 14:56:03 2021 ] 	Top5: 97.76%
[ Tue Feb  2 14:56:04 2021 ] Training epoch: 130
[ Tue Feb  2 14:56:27 2021 ] 	Batch(91/1252) done. Loss: 0.0285  lr:0.000100  network_time: 0.0987
[ Tue Feb  2 14:56:49 2021 ] 	Batch(191/1252) done. Loss: 0.0217  lr:0.000100  network_time: 0.0898
[ Tue Feb  2 14:57:11 2021 ] 	Batch(291/1252) done. Loss: 0.0275  lr:0.000100  network_time: 0.0854
[ Tue Feb  2 14:57:33 2021 ] 	Batch(391/1252) done. Loss: 0.0408  lr:0.000100  network_time: 0.0797
[ Tue Feb  2 14:57:55 2021 ] 	Batch(491/1252) done. Loss: 0.0375  lr:0.000100  network_time: 0.0929
[ Tue Feb  2 14:58:18 2021 ] 	Batch(591/1252) done. Loss: 0.0454  lr:0.000100  network_time: 0.0924
[ Tue Feb  2 14:58:40 2021 ] 	Batch(691/1252) done. Loss: 0.0272  lr:0.000100  network_time: 0.0797
[ Tue Feb  2 14:59:02 2021 ] 	Batch(791/1252) done. Loss: 0.0488  lr:0.000100  network_time: 0.0823
[ Tue Feb  2 14:59:24 2021 ] 	Batch(891/1252) done. Loss: 0.0242  lr:0.000100  network_time: 0.0849
[ Tue Feb  2 14:59:46 2021 ] 	Batch(991/1252) done. Loss: 0.0298  lr:0.000100  network_time: 0.0765
[ Tue Feb  2 15:00:09 2021 ] 	Batch(1091/1252) done. Loss: 0.0360  lr:0.000100  network_time: 0.0892
[ Tue Feb  2 15:00:31 2021 ] 	Batch(1191/1252) done. Loss: 0.0595  lr:0.000100  network_time: 0.0802
[ Tue Feb  2 15:00:44 2021 ] Eval epoch: 130
[ Tue Feb  2 15:01:18 2021 ] 	Mean test loss of 258 batches: 0.5368034839630127.
[ Tue Feb  2 15:01:18 2021 ] 	Top1: 85.55%
[ Tue Feb  2 15:01:18 2021 ] 	Top5: 97.57%
[ Tue Feb  2 15:01:18 2021 ] Training epoch: 131
[ Tue Feb  2 15:01:30 2021 ] 	Batch(39/1252) done. Loss: 0.0394  lr:0.000100  network_time: 0.0937
[ Tue Feb  2 15:01:52 2021 ] 	Batch(139/1252) done. Loss: 0.0388  lr:0.000100  network_time: 0.0797
[ Tue Feb  2 15:02:14 2021 ] 	Batch(239/1252) done. Loss: 0.0185  lr:0.000100  network_time: 0.0840
[ Tue Feb  2 15:02:36 2021 ] 	Batch(339/1252) done. Loss: 0.0244  lr:0.000100  network_time: 0.0839
[ Tue Feb  2 15:02:58 2021 ] 	Batch(439/1252) done. Loss: 0.0346  lr:0.000100  network_time: 0.0777
[ Tue Feb  2 15:03:21 2021 ] 	Batch(539/1252) done. Loss: 0.0202  lr:0.000100  network_time: 0.0896
[ Tue Feb  2 15:03:43 2021 ] 	Batch(639/1252) done. Loss: 0.0633  lr:0.000100  network_time: 0.0880
[ Tue Feb  2 15:04:05 2021 ] 	Batch(739/1252) done. Loss: 0.0360  lr:0.000100  network_time: 0.0836
[ Tue Feb  2 15:04:27 2021 ] 	Batch(839/1252) done. Loss: 0.0527  lr:0.000100  network_time: 0.0864
[ Tue Feb  2 15:04:50 2021 ] 	Batch(939/1252) done. Loss: 0.1512  lr:0.000100  network_time: 0.0863
[ Tue Feb  2 15:05:12 2021 ] 	Batch(1039/1252) done. Loss: 0.0168  lr:0.000100  network_time: 0.0829
[ Tue Feb  2 15:05:34 2021 ] 	Batch(1139/1252) done. Loss: 0.0193  lr:0.000100  network_time: 0.0824
[ Tue Feb  2 15:05:56 2021 ] 	Batch(1239/1252) done. Loss: 0.0465  lr:0.000100  network_time: 0.0799
[ Tue Feb  2 15:05:59 2021 ] Eval epoch: 131
[ Tue Feb  2 15:06:33 2021 ] 	Mean test loss of 258 batches: 0.5288313031196594.
[ Tue Feb  2 15:06:33 2021 ] 	Top1: 85.55%
[ Tue Feb  2 15:06:33 2021 ] 	Top5: 97.70%
[ Tue Feb  2 15:06:33 2021 ] Training epoch: 132
[ Tue Feb  2 15:06:56 2021 ] 	Batch(87/1252) done. Loss: 0.0507  lr:0.000100  network_time: 0.0981
[ Tue Feb  2 15:07:18 2021 ] 	Batch(187/1252) done. Loss: 0.0491  lr:0.000100  network_time: 0.0921
[ Tue Feb  2 15:07:40 2021 ] 	Batch(287/1252) done. Loss: 0.1250  lr:0.000100  network_time: 0.0823
[ Tue Feb  2 15:08:02 2021 ] 	Batch(387/1252) done. Loss: 0.0320  lr:0.000100  network_time: 0.0793
[ Tue Feb  2 15:08:24 2021 ] 	Batch(487/1252) done. Loss: 0.0345  lr:0.000100  network_time: 0.0759
[ Tue Feb  2 15:08:47 2021 ] 	Batch(587/1252) done. Loss: 0.0480  lr:0.000100  network_time: 0.0988
[ Tue Feb  2 15:09:09 2021 ] 	Batch(687/1252) done. Loss: 0.0880  lr:0.000100  network_time: 0.1008
[ Tue Feb  2 15:09:31 2021 ] 	Batch(787/1252) done. Loss: 0.0448  lr:0.000100  network_time: 0.0839
[ Tue Feb  2 15:09:53 2021 ] 	Batch(887/1252) done. Loss: 0.0324  lr:0.000100  network_time: 0.0972
[ Tue Feb  2 15:10:15 2021 ] 	Batch(987/1252) done. Loss: 0.0881  lr:0.000100  network_time: 0.0891
[ Tue Feb  2 15:10:37 2021 ] 	Batch(1087/1252) done. Loss: 0.0309  lr:0.000100  network_time: 0.0823
[ Tue Feb  2 15:10:59 2021 ] 	Batch(1187/1252) done. Loss: 0.0109  lr:0.000100  network_time: 0.0853
[ Tue Feb  2 15:11:13 2021 ] Eval epoch: 132
[ Tue Feb  2 15:11:47 2021 ] 	Mean test loss of 258 batches: 0.5111232399940491.
[ Tue Feb  2 15:11:47 2021 ] 	Top1: 85.67%
[ Tue Feb  2 15:11:47 2021 ] 	Top5: 97.77%
[ Tue Feb  2 15:11:47 2021 ] Training epoch: 133
[ Tue Feb  2 15:11:59 2021 ] 	Batch(35/1252) done. Loss: 0.0703  lr:0.000100  network_time: 0.0798
[ Tue Feb  2 15:12:21 2021 ] 	Batch(135/1252) done. Loss: 0.0561  lr:0.000100  network_time: 0.1048
[ Tue Feb  2 15:12:43 2021 ] 	Batch(235/1252) done. Loss: 0.0470  lr:0.000100  network_time: 0.0763
[ Tue Feb  2 15:13:05 2021 ] 	Batch(335/1252) done. Loss: 0.0490  lr:0.000100  network_time: 0.0973
[ Tue Feb  2 15:13:27 2021 ] 	Batch(435/1252) done. Loss: 0.0985  lr:0.000100  network_time: 0.0681
[ Tue Feb  2 15:13:49 2021 ] 	Batch(535/1252) done. Loss: 0.0474  lr:0.000100  network_time: 0.0982
[ Tue Feb  2 15:14:11 2021 ] 	Batch(635/1252) done. Loss: 0.0222  lr:0.000100  network_time: 0.0828
[ Tue Feb  2 15:14:34 2021 ] 	Batch(735/1252) done. Loss: 0.0350  lr:0.000100  network_time: 0.0874
[ Tue Feb  2 15:14:56 2021 ] 	Batch(835/1252) done. Loss: 0.0409  lr:0.000100  network_time: 0.0840
[ Tue Feb  2 15:15:18 2021 ] 	Batch(935/1252) done. Loss: 0.0570  lr:0.000100  network_time: 0.0763
[ Tue Feb  2 15:15:40 2021 ] 	Batch(1035/1252) done. Loss: 0.0443  lr:0.000100  network_time: 0.0878
[ Tue Feb  2 15:16:02 2021 ] 	Batch(1135/1252) done. Loss: 0.0083  lr:0.000100  network_time: 0.0855
[ Tue Feb  2 15:16:25 2021 ] 	Batch(1235/1252) done. Loss: 0.0338  lr:0.000100  network_time: 0.0789
[ Tue Feb  2 15:16:28 2021 ] Eval epoch: 133
[ Tue Feb  2 15:17:03 2021 ] 	Mean test loss of 258 batches: 0.526906430721283.
[ Tue Feb  2 15:17:03 2021 ] 	Top1: 85.67%
[ Tue Feb  2 15:17:03 2021 ] 	Top5: 97.79%
[ Tue Feb  2 15:17:03 2021 ] Training epoch: 134
[ Tue Feb  2 15:17:24 2021 ] 	Batch(83/1252) done. Loss: 0.0147  lr:0.000100  network_time: 0.0926
[ Tue Feb  2 15:17:47 2021 ] 	Batch(183/1252) done. Loss: 0.0245  lr:0.000100  network_time: 0.0788
[ Tue Feb  2 15:18:09 2021 ] 	Batch(283/1252) done. Loss: 0.0412  lr:0.000100  network_time: 0.0965
[ Tue Feb  2 15:18:31 2021 ] 	Batch(383/1252) done. Loss: 0.0259  lr:0.000100  network_time: 0.0828
[ Tue Feb  2 15:18:53 2021 ] 	Batch(483/1252) done. Loss: 0.0223  lr:0.000100  network_time: 0.0935
[ Tue Feb  2 15:19:14 2021 ] 	Batch(583/1252) done. Loss: 0.0388  lr:0.000100  network_time: 0.0999
[ Tue Feb  2 15:19:36 2021 ] 	Batch(683/1252) done. Loss: 0.0379  lr:0.000100  network_time: 0.0827
[ Tue Feb  2 15:19:59 2021 ] 	Batch(783/1252) done. Loss: 0.0394  lr:0.000100  network_time: 0.0853
[ Tue Feb  2 15:20:21 2021 ] 	Batch(883/1252) done. Loss: 0.0493  lr:0.000100  network_time: 0.0842
[ Tue Feb  2 15:20:43 2021 ] 	Batch(983/1252) done. Loss: 0.0209  lr:0.000100  network_time: 0.0820
[ Tue Feb  2 15:21:05 2021 ] 	Batch(1083/1252) done. Loss: 0.0772  lr:0.000100  network_time: 0.0831
[ Tue Feb  2 15:21:26 2021 ] 	Batch(1183/1252) done. Loss: 0.0816  lr:0.000100  network_time: 0.0842
[ Tue Feb  2 15:21:42 2021 ] Eval epoch: 134
[ Tue Feb  2 15:22:16 2021 ] 	Mean test loss of 258 batches: 0.539790689945221.
[ Tue Feb  2 15:22:16 2021 ] 	Top1: 85.36%
[ Tue Feb  2 15:22:16 2021 ] 	Top5: 97.66%
[ Tue Feb  2 15:22:16 2021 ] Training epoch: 135
[ Tue Feb  2 15:22:26 2021 ] 	Batch(31/1252) done. Loss: 0.0401  lr:0.000100  network_time: 0.0804
[ Tue Feb  2 15:22:48 2021 ] 	Batch(131/1252) done. Loss: 0.0225  lr:0.000100  network_time: 0.0852
[ Tue Feb  2 15:23:10 2021 ] 	Batch(231/1252) done. Loss: 0.0382  lr:0.000100  network_time: 0.0833
[ Tue Feb  2 15:23:32 2021 ] 	Batch(331/1252) done. Loss: 0.0428  lr:0.000100  network_time: 0.0853
[ Tue Feb  2 15:23:54 2021 ] 	Batch(431/1252) done. Loss: 0.0402  lr:0.000100  network_time: 0.0815
[ Tue Feb  2 15:24:16 2021 ] 	Batch(531/1252) done. Loss: 0.0790  lr:0.000100  network_time: 0.0820
[ Tue Feb  2 15:24:38 2021 ] 	Batch(631/1252) done. Loss: 0.0218  lr:0.000100  network_time: 0.0888
[ Tue Feb  2 15:25:00 2021 ] 	Batch(731/1252) done. Loss: 0.0210  lr:0.000100  network_time: 0.0746
[ Tue Feb  2 15:25:22 2021 ] 	Batch(831/1252) done. Loss: 0.0298  lr:0.000100  network_time: 0.0722
[ Tue Feb  2 15:25:44 2021 ] 	Batch(931/1252) done. Loss: 0.0864  lr:0.000100  network_time: 0.0833
[ Tue Feb  2 15:26:06 2021 ] 	Batch(1031/1252) done. Loss: 0.0247  lr:0.000100  network_time: 0.0759
[ Tue Feb  2 15:26:28 2021 ] 	Batch(1131/1252) done. Loss: 0.0411  lr:0.000100  network_time: 0.0876
[ Tue Feb  2 15:26:50 2021 ] 	Batch(1231/1252) done. Loss: 0.0241  lr:0.000100  network_time: 0.0783
[ Tue Feb  2 15:26:55 2021 ] Eval epoch: 135
[ Tue Feb  2 15:27:29 2021 ] 	Mean test loss of 258 batches: 0.5275974273681641.
[ Tue Feb  2 15:27:29 2021 ] 	Top1: 85.53%
[ Tue Feb  2 15:27:29 2021 ] 	Top5: 97.68%
[ Tue Feb  2 15:27:29 2021 ] Training epoch: 136
[ Tue Feb  2 15:27:50 2021 ] 	Batch(79/1252) done. Loss: 0.0215  lr:0.000100  network_time: 0.0848
[ Tue Feb  2 15:28:12 2021 ] 	Batch(179/1252) done. Loss: 0.0601  lr:0.000100  network_time: 0.0878
[ Tue Feb  2 15:28:34 2021 ] 	Batch(279/1252) done. Loss: 0.0500  lr:0.000100  network_time: 0.0910
[ Tue Feb  2 15:28:56 2021 ] 	Batch(379/1252) done. Loss: 0.0286  lr:0.000100  network_time: 0.0883
[ Tue Feb  2 15:29:18 2021 ] 	Batch(479/1252) done. Loss: 0.0488  lr:0.000100  network_time: 0.0879
[ Tue Feb  2 15:29:40 2021 ] 	Batch(579/1252) done. Loss: 0.0090  lr:0.000100  network_time: 0.0729
[ Tue Feb  2 15:30:02 2021 ] 	Batch(679/1252) done. Loss: 0.0208  lr:0.000100  network_time: 0.0977
[ Tue Feb  2 15:30:24 2021 ] 	Batch(779/1252) done. Loss: 0.0354  lr:0.000100  network_time: 0.0710
[ Tue Feb  2 15:30:47 2021 ] 	Batch(879/1252) done. Loss: 0.0702  lr:0.000100  network_time: 0.0807
[ Tue Feb  2 15:31:09 2021 ] 	Batch(979/1252) done. Loss: 0.0465  lr:0.000100  network_time: 0.0918
[ Tue Feb  2 15:31:31 2021 ] 	Batch(1079/1252) done. Loss: 0.0348  lr:0.000100  network_time: 0.1059
[ Tue Feb  2 15:31:53 2021 ] 	Batch(1179/1252) done. Loss: 0.0241  lr:0.000100  network_time: 0.0806
[ Tue Feb  2 15:32:09 2021 ] Eval epoch: 136
[ Tue Feb  2 15:32:42 2021 ] 	Mean test loss of 258 batches: 0.5271883010864258.
[ Tue Feb  2 15:32:43 2021 ] 	Top1: 85.66%
[ Tue Feb  2 15:32:43 2021 ] 	Top5: 97.73%
[ Tue Feb  2 15:32:43 2021 ] Training epoch: 137
[ Tue Feb  2 15:32:52 2021 ] 	Batch(27/1252) done. Loss: 0.0398  lr:0.000100  network_time: 0.0825
[ Tue Feb  2 15:33:14 2021 ] 	Batch(127/1252) done. Loss: 0.0844  lr:0.000100  network_time: 0.0772
[ Tue Feb  2 15:33:35 2021 ] 	Batch(227/1252) done. Loss: 0.0276  lr:0.000100  network_time: 0.0847
[ Tue Feb  2 15:33:58 2021 ] 	Batch(327/1252) done. Loss: 0.0358  lr:0.000100  network_time: 0.0818
[ Tue Feb  2 15:34:20 2021 ] 	Batch(427/1252) done. Loss: 0.0553  lr:0.000100  network_time: 0.0774
[ Tue Feb  2 15:34:42 2021 ] 	Batch(527/1252) done. Loss: 0.0379  lr:0.000100  network_time: 0.0845
[ Tue Feb  2 15:35:04 2021 ] 	Batch(627/1252) done. Loss: 0.0255  lr:0.000100  network_time: 0.0957
[ Tue Feb  2 15:35:26 2021 ] 	Batch(727/1252) done. Loss: 0.0180  lr:0.000100  network_time: 0.0790
[ Tue Feb  2 15:35:48 2021 ] 	Batch(827/1252) done. Loss: 0.0217  lr:0.000100  network_time: 0.0947
[ Tue Feb  2 15:36:10 2021 ] 	Batch(927/1252) done. Loss: 0.0285  lr:0.000100  network_time: 0.0816
[ Tue Feb  2 15:36:32 2021 ] 	Batch(1027/1252) done. Loss: 0.0678  lr:0.000100  network_time: 0.0864
[ Tue Feb  2 15:36:53 2021 ] 	Batch(1127/1252) done. Loss: 0.0407  lr:0.000100  network_time: 0.0900
[ Tue Feb  2 15:37:16 2021 ] 	Batch(1227/1252) done. Loss: 0.1185  lr:0.000100  network_time: 0.0810
[ Tue Feb  2 15:37:21 2021 ] Eval epoch: 137
[ Tue Feb  2 15:37:55 2021 ] 	Mean test loss of 258 batches: 0.5293797850608826.
[ Tue Feb  2 15:37:55 2021 ] 	Top1: 85.55%
[ Tue Feb  2 15:37:55 2021 ] 	Top5: 97.76%
[ Tue Feb  2 15:37:55 2021 ] Training epoch: 138
[ Tue Feb  2 15:38:15 2021 ] 	Batch(75/1252) done. Loss: 0.0225  lr:0.000100  network_time: 0.0936
[ Tue Feb  2 15:38:37 2021 ] 	Batch(175/1252) done. Loss: 0.0147  lr:0.000100  network_time: 0.0961
[ Tue Feb  2 15:38:59 2021 ] 	Batch(275/1252) done. Loss: 0.0405  lr:0.000100  network_time: 0.0866
[ Tue Feb  2 15:39:22 2021 ] 	Batch(375/1252) done. Loss: 0.0276  lr:0.000100  network_time: 0.0827
[ Tue Feb  2 15:39:44 2021 ] 	Batch(475/1252) done. Loss: 0.0128  lr:0.000100  network_time: 0.0960
[ Tue Feb  2 15:40:06 2021 ] 	Batch(575/1252) done. Loss: 0.0260  lr:0.000100  network_time: 0.0829
[ Tue Feb  2 15:40:28 2021 ] 	Batch(675/1252) done. Loss: 0.0424  lr:0.000100  network_time: 0.1007
[ Tue Feb  2 15:40:50 2021 ] 	Batch(775/1252) done. Loss: 0.0282  lr:0.000100  network_time: 0.0803
[ Tue Feb  2 15:41:12 2021 ] 	Batch(875/1252) done. Loss: 0.0609  lr:0.000100  network_time: 0.0971
[ Tue Feb  2 15:41:34 2021 ] 	Batch(975/1252) done. Loss: 0.0330  lr:0.000100  network_time: 0.0860
[ Tue Feb  2 15:41:57 2021 ] 	Batch(1075/1252) done. Loss: 0.0925  lr:0.000100  network_time: 0.1008
[ Tue Feb  2 15:42:19 2021 ] 	Batch(1175/1252) done. Loss: 0.1243  lr:0.000100  network_time: 0.0859
[ Tue Feb  2 15:42:36 2021 ] Eval epoch: 138
[ Tue Feb  2 15:43:10 2021 ] 	Mean test loss of 258 batches: 0.536871612071991.
[ Tue Feb  2 15:43:10 2021 ] 	Top1: 85.39%
[ Tue Feb  2 15:43:10 2021 ] 	Top5: 97.66%
[ Tue Feb  2 15:43:10 2021 ] Training epoch: 139
[ Tue Feb  2 15:43:18 2021 ] 	Batch(23/1252) done. Loss: 0.0223  lr:0.000100  network_time: 0.0846
[ Tue Feb  2 15:43:40 2021 ] 	Batch(123/1252) done. Loss: 0.0272  lr:0.000100  network_time: 0.0797
[ Tue Feb  2 15:44:02 2021 ] 	Batch(223/1252) done. Loss: 0.0566  lr:0.000100  network_time: 0.0886
[ Tue Feb  2 15:44:24 2021 ] 	Batch(323/1252) done. Loss: 0.0184  lr:0.000100  network_time: 0.0717
[ Tue Feb  2 15:44:46 2021 ] 	Batch(423/1252) done. Loss: 0.0180  lr:0.000100  network_time: 0.0801
[ Tue Feb  2 15:45:08 2021 ] 	Batch(523/1252) done. Loss: 0.0251  lr:0.000100  network_time: 0.0929
[ Tue Feb  2 15:45:30 2021 ] 	Batch(623/1252) done. Loss: 0.0471  lr:0.000100  network_time: 0.0985
[ Tue Feb  2 15:45:52 2021 ] 	Batch(723/1252) done. Loss: 0.0160  lr:0.000100  network_time: 0.0799
[ Tue Feb  2 15:46:14 2021 ] 	Batch(823/1252) done. Loss: 0.0221  lr:0.000100  network_time: 0.0941
[ Tue Feb  2 15:46:36 2021 ] 	Batch(923/1252) done. Loss: 0.0479  lr:0.000100  network_time: 0.0802
[ Tue Feb  2 15:46:58 2021 ] 	Batch(1023/1252) done. Loss: 0.0163  lr:0.000100  network_time: 0.0937
[ Tue Feb  2 15:47:20 2021 ] 	Batch(1123/1252) done. Loss: 0.0235  lr:0.000100  network_time: 0.0788
[ Tue Feb  2 15:47:42 2021 ] 	Batch(1223/1252) done. Loss: 0.0232  lr:0.000100  network_time: 0.0813
[ Tue Feb  2 15:47:49 2021 ] Eval epoch: 139
[ Tue Feb  2 15:48:22 2021 ] 	Mean test loss of 258 batches: 0.5296058654785156.
[ Tue Feb  2 15:48:22 2021 ] 	Top1: 85.61%
[ Tue Feb  2 15:48:22 2021 ] 	Top5: 97.68%
[ Tue Feb  2 15:48:22 2021 ] Training epoch: 140
[ Tue Feb  2 15:48:41 2021 ] 	Batch(71/1252) done. Loss: 0.0456  lr:0.000100  network_time: 0.0802
[ Tue Feb  2 15:49:03 2021 ] 	Batch(171/1252) done. Loss: 0.0400  lr:0.000100  network_time: 0.0808
[ Tue Feb  2 15:49:26 2021 ] 	Batch(271/1252) done. Loss: 0.0348  lr:0.000100  network_time: 0.0866
[ Tue Feb  2 15:49:48 2021 ] 	Batch(371/1252) done. Loss: 0.0371  lr:0.000100  network_time: 0.0836
[ Tue Feb  2 15:50:10 2021 ] 	Batch(471/1252) done. Loss: 0.0470  lr:0.000100  network_time: 0.0836
[ Tue Feb  2 15:50:32 2021 ] 	Batch(571/1252) done. Loss: 0.0204  lr:0.000100  network_time: 0.0870
[ Tue Feb  2 15:50:54 2021 ] 	Batch(671/1252) done. Loss: 0.0280  lr:0.000100  network_time: 0.0855
[ Tue Feb  2 15:51:16 2021 ] 	Batch(771/1252) done. Loss: 0.0131  lr:0.000100  network_time: 0.0789
[ Tue Feb  2 15:51:38 2021 ] 	Batch(871/1252) done. Loss: 0.0278  lr:0.000100  network_time: 0.1004
[ Tue Feb  2 15:52:00 2021 ] 	Batch(971/1252) done. Loss: 0.0378  lr:0.000100  network_time: 0.0791
[ Tue Feb  2 15:52:23 2021 ] 	Batch(1071/1252) done. Loss: 0.0189  lr:0.000100  network_time: 0.0779
[ Tue Feb  2 15:52:45 2021 ] 	Batch(1171/1252) done. Loss: 0.0198  lr:0.000100  network_time: 0.0803
[ Tue Feb  2 15:53:02 2021 ] Eval epoch: 140
[ Tue Feb  2 15:53:36 2021 ] 	Mean test loss of 258 batches: 0.5262705683708191.
[ Tue Feb  2 15:53:36 2021 ] 	Top1: 85.72%
[ Tue Feb  2 15:53:36 2021 ] 	Top5: 97.73%
